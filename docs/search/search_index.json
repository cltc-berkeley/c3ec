{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Public Interest Cybersecurity The Citizen Clinic is a public-interest cybersecurity clinic at the University of California, Berkeley. We support the capacity of politically targeted organizations to defend themselves against online threats. Building off the Center for Long-Term Cybersecurity\u2019s research on the ecosystem of organizations providing technical assistance to civil society, the clinic supports multidisciplinary teams of students to assess threats to targeted organizations, recommend risk-appropriate mitigations, and work collaboratively with clients to implement new policies and technical controls that enhance their cybersecurity. Visit this page to read case studies about our recent work. For organizations seeking more information about Citizen Clinic, please visit https://cltc.berkeley.edu/about-us/citizen-clinic/ . The Citizen Clinic Cybersecurity Education Center The Citizen Clinic Cybersecurity Education Center is designed to share basic cybersecurity resources for civil society organizations, and to inform other academic institutions that may be interested in adopting the clinic model. Curriculum Interested in setting up a cybersecurity clinic? View current and past Citizen Clinic syllabi and reading lists, in-class activities, and work assignments. Infrastructure Setting up the technology infrastructure for your own program? Check out our primers and policies for setting up virtual profiles, virtual private networks, and phishing simulators. Baseline Organizational Security Guide All organizations need a basic level of cybersecurity , so whether or not you think you are at risk of a cyberattack, we encourage you to read our Baseline Organizational Security Guide. Comments or ideas? Submit an issue. Citizen Clinic is a program of the Center for Long-Term Cybersecurity. Learn more at https://cltc.berkeley.edu/ . License for written content: CC BY 3.0. See original sources for license information of any images and linked publications.","title":"Home"},{"location":"#public-interest-cybersecurity","text":"The Citizen Clinic is a public-interest cybersecurity clinic at the University of California, Berkeley. We support the capacity of politically targeted organizations to defend themselves against online threats. Building off the Center for Long-Term Cybersecurity\u2019s research on the ecosystem of organizations providing technical assistance to civil society, the clinic supports multidisciplinary teams of students to assess threats to targeted organizations, recommend risk-appropriate mitigations, and work collaboratively with clients to implement new policies and technical controls that enhance their cybersecurity. Visit this page to read case studies about our recent work. For organizations seeking more information about Citizen Clinic, please visit https://cltc.berkeley.edu/about-us/citizen-clinic/ .","title":"Public Interest Cybersecurity"},{"location":"#the-citizen-clinic-cybersecurity-education-center","text":"The Citizen Clinic Cybersecurity Education Center is designed to share basic cybersecurity resources for civil society organizations, and to inform other academic institutions that may be interested in adopting the clinic model.","title":"The Citizen Clinic Cybersecurity Education Center"},{"location":"#curriculum","text":"Interested in setting up a cybersecurity clinic? View current and past Citizen Clinic syllabi and reading lists, in-class activities, and work assignments.","title":"Curriculum"},{"location":"#infrastructure","text":"Setting up the technology infrastructure for your own program? Check out our primers and policies for setting up virtual profiles, virtual private networks, and phishing simulators.","title":"Infrastructure"},{"location":"#baseline-organizational-security-guide","text":"All organizations need a basic level of cybersecurity , so whether or not you think you are at risk of a cyberattack, we encourage you to read our Baseline Organizational Security Guide. Comments or ideas? Submit an issue. Citizen Clinic is a program of the Center for Long-Term Cybersecurity. Learn more at https://cltc.berkeley.edu/ . License for written content: CC BY 3.0. See original sources for license information of any images and linked publications.","title":"Baseline Organizational Security Guide"},{"location":"Clinic_Curriculum/Case_Studies/","text":"A Voting Rights Organization A Regional Abortion Fund A Domestic LGBTQ Support Organization Land Is Life, an Indigenous Community Support Network A Voting Rights Organization The Challenge: In the run up to the 2020 primary election, a volunteer-led, U.S.-based voting rights organization had increasing concerns about the digital safety of their team members and the integrity of their data. In particular, the organization was concerned that online disinformation campaigns could hamper its efforts to ensure a fair and open democracy. What Citizen Clinic Did: A team of students from Citizen Clinic, led by mentors from UC Berkeley and partner organizations, reached out to help the organization secure its online systems to be more resistant to cyberattacks. They began by conducting a large-scale audit to understand the organization\u2019s cybersecurity challenges and the threats their team members faced. This audit exposed that the organization had no formalized structures in place for securing online accounts and responding to security incidents. More worryingly, many of the organization\u2019s online accounts were accessed by multiple volunteers through shared logins. The Citizen Clinic student team identified the shared accounts as the greatest immediate risk, and focused their efforts on moving the organization toward a more robust, secure account system. Outcome: As a result of Citizen Clinic\u2019s recommendations, the organization has successfully created an account structure through which login credentials do not have to be shared among volunteers, which will make it easier to implement further security measures in the future. With a plan for improving its cybersecurity in place, the organization can more confidently carry out its mission to protect voter rights. A Regional Abortion Fund The Challenge: A regional abortion fund dedicated to supporting the reproductive rights of Americans faced diverse challenges online, including online harassment from bots and trolls, threats of data breaches to reveal patient, provider, and donor information, and fraudulent websites that promote fake clinics or scams to collect donations. What Citizen Clinic Did: The Citizen Clinic student team performed an audit of the client\u2019s information storage and communication systems, as well as a comprehensive risk assessment that led to the identification of key organizational assets and likely threat scenarios. As part of this process, the team met with different people in the organization and rigorously documented the organization\u2019s information workflow. The students created a series of spreadsheets to help organize this information, which ultimately helped identify which systems were most vulnerable and contained sensitive information. This risk assessment revealed a major vulnerability in a document storage system that contained both financial information and patient data. In addition, vulnerabilities were found in the organization\u2019s email system, as well as in an online form and data collection tool. The Citizen Clinic\u2019s student team also upgraded some of the organization\u2019s key digital business systems, which had previously been too difficult to safely and efficiently use. They also completed a migration of assets to a more secure data storage platform; re-organized a folder structure to better manage access permissions; and enabled multi-factor authentication for the organization\u2019s new accounts. Outcomes: The team provided the client with a comprehensive report that included a risk assessment, explanation of deliverables, and original context research for the project. They created security policies and information workflows for different roles within the organization \u2014 including board members, staff, and volunteers \u2014 and drew an outline of each member\u2019s access to the digital storage system and how each member can manage their permissions optimally. Working with the fund\u2019s interim executive director, the team delivered a comprehensive security training that introduced members to the threats they face, the new storage system, and the security policies and general best practices to follow on a daily basis to keep the organization secure. \u201cWe used our training and policies to present the ideas from our threat model to the staff of the organization and to begin an organizational conversation about information security,\u201d one of the students explained. \u201cCybersecurity is not all tech. It involves strategic thinking and prioritization of threats, and a strategic search for creative end solutions that are simple and practical enough for clients to implement.\u201d A Domestic LGBTQ Support Organization The Challenge: A U.S.-based LGBTQ nonprofit organization was subjected to hate campaigns from extremist groups and violent online communities. Beyond harassment on social media and denial of service attacks on their web applications, the organization has had its member\u2019s personal information - home addresses, dead names, phone numbers, and photographs - collected and published on the web (also known as doxxing ). This has led to staff members\u2019 facing in-person harassment and death threats. What Citizen Clinic Did: The Citizen Clinic team first gained a foundational understanding of the organization\u2019s unique context, a contextual research process that included an in-depth interview with the technology director and a review of the organization\u2019s existing cybersecurity protocols. Based on insights from industry experts, the students provided concrete suggestions about how the organization could enhance its cybersecurity training program, as well as its telephone and website security. They also connected the organization with experts who could provide future support beyond the Clinic\u2019s capabilities. After implementing cybersecurity practices, the students developed short security quizzes to assess the degree to which these practices had \u201csunk in\u201d to the organization\u2019s members. The quizzes were intended to remind staff about existing policies as well as to assess any possible weak spots in training. In addition, the students instigated a comprehensive phishing campaign, and emailed fifteen members from an unfamiliar email address and urged them to click a link and submit their credentials. The phishing campaign provided the Technology Director with concrete feedback on the organization\u2019s strengths and vulnerabilities to phishing attacks. Outcomes: The Citizen Clinic student team holistically assessed this organization\u2019s cybersecurity capabilities, improved its training program, provided feedback on strengthening its hotline and website, and connected the organization to additional pro bono resources. Ultimately, the efforts improved the organization\u2019s ability to handle DDoS attacks, misinformation campaigns, phishing attempts, and doxxing by trolls. \u201cWe were successful in helping the organization because we understood its unique needs, concerns, and goals,\u201d one of the students said. \u201cBy focusing on both implementing new policies and making sure those policies were accepted by members, we helped the organization find effective and practical solutions. Land Is Life, an Indigenous Community Support Network The Challenge: Land is Life is a non-profit civil society organization that supports local communities around the world that are adversely affected by development projects, particularly those that relate to environmental and human rights. Land Is Life and its partner network are frequently subjected to online disinformation campaigns, data breaches, and other online threats from a variety of threat actors, including governments, corporations, cartels, and paramilitary groups. What Citizen Clinic Did: A student team from Citizen Clinic performed an analysis of factors contributing to vulnerabilities and threats to Land is Life. The students interviewed regional field directors in different geographies (i.e. Africa, Asia, and Latin America), which revealed that team members around the world used a variety of digital devices, communication methods, and security practices. While the organization had baseline security practices in place, they lacked standardized secure protocols for communications and travel. Citizen Clinic addressed this problem by developing a communications and travel protocol guide with a quick-guide section for easy usage. The student team also wrote an onboarding guide for technology so that employees could quickly set up their devices in a secure fashion, independent of their understanding of secure communications or travel practices. They also conducted phishing testing that revealed the organization is vulnerable to phishing attacks. They presented Land is Life\u2019s leaders with a series of recommendations for implementation and integration. \u201cWe wanted to keep documents concise and condensed so that users of the document could quickly acquire the information they need and would not get fatigued from its density, while also being thorough in informing people of the motivations behind why such practices are necessary or important,\u201d the students explained. Outcomes: The Citizen Clinic team recommended and implemented a variety of solutions to help Land is Life and its partners to improve their cybersecurity, including multi-factor authentication, password management tools, and enhancing other security protocols. As a result of implementing these recommendations, the organization\u2019s baseline digital defenses were greatly improved. \u201cIn some ways, Citizen Clinic engaging with Land is Life is like engaging with many dozens of organizations,\u201d says Casey Box, Executive Director of Land is Life. \u201cCitizen Clinic took the time to do a diagnostic amongst my entire team and partners to understand how they operate day-to-day at the organization, and what kind of threats and concerns they had in regards to their digital security. We developed a plan that we rolled out over the course of two years to develop protocols, systems, and different ways that we could strengthen our digital security as an organization.\u201d","title":"Case Studies"},{"location":"Clinic_Curriculum/Case_Studies/#a-voting-rights-organization","text":"The Challenge: In the run up to the 2020 primary election, a volunteer-led, U.S.-based voting rights organization had increasing concerns about the digital safety of their team members and the integrity of their data. In particular, the organization was concerned that online disinformation campaigns could hamper its efforts to ensure a fair and open democracy. What Citizen Clinic Did: A team of students from Citizen Clinic, led by mentors from UC Berkeley and partner organizations, reached out to help the organization secure its online systems to be more resistant to cyberattacks. They began by conducting a large-scale audit to understand the organization\u2019s cybersecurity challenges and the threats their team members faced. This audit exposed that the organization had no formalized structures in place for securing online accounts and responding to security incidents. More worryingly, many of the organization\u2019s online accounts were accessed by multiple volunteers through shared logins. The Citizen Clinic student team identified the shared accounts as the greatest immediate risk, and focused their efforts on moving the organization toward a more robust, secure account system. Outcome: As a result of Citizen Clinic\u2019s recommendations, the organization has successfully created an account structure through which login credentials do not have to be shared among volunteers, which will make it easier to implement further security measures in the future. With a plan for improving its cybersecurity in place, the organization can more confidently carry out its mission to protect voter rights.","title":"A Voting Rights Organization"},{"location":"Clinic_Curriculum/Case_Studies/#a-regional-abortion-fund","text":"The Challenge: A regional abortion fund dedicated to supporting the reproductive rights of Americans faced diverse challenges online, including online harassment from bots and trolls, threats of data breaches to reveal patient, provider, and donor information, and fraudulent websites that promote fake clinics or scams to collect donations. What Citizen Clinic Did: The Citizen Clinic student team performed an audit of the client\u2019s information storage and communication systems, as well as a comprehensive risk assessment that led to the identification of key organizational assets and likely threat scenarios. As part of this process, the team met with different people in the organization and rigorously documented the organization\u2019s information workflow. The students created a series of spreadsheets to help organize this information, which ultimately helped identify which systems were most vulnerable and contained sensitive information. This risk assessment revealed a major vulnerability in a document storage system that contained both financial information and patient data. In addition, vulnerabilities were found in the organization\u2019s email system, as well as in an online form and data collection tool. The Citizen Clinic\u2019s student team also upgraded some of the organization\u2019s key digital business systems, which had previously been too difficult to safely and efficiently use. They also completed a migration of assets to a more secure data storage platform; re-organized a folder structure to better manage access permissions; and enabled multi-factor authentication for the organization\u2019s new accounts. Outcomes: The team provided the client with a comprehensive report that included a risk assessment, explanation of deliverables, and original context research for the project. They created security policies and information workflows for different roles within the organization \u2014 including board members, staff, and volunteers \u2014 and drew an outline of each member\u2019s access to the digital storage system and how each member can manage their permissions optimally. Working with the fund\u2019s interim executive director, the team delivered a comprehensive security training that introduced members to the threats they face, the new storage system, and the security policies and general best practices to follow on a daily basis to keep the organization secure. \u201cWe used our training and policies to present the ideas from our threat model to the staff of the organization and to begin an organizational conversation about information security,\u201d one of the students explained. \u201cCybersecurity is not all tech. It involves strategic thinking and prioritization of threats, and a strategic search for creative end solutions that are simple and practical enough for clients to implement.\u201d","title":"A Regional Abortion Fund"},{"location":"Clinic_Curriculum/Case_Studies/#a-domestic-lgbtq-support-organization","text":"The Challenge: A U.S.-based LGBTQ nonprofit organization was subjected to hate campaigns from extremist groups and violent online communities. Beyond harassment on social media and denial of service attacks on their web applications, the organization has had its member\u2019s personal information - home addresses, dead names, phone numbers, and photographs - collected and published on the web (also known as doxxing ). This has led to staff members\u2019 facing in-person harassment and death threats. What Citizen Clinic Did: The Citizen Clinic team first gained a foundational understanding of the organization\u2019s unique context, a contextual research process that included an in-depth interview with the technology director and a review of the organization\u2019s existing cybersecurity protocols. Based on insights from industry experts, the students provided concrete suggestions about how the organization could enhance its cybersecurity training program, as well as its telephone and website security. They also connected the organization with experts who could provide future support beyond the Clinic\u2019s capabilities. After implementing cybersecurity practices, the students developed short security quizzes to assess the degree to which these practices had \u201csunk in\u201d to the organization\u2019s members. The quizzes were intended to remind staff about existing policies as well as to assess any possible weak spots in training. In addition, the students instigated a comprehensive phishing campaign, and emailed fifteen members from an unfamiliar email address and urged them to click a link and submit their credentials. The phishing campaign provided the Technology Director with concrete feedback on the organization\u2019s strengths and vulnerabilities to phishing attacks. Outcomes: The Citizen Clinic student team holistically assessed this organization\u2019s cybersecurity capabilities, improved its training program, provided feedback on strengthening its hotline and website, and connected the organization to additional pro bono resources. Ultimately, the efforts improved the organization\u2019s ability to handle DDoS attacks, misinformation campaigns, phishing attempts, and doxxing by trolls. \u201cWe were successful in helping the organization because we understood its unique needs, concerns, and goals,\u201d one of the students said. \u201cBy focusing on both implementing new policies and making sure those policies were accepted by members, we helped the organization find effective and practical solutions.","title":"A Domestic LGBTQ Support Organization"},{"location":"Clinic_Curriculum/Case_Studies/#land-is-life-an-indigenous-community-support-network","text":"The Challenge: Land is Life is a non-profit civil society organization that supports local communities around the world that are adversely affected by development projects, particularly those that relate to environmental and human rights. Land Is Life and its partner network are frequently subjected to online disinformation campaigns, data breaches, and other online threats from a variety of threat actors, including governments, corporations, cartels, and paramilitary groups. What Citizen Clinic Did: A student team from Citizen Clinic performed an analysis of factors contributing to vulnerabilities and threats to Land is Life. The students interviewed regional field directors in different geographies (i.e. Africa, Asia, and Latin America), which revealed that team members around the world used a variety of digital devices, communication methods, and security practices. While the organization had baseline security practices in place, they lacked standardized secure protocols for communications and travel. Citizen Clinic addressed this problem by developing a communications and travel protocol guide with a quick-guide section for easy usage. The student team also wrote an onboarding guide for technology so that employees could quickly set up their devices in a secure fashion, independent of their understanding of secure communications or travel practices. They also conducted phishing testing that revealed the organization is vulnerable to phishing attacks. They presented Land is Life\u2019s leaders with a series of recommendations for implementation and integration. \u201cWe wanted to keep documents concise and condensed so that users of the document could quickly acquire the information they need and would not get fatigued from its density, while also being thorough in informing people of the motivations behind why such practices are necessary or important,\u201d the students explained. Outcomes: The Citizen Clinic team recommended and implemented a variety of solutions to help Land is Life and its partners to improve their cybersecurity, including multi-factor authentication, password management tools, and enhancing other security protocols. As a result of implementing these recommendations, the organization\u2019s baseline digital defenses were greatly improved. \u201cIn some ways, Citizen Clinic engaging with Land is Life is like engaging with many dozens of organizations,\u201d says Casey Box, Executive Director of Land is Life. \u201cCitizen Clinic took the time to do a diagnostic amongst my entire team and partners to understand how they operate day-to-day at the organization, and what kind of threats and concerns they had in regards to their digital security. We developed a plan that we rolled out over the course of two years to develop protocols, systems, and different ways that we could strengthen our digital security as an organization.\u201d","title":"Land Is Life, an Indigenous Community Support Network"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/","text":"Info 290. Public Interest Cybersecurity: The Citizen Clinic Practicum. Fall 2018. Course description. For individuals and organizations involved in political advocacy, cybersecurity threats are an increasingly common reality of operating in the digital world. Civil society has always been under attack from ideological, political, and governmental opponents who seek to silence dissenting opinions, but the widespread adoption of connected technologies by the individuals and organizations that make up civil society creates a new class of vulnerabilities. The Center for Long-Term Cybersecurity\u2019s Citizen Clinic provides students with real-world experience to develop and implement sound cybersecurity practices needed to protect these politically-vulnerable organizations and persons around the world. Students will learn about both the theory and practice of baseline digital security, the intricacies of protection for largely under-resourced organizations, and effective risk management in complex political, sociological, legal, and ethical contexts. Working with civil society organizations as clients, students will learn how to assess vulnerabilities and develop, recommend, and implement mitigations for security risks despite having little or no prior background in the client\u2019s mission or context. The emphasis is on pragmatic, workable solutions that take into account the way client organizations operate. Coursework will focus on client-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the client. Schedule. Typically, Wednesday class meetings in the first half of the semester will be lecture/discussion-centered, while Monday meetings will be more technical & project-oriented. In the second half of the semester, these class times will be reserved for work with the teaching team, guest speakers, and discussions tailored to the specific needs of your client. Note: This schedule is tentative and may be adjusted - assignment dates may change, additional readings may be assigned, speakers/lectures may be shuffled, etc. The teaching team will announce when changes are made. Week 0: Introduction Read: Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] Sean Brooks \u201cDefending Politically Vulnerable Organizations Online\u201d [ https://cltc.berkeley.edu/wp-content/uploads/2018/07/CLTC_Defending_PVOs.pdf ] Assignments Due: 8/22 11:59PM : Submit application materials to enroll in this course. You will be notified of your enrollment status prior to the next class meeting on August 27th. Wednesday 8/22 [South Hall Room 107] : We will introduce the content and methods of the course, answer your questions, and everyone will introduce themselves to one another. Week 1: What is Public-Interest Cybersecurity? Read: Jorge Luis Sierra \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://ijnet.org/en/content/digital-and-mobile-security-mexican-journalists-and-bloggers ] Netgain \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] Citizen Lab\u2019s \u201cAbout Us\u201d Paper. [ https://citizenlab.ca/wp-content/uploads/2018/05/18033-Citizen-Lab-booklet-p-E.pdf ] Tactical Tech's Annual Report [ https://tacticaltech.org/media/news/annual-report-2017.pdf ] Assignments Due: 8/27 in-class : Code of Conduct Signed [Individual] 8/31 6:00PM: Secure Communications Established (with Reflection) [Individual] Monday 8/27 Lab: Citizen Clinic \u201cRules of the Road\u201d Citizen Clinic Code of Conduct. Personal Risk of Citizen Clinic. How to talk about Citizen Clinic. Ethical Considerations. Security Response Plan. Personal Communications setup and equipment issue. Wednesday 8/29 Lecture: Sean B & Steve T: \u201cThe need for public interest cybersecurity\u201d Week 2: Threat Landscape (Technical Theory Base) Read: Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] Silver & Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ] (Optional) Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Optional) Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] Assignments Due: 9/7 6:00PM: Collaborative Plan [Team] 9/9 11:59PM: 9/12 11:59PM: Secure-a-Friend Reflection [Individual] Monday 9/3: Academic and Administrative Holiday (Labor Day) Wednesday 9/5 Lecture: Bill Marczak \u201cThe vulnerabilities of cyberspace\u201d Week 3: Challenges to Securing Politically-Vulnerable Organizations Read: CIPESA. \u201cSafeguarding Civil Society: Assessing Internet Freedom and the Digital Resilience of Civil Society in East Africa\u201d - Read each chapter, but for one country only. [ https://cipesa.org/?wpfb_dl=237 ] Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] Alma Whitten and Doug Tygar. \u201cWhy Johnny Can\u2019t Encrypt\u201d [ https://www.usenix.org/legacy/publications/library/proceedings/sec99/full_papers/whitten/whitten_html/index.html ] Scott, James C. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ] Assignments Due: 9/10 11:59PM : Client Communications Instructions (for Review) [Team] 9/12 11:59PM: (Moved from Week 2) Secure-a-Friend Reflection [Individual] 9/20 (Target) : Communication Established with Client [Team] 9/16 11:59PM: Personal Threat Model [Individual] TBD Monday 9/10: Lab: Threat modelling. Establishing communications with clients. Conducting interviews. Wednesday 9/12 Lecture: Steve Weber \u201cChanging behaviors within PVOs\u201d Week 4: Contextual Assessments for Cybersecurity Read: SAFETAG Guide. Read pages 1 - 31, skim rest. [ github.com/SAFETAG/SAFETAG/files/1278308/SAFETAG-FullGuide_Sep2017.pdf ] NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf ] NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf ] NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf ] Fong, Rowland, Trush. \u201cA CRIMSon Tide of Data: An Assessment of Potential Privacy Problems of the Consolidate Records Information Management System\u201d [ http://people.ischool.berkeley.edu/~strush/CRIMS_FongRowlandTrush_Feb2018.pdf ] About PESTLE. [ http://guides.ucf.edu/industryanalysis/PESTLE ] Assignments Due: 9/20 (Target) Continued : Communication Established with Client [Team] Monday 9/17: Lab Open Source Research methods and tools. Environmental factors frameworks (PESTLE-M, PMESII). Wednesday 9/19 Lecture: Sean Brooks: \u201cBounding risk assessments\u201d Week 5: Conducting Technical Assessments Read: Marczak and John Scott-Railton. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] Micah Lee. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] Explore Mitre\u2019s PRE-ATT&CK Techniques. [ https://attack.mitre.org/techniques/pre/ ] Explore Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/wiki/Main_Page ] Use Mitre\u2019s Common Vulnerabilities and Exposures search. [ https://cve.mitre.org/cve/ ]. Additional readings as specified by guest Assignments Due: 9/24 2:00PM : 1st Contextual Research Briefs [Individual] 9/26 2:00PM : Threat Model Reflection [Individual - Mini Assignment] 9/26 11:59PM : Initial Work Plan (for Teaching Team Review) [Team] 9/28 6:00PM : Work Plan To Client [Team] Monday 9/24 Lab: Conducting interviews. Surveys / Device inventories. Wednesday 9/26 Lecture: Eva Galperin, Director of Cybersecurity, EFF \u201cBeing a good security educator / trainer\u201d Week 6: Establishing Baseline Digital Security (Part 1) Read: Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] Musiani & Ermoshina. \u201cWhat is a Good Secure Messaging Tool? The EFF Secure Messaging Scorecard and the Shaping of Digital (Usable) Security\u201d [ https://www.westminsterpapers.org/articles/10.16997/wpcc.265/ ] Use Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] Explore EFF\u2019s Surveillance Self-Defense guide. [ https://ssd.eff.org/ ] Additional readings as specified by guest. Assignments Due: 10/1 2:00PM 2nd Contextual Research Briefs [Individual] Monday 10/1: Lab Technical assessments. Tool Evaluation. Wednesday 10/3 Guest Lecture: Bill Marczak \u201cTechnical investigations and techniques\u201d Week 7: Establishing Baseline Digital Security (Part 2) Read: Additional readings as specified by guest Assignments Due: 10/14 11:59PM : Phishing Templates [Individual] TBD: Home Router Assessment [Individual] TBD: Community Clinic Reflection [Individual] Monday 10/8 Lab: Recommendations Guides: Password manager, device security. Phishing training. (Potential move) Community Clinic: an event for assessing & securing local high-risk organization members Wednesday 10/10 Lecture: F\u00e9lim McMahon, Technology Director, Human Rights Center \u201cDeploying security controls in high-risk environments\u201d Week 8: Monday 10/15: Clinic Core Hours \u201cClinic Core Hours\u201d refers to the required student attendance of official class meeting hours between 2PM and 4PM that will be reserved for instruction specific to client needs, feedback and guidance from the teaching team, and potential guest lectures. Wednesday 10/17: Clinic Core Hours Week 9: Assignments Due: 10/29 11:59PM: Community Clinic Reflection [Individual] Monday 10/22 : Clinic Core Hours Wednesday 10/24 : Clinic Core Hours Thursday 10/25, 4:50 - 7:00PM: Digital Security Crash Course, UC Berkeley, South Hall Room 210 Week 10: Assignments Due: 10/31 11:59PM: Team Midterm Progress Report [Team] 10/31 11:59PM: Team Evaluation 1 [Individual] Monday 10/29: Clinic Core Hours Wednesday 10/31: Clinic Core Hours Week 11: Monday 11/5: Clinic Core Hours Wednesday 11/7: Clinic Core Hours Week 12: Monday 11/12: Academic and Administrative Holiday (Labor Day) Wednesday 11/14: Clinic Core Hours Week 13: Thanksgiving Week Monday 11/19: Clinic Core Hours Wednesday 11/21: Academic and Administrative Holiday (Thanksgiving Eve) Week 14: Assignments Due: 11/28 11:59PM: Final Client Report (for Teaching Team Review) [Team] Monday 11/26: Clinic Core Hours Wednesday 11/28: Clinic Core Hours Week 15 (RRR): Wrap-up & Project Presentations Assignments Due: 12/3 6:00PM: Final Client Report (to Client) [Team] 12/4 11:59PM : Project Presentations [Team] 12/9 11:59PM: Final Individual Write-up [Individual] 12/9 11:59PM: Team Evaluation 2 [Individual] Monday 12/3 - Course Wrap-up: Feedback on deliverables, submit all final deliverables, turn-in all equipment. Wednesday 12/5 - Project Presentations: An overview of client work, findings, recommendations delivered to CLTC and stakeholders. Course policies Workload. This is a 4-unit class. Coursework will primarily focus on client-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the client. Evaluation. Assignments will largely be evaluated on the following rubric that emphasizes (1) sound rationale in assessments, recommendations, and reflections, (2) \u201cclient-ready\u201d work products which reflect professional quality, and (3) completing the instructions of the assignment or the requirements agreed upon work plan with the client. General Grading Rubric Component 0 points 5 points 10 points Rationale Does not meet client needs, introduces serious harms to client, shows limited or inappropriate consideration for context Addresses most of client needs, some oversight of potential harms to client, mostly appropriate for given context. All client needs are met, feasible & effective rationale that addresses all major threats, appropriate for given context. Professionalism Hard to understand, full of jargon, serious writing/format errors present Writing is mostly understandable; minor writing/format errors (typos) \u201cClient-ready,\u201d clear and concise writing, almost no writing/formatting errors Requirements Some requirements in assignment or work plan not met; no insights or connections to readings/lectures; for group work: no evidence of group work Most requirements met, some evidence for connections with readings/lectures; for group work: some evidence of group work All requirements met, with clear, thoughtful insights and multiple cited connections to relevant readings/lectures; for group work: full evidence of strong, equitable collaboration Note: Students taking the course for P/NP or S/U are expected to participate in classes and complete all work to the same level of quality as students taking the course for a letter grade. Assignments. 1. Client Deliverables - 50% The largest portion of graded evaluation will be based upon your team\u2019s work and support for its assigned client. These deliverables may include assessments, recommendations, and guides, each tailored towards the client\u2019s needs. Each team will also deliver a final report summarizing work performed with their client. 2. Individual Assignments - 20% A small number of individual assignments will be given, mostly within the first half of the course. 3. Final Individual Write-Up - 10% We want students to be able to discuss and share their experience in the course with others, including future employers. We also want our clients to remain confidential and protected. This being said, each student will submit a write-up of work performed and takeaways with sensitive information removed. The teaching team will review to ensure your experience is captured in an effective & safe manner. 4. Participation - 10% You are expected to attend each official class meeting and contribute substantially to class discussions. While you may not be able to attend every team meeting and client engagement outside of normal class hours, you are expected to attend and contribute to your team\u2019s effort as often as possible. 5. Team Evaluations - 10% If there are difficulties with any team member, discuss the matter within your team and seek resolution. If you cannot resolve the problem, immediately contact any faculty member, so that we can make an appointment to discuss the situation individually or with the entire group as needed. Throughout the course, you will submit confidential evaluation forms which ask you to evaluate the contributions of each team member including yourself. Your final course grade will be adjusted, higher or lower, if you are contributing more or less than those within your group. Late assignments. As we want to respect the time of our clients and ensure a high level of quality control (the teaching team will review deliverables before it reaches the client), we expect students to adhere to timelines and due dates. Each day an assignment is late will result in a letter grade deduction. Recognizing that emergencies arise and clients may require schedule adjustments, exceptions will be made on a case-by-case basis. Code of Conduct. Each student enrolled in the course must agree in writing to the Citizen Clinic\u2019s Code of Conduct (to be distributed) for maintaining a safe and secure learning experience and client relationship. This Code of Conduct will be respected by all students, the teaching team, and CLTC staff and it is the responsibility of all personnel to report possible violations of the Code of Conduct to the teaching team. Additionally, we expect all students to abide by the Berkeley Student Code of Conduct (see https://sa.berkeley.edu/student-code-of-conduct ) and act with honesty, integrity, and respect for others. (See also https://diversity.berkeley.edu/principles-community ). The consequences for failing to act within these standards may include failing an assignment, a referral to the Center for Student Conduct and Community Standards, a failed grade in the course, and even immediate expulsion. A note on plagiarism: even in the scope of providing a client with a walkthrough for securing a certain account or system, you are expected not to copy material from another guide, website, article or book (word-for-word or paraphrased) without citing the source - it\u2019s a small community and we should give credit where it is due. Other examples of unacceptable conduct include turning in deliverables created by students not currently in the course, work found on the Internet, or created by a commercial service. Disability Accommodation . If you need disability-related accommodations in this class, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please inform us as soon as possible.","title":"Fall 2018"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-0-introduction","text":"Read: Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] Sean Brooks \u201cDefending Politically Vulnerable Organizations Online\u201d [ https://cltc.berkeley.edu/wp-content/uploads/2018/07/CLTC_Defending_PVOs.pdf ] Assignments Due: 8/22 11:59PM : Submit application materials to enroll in this course. You will be notified of your enrollment status prior to the next class meeting on August 27th. Wednesday 8/22 [South Hall Room 107] : We will introduce the content and methods of the course, answer your questions, and everyone will introduce themselves to one another.","title":"Week 0: Introduction"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-1-what-is-public-interest-cybersecurity","text":"Read: Jorge Luis Sierra \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://ijnet.org/en/content/digital-and-mobile-security-mexican-journalists-and-bloggers ] Netgain \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] Citizen Lab\u2019s \u201cAbout Us\u201d Paper. [ https://citizenlab.ca/wp-content/uploads/2018/05/18033-Citizen-Lab-booklet-p-E.pdf ] Tactical Tech's Annual Report [ https://tacticaltech.org/media/news/annual-report-2017.pdf ] Assignments Due: 8/27 in-class : Code of Conduct Signed [Individual] 8/31 6:00PM: Secure Communications Established (with Reflection) [Individual] Monday 8/27 Lab: Citizen Clinic \u201cRules of the Road\u201d Citizen Clinic Code of Conduct. Personal Risk of Citizen Clinic. How to talk about Citizen Clinic. Ethical Considerations. Security Response Plan. Personal Communications setup and equipment issue. Wednesday 8/29 Lecture: Sean B & Steve T: \u201cThe need for public interest cybersecurity\u201d","title":"Week 1: What is Public-Interest Cybersecurity?"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-2-threat-landscape-technical-theory-base","text":"Read: Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] Silver & Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ] (Optional) Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Optional) Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] Assignments Due: 9/7 6:00PM: Collaborative Plan [Team] 9/9 11:59PM: 9/12 11:59PM: Secure-a-Friend Reflection [Individual] Monday 9/3: Academic and Administrative Holiday (Labor Day) Wednesday 9/5 Lecture: Bill Marczak \u201cThe vulnerabilities of cyberspace\u201d","title":"Week 2: Threat Landscape (Technical Theory Base)"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-3-challenges-to-securing-politically-vulnerable-organizations","text":"Read: CIPESA. \u201cSafeguarding Civil Society: Assessing Internet Freedom and the Digital Resilience of Civil Society in East Africa\u201d - Read each chapter, but for one country only. [ https://cipesa.org/?wpfb_dl=237 ] Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] Alma Whitten and Doug Tygar. \u201cWhy Johnny Can\u2019t Encrypt\u201d [ https://www.usenix.org/legacy/publications/library/proceedings/sec99/full_papers/whitten/whitten_html/index.html ] Scott, James C. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ] Assignments Due: 9/10 11:59PM : Client Communications Instructions (for Review) [Team] 9/12 11:59PM: (Moved from Week 2) Secure-a-Friend Reflection [Individual] 9/20 (Target) : Communication Established with Client [Team] 9/16 11:59PM: Personal Threat Model [Individual] TBD Monday 9/10: Lab: Threat modelling. Establishing communications with clients. Conducting interviews. Wednesday 9/12 Lecture: Steve Weber \u201cChanging behaviors within PVOs\u201d","title":"Week 3: Challenges to Securing Politically-Vulnerable Organizations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-4-contextual-assessments-for-cybersecurity","text":"Read: SAFETAG Guide. Read pages 1 - 31, skim rest. [ github.com/SAFETAG/SAFETAG/files/1278308/SAFETAG-FullGuide_Sep2017.pdf ] NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf ] NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf ] NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf ] Fong, Rowland, Trush. \u201cA CRIMSon Tide of Data: An Assessment of Potential Privacy Problems of the Consolidate Records Information Management System\u201d [ http://people.ischool.berkeley.edu/~strush/CRIMS_FongRowlandTrush_Feb2018.pdf ] About PESTLE. [ http://guides.ucf.edu/industryanalysis/PESTLE ] Assignments Due: 9/20 (Target) Continued : Communication Established with Client [Team] Monday 9/17: Lab Open Source Research methods and tools. Environmental factors frameworks (PESTLE-M, PMESII). Wednesday 9/19 Lecture: Sean Brooks: \u201cBounding risk assessments\u201d","title":"Week 4: Contextual Assessments for Cybersecurity"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-5-conducting-technical-assessments","text":"Read: Marczak and John Scott-Railton. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] Micah Lee. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] Explore Mitre\u2019s PRE-ATT&CK Techniques. [ https://attack.mitre.org/techniques/pre/ ] Explore Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/wiki/Main_Page ] Use Mitre\u2019s Common Vulnerabilities and Exposures search. [ https://cve.mitre.org/cve/ ]. Additional readings as specified by guest Assignments Due: 9/24 2:00PM : 1st Contextual Research Briefs [Individual] 9/26 2:00PM : Threat Model Reflection [Individual - Mini Assignment] 9/26 11:59PM : Initial Work Plan (for Teaching Team Review) [Team] 9/28 6:00PM : Work Plan To Client [Team] Monday 9/24 Lab: Conducting interviews. Surveys / Device inventories. Wednesday 9/26 Lecture: Eva Galperin, Director of Cybersecurity, EFF \u201cBeing a good security educator / trainer\u201d","title":"Week 5: Conducting Technical Assessments"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-6-establishing-baseline-digital-security-part-1","text":"Read: Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] Musiani & Ermoshina. \u201cWhat is a Good Secure Messaging Tool? The EFF Secure Messaging Scorecard and the Shaping of Digital (Usable) Security\u201d [ https://www.westminsterpapers.org/articles/10.16997/wpcc.265/ ] Use Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] Explore EFF\u2019s Surveillance Self-Defense guide. [ https://ssd.eff.org/ ] Additional readings as specified by guest. Assignments Due: 10/1 2:00PM 2nd Contextual Research Briefs [Individual] Monday 10/1: Lab Technical assessments. Tool Evaluation. Wednesday 10/3 Guest Lecture: Bill Marczak \u201cTechnical investigations and techniques\u201d","title":"Week 6: Establishing Baseline Digital Security (Part 1)"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-7-establishing-baseline-digital-security-part-2","text":"Read: Additional readings as specified by guest Assignments Due: 10/14 11:59PM : Phishing Templates [Individual] TBD: Home Router Assessment [Individual] TBD: Community Clinic Reflection [Individual] Monday 10/8 Lab: Recommendations Guides: Password manager, device security. Phishing training. (Potential move) Community Clinic: an event for assessing & securing local high-risk organization members Wednesday 10/10 Lecture: F\u00e9lim McMahon, Technology Director, Human Rights Center \u201cDeploying security controls in high-risk environments\u201d","title":"Week 7: Establishing Baseline Digital Security (Part 2)"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-8","text":"Monday 10/15: Clinic Core Hours \u201cClinic Core Hours\u201d refers to the required student attendance of official class meeting hours between 2PM and 4PM that will be reserved for instruction specific to client needs, feedback and guidance from the teaching team, and potential guest lectures. Wednesday 10/17: Clinic Core Hours","title":"Week 8:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-9","text":"Assignments Due: 10/29 11:59PM: Community Clinic Reflection [Individual] Monday 10/22 : Clinic Core Hours Wednesday 10/24 : Clinic Core Hours Thursday 10/25, 4:50 - 7:00PM: Digital Security Crash Course, UC Berkeley, South Hall Room 210","title":"Week 9:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-10","text":"Assignments Due: 10/31 11:59PM: Team Midterm Progress Report [Team] 10/31 11:59PM: Team Evaluation 1 [Individual] Monday 10/29: Clinic Core Hours Wednesday 10/31: Clinic Core Hours","title":"Week 10:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-11","text":"Monday 11/5: Clinic Core Hours Wednesday 11/7: Clinic Core Hours","title":"Week 11:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-12","text":"Monday 11/12: Academic and Administrative Holiday (Labor Day) Wednesday 11/14: Clinic Core Hours","title":"Week 12:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-13-thanksgiving-week","text":"Monday 11/19: Clinic Core Hours Wednesday 11/21: Academic and Administrative Holiday (Thanksgiving Eve)","title":"Week 13: Thanksgiving Week"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-14","text":"Assignments Due: 11/28 11:59PM: Final Client Report (for Teaching Team Review) [Team] Monday 11/26: Clinic Core Hours Wednesday 11/28: Clinic Core Hours","title":"Week 14:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#week-15-rrr-wrap-up-project-presentations","text":"Assignments Due: 12/3 6:00PM: Final Client Report (to Client) [Team] 12/4 11:59PM : Project Presentations [Team] 12/9 11:59PM: Final Individual Write-up [Individual] 12/9 11:59PM: Team Evaluation 2 [Individual] Monday 12/3 - Course Wrap-up: Feedback on deliverables, submit all final deliverables, turn-in all equipment. Wednesday 12/5 - Project Presentations: An overview of client work, findings, recommendations delivered to CLTC and stakeholders.","title":"Week 15 (RRR): Wrap-up &amp; Project Presentations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2018/#course-policies","text":"Workload. This is a 4-unit class. Coursework will primarily focus on client-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the client. Evaluation. Assignments will largely be evaluated on the following rubric that emphasizes (1) sound rationale in assessments, recommendations, and reflections, (2) \u201cclient-ready\u201d work products which reflect professional quality, and (3) completing the instructions of the assignment or the requirements agreed upon work plan with the client. General Grading Rubric Component 0 points 5 points 10 points Rationale Does not meet client needs, introduces serious harms to client, shows limited or inappropriate consideration for context Addresses most of client needs, some oversight of potential harms to client, mostly appropriate for given context. All client needs are met, feasible & effective rationale that addresses all major threats, appropriate for given context. Professionalism Hard to understand, full of jargon, serious writing/format errors present Writing is mostly understandable; minor writing/format errors (typos) \u201cClient-ready,\u201d clear and concise writing, almost no writing/formatting errors Requirements Some requirements in assignment or work plan not met; no insights or connections to readings/lectures; for group work: no evidence of group work Most requirements met, some evidence for connections with readings/lectures; for group work: some evidence of group work All requirements met, with clear, thoughtful insights and multiple cited connections to relevant readings/lectures; for group work: full evidence of strong, equitable collaboration Note: Students taking the course for P/NP or S/U are expected to participate in classes and complete all work to the same level of quality as students taking the course for a letter grade. Assignments. 1. Client Deliverables - 50% The largest portion of graded evaluation will be based upon your team\u2019s work and support for its assigned client. These deliverables may include assessments, recommendations, and guides, each tailored towards the client\u2019s needs. Each team will also deliver a final report summarizing work performed with their client. 2. Individual Assignments - 20% A small number of individual assignments will be given, mostly within the first half of the course. 3. Final Individual Write-Up - 10% We want students to be able to discuss and share their experience in the course with others, including future employers. We also want our clients to remain confidential and protected. This being said, each student will submit a write-up of work performed and takeaways with sensitive information removed. The teaching team will review to ensure your experience is captured in an effective & safe manner. 4. Participation - 10% You are expected to attend each official class meeting and contribute substantially to class discussions. While you may not be able to attend every team meeting and client engagement outside of normal class hours, you are expected to attend and contribute to your team\u2019s effort as often as possible. 5. Team Evaluations - 10% If there are difficulties with any team member, discuss the matter within your team and seek resolution. If you cannot resolve the problem, immediately contact any faculty member, so that we can make an appointment to discuss the situation individually or with the entire group as needed. Throughout the course, you will submit confidential evaluation forms which ask you to evaluate the contributions of each team member including yourself. Your final course grade will be adjusted, higher or lower, if you are contributing more or less than those within your group. Late assignments. As we want to respect the time of our clients and ensure a high level of quality control (the teaching team will review deliverables before it reaches the client), we expect students to adhere to timelines and due dates. Each day an assignment is late will result in a letter grade deduction. Recognizing that emergencies arise and clients may require schedule adjustments, exceptions will be made on a case-by-case basis. Code of Conduct. Each student enrolled in the course must agree in writing to the Citizen Clinic\u2019s Code of Conduct (to be distributed) for maintaining a safe and secure learning experience and client relationship. This Code of Conduct will be respected by all students, the teaching team, and CLTC staff and it is the responsibility of all personnel to report possible violations of the Code of Conduct to the teaching team. Additionally, we expect all students to abide by the Berkeley Student Code of Conduct (see https://sa.berkeley.edu/student-code-of-conduct ) and act with honesty, integrity, and respect for others. (See also https://diversity.berkeley.edu/principles-community ). The consequences for failing to act within these standards may include failing an assignment, a referral to the Center for Student Conduct and Community Standards, a failed grade in the course, and even immediate expulsion. A note on plagiarism: even in the scope of providing a client with a walkthrough for securing a certain account or system, you are expected not to copy material from another guide, website, article or book (word-for-word or paraphrased) without citing the source - it\u2019s a small community and we should give credit where it is due. Other examples of unacceptable conduct include turning in deliverables created by students not currently in the course, work found on the Internet, or created by a commercial service. Disability Accommodation . If you need disability-related accommodations in this class, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please inform us as soon as possible.","title":"Course policies"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/","text":"New in Fall 2019! Nominated student discussion leaders. Added phishing simulation training. Added student-led Community Office Hours Added Resiliency module. Added elements of SCU's Internet Ethics's Cybersecurity Ethics Module. Info 289. Public Interest Cybersecurity: The Citizen Clinic Practicum. Fall 2019. Course Description. For individuals and organizations involved in political advocacy, cybersecurity threats are an increasingly common reality of operating in the digital world. Civil society has always been under attack from ideological, political, and governmental opponents who seek to silence dissenting opinions, but the widespread adoption of connected technologies by the individuals and organizations that make up civil society creates a new class of vulnerabilities. Citizen Clinic at the Center for Long-Term Cybersecurity provides students with real-world experience assisting politically vulnerable organizations and persons around the world to develop and implement sound cybersecurity practices. Clinic students will participate in both a classroom and clinic component. In the classroom, students will study the basic theories and practices of digital security, the intricacies of protecting largely under-resourced organizations, and the tools needed to manage risk in complex political, sociological, legal, and ethical contexts. In the clinic component, students will work in teams supervised by the Clinic staff to provide direct cybersecurity assistance to civil society organizations. Students\u2019 clinic responsibilities will include learning about an organization\u2019s mission and context, assessing its vulnerabilities, and ultimately recommending and implementing mitigations to the identified security risks. The emphasis will be on pragmatic, workable solutions that take into account the unique operational needs of each partner organization.Weekly lectures will provide students with the background information and tools they will need to engage with partners. Coursework will focus on partner-facing, hands-on projects. Students will be expected to work an average of 12 hours per week, although the distribution of this workload may fluctuate based upon the availability and needs of the partner. Schedule. In the first half of the semester, class meetings will be a mix of lectures & discussions with more technical & project-oriented labs. In the second half of the semester, these class times will be reserved for work with the teaching team and check-ins tailored to the specific needs of your partner organization. Note: This schedule is tentative and may be adjusted - assignment dates may change, additional readings may be assigned, speakers/lectures may be shuffled, etc. The teaching team will announce when changes are made. Week 1: Introduction / What is Public-Interest Cybersecurity? Wednesday 8/28: Introduction to Public Interest Cybersecurity: We will introduce the content and methods of the course, answer your questions, and everyone will introduce themselves to one another. Assignments: Due Friday 8/30 11:59PM: Submit application materials to enroll in this course. You will be notified of your enrollment status prior to the next class meeting on September 4th. Due Wednesday 9/4 before class: Read pages 7 - 21 & 48 - 52 of \u201cAn Introduction to Cybersecurity Ethics\u201d (Shannon Vallor, The Markkula Center for Applied Ethics) [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Prepare answers to questions on pages 15 - 17 and page 53 for in-class discussion. Read (by end of week): Shannon Vallor, The Markkula Center for Applied Ethics, \u201cAn Introduction to Cybersecurity Ethics\u201d pages 7 - 21 & 48 - 52. [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] Netgain \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] Sean Brooks \u201cDefending Politically Vulnerable Organizations Online\u201d [ https://cltc.berkeley.edu/wp-content/uploads/2018/07/CLTC_Defending_PVOs.pdf ] (Skim) Citizen Lab\u2019s \u201cAbout Us\u201d Paper. [ https://citizenlab.ca/wp-content/uploads/2018/05/18033-Citizen-Lab-booklet-p-E.pdf ] (Skim) Tactical Tech's Annual Report [ https://cdn.ttc.io/s/tacticaltech.org/Tactical-Tech-2018-Annual-Report.pdf ] Week 2: Code of Conduct and Ethics in Cybersecurity Monday 9/2: No class. Wednesday 9/4: Ethics and \u201cRules of the Road\u201d: Citizen Clinic Code of Conduct. Ethical Considerations. Security Response Plan. Partner Overview Personal Communications setup and equipment issue Assignments: Due 9/4 before class: Prepare answers to questions on pages 15 - 17 and page 53 of \u201cIntro to Cybersecurity Ethics\u201d for in-class discussion. [Individual] Due 9/4 In-Class: Code of Conduct Signed [Individual] Read (by end of week): (Watch) CLTC / TechSoup. Webinar. \u201cCybersecurity in Low-Risk Organizations: Understanding Your Risk and Making Practical Improvements.\u201d linked here: [ https://cltc.berkeley.edu/2019/02/25/cltc-and-citizen-clinic-present-cybersecurity-in-low-risk-organizations-webinar/ ] Jorge Luis Sierra \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://freedomhouse.org/sites/default/files/Digital%20and%20Mobile%20Security%20for%20Mexican%20Journalists%20and%20Bloggers.pdf ] Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] Arthur Turner. \u201cConsulting Is More Than Giving Advice.\u201d [ https://hbr.org/1982/09/consulting-is-more-than-giving-advice ] (Optional) Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] (Optional) Rus Shuler. \u201cHow Does the Internet Work?\u201d [ web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm ] Week 3: Integrating Outside Expertise within Civil Society Organizations Monday 9/9: Problem diagnosis and reframing - Deloitte Wednesday 9/11: Strategies for effective meetings - PWC Assignments: Due 9/8 11:59PM: Equipment Setup & Partner Preference Submitted [Individual] Due 9/15 11:59PM: Collaborative Plan [Team] Due 9/13 6:00PM : Partner Communications Established [Team] Read (by end of week): Electronic Frontier Foundation, \u201cSurveillance Self-Defense: Your Security Plan\u201d [ https://ssd.eff.org/en/playlist/activist-or-protester#your-security-plan ] - know the definitions of underlined terms. Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Silver & Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] (Explore) MSFT\u2019s STRIDE and related blog posts. [ https://cloudblogs.microsoft.com/microsoftsecure/2007/09/11/stride-chart/ ] (Optional) Joseph Cox. \u201cI Gave a Bounty Hunter $300. Then He Located Our Phone\u201d [ https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile ] (Optional) Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ] Week 4: Understanding Threats to Civil Society Organizations Monday 9/16: Threat Modeling & Bounding Risk Assessments Wednesday 9/18: Bill Marczak, \u201cDigital Surveillance of PVOs - The Threat Landscape\u201d Read (by end of week): Amnesty International. \u201cDigitally dissecting atrocities \u2013 Amnesty International\u2019s open source investigations.\u201d [ https://www.amnesty.org/en/latest/news/2018/09/digitally-dissecting-atrocities-amnesty-internationals-open-source-investigations/ ] Protective Intelligence. \u201cPart I: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt1 ] Protective Intelligence. \u201cPart 2: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt2 ] Ian Barwise. \u201cOpen-Source Intelligence (OSINT) Reconnaissance\u201d [ https://medium.com/@z3roTrust/open-source-intelligence-osint-reconnaissance-75edd7f7dada ] (Explore) About PESTLE. [ http://guides.ucf.edu/industryanalysis/PESTLE ] (Explore) OSINT Framework [ https://osintframework.com/ ] (Explore) OSINT.link [ https://osint.link ] Week 5: Contextual Research and OSINT Collection Monday 9/23: Contextual Factors and Frameworks SAFETAG PESTLE-M PMESII Wednesday 9/25: Open Source Research Methods, Safety, and Tools Burner Profiles w/ Raj Read (by end of week): Example Risk Assessment shared via email. * SAFETAG Guide. Read to Section 4.4, skim rest. [ https://safetag.org/guide/ read to Section 4.4] Julian Cohen. \u201cPlaybook Based Testing.\u201d [ https://medium.com/@HockeyInJune/playbook-based-testing-5df4b656113a ] NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf or Shutdown Mirror ] (Skim) NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf or Shutdown Mirror ] (Skim) NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf or Shutdown Mirror ] Week 6: Threat Scenario Development Monday 9/30: Adversary Persona Development Wednesday 10/2: Threat Scenario Development \u201cHow to Hack\u201d: Capture the Flag Activity Read (by end of week): Engine Room. \u201cTies That Bind: Organisational Security for Civil Society\u201d - read Full Report. [ https://www.theengineroom.org/civil-society-digital-security-new-research/ ] APF et al. \u201cImproving SSL Warnings: Comprehension and Adherence\u201d [ https://dl.acm.org/citation.cfm?id=2702442 ] Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] (Watch) Rachel Tobac. \u201cHow I would Hack You: Social Engineering Step-by-Step\u201d [ https://www.youtube.com/watch?v=L5J2PgGOLtE ] (Optional) Scott, James C. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ] Week 7: Changing Security Behaviors Monday 10/7: Phishing from Context; Phishing Simulators (Raj) Wednesday 10/9: Steve Weber, \u201cChanging Behaviors within PVOs\u201d (Cancelled to Power Outage) Assignments: Due 10/11 6:00PM Draft Work Plan and Partner Report [Team] Due 10/13 11:59PM Team Evaluation 1 [Individual] Read (by end of week): Bill Marczak and John Scott-Railton. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] Micah Lee. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] (Explore) Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/wiki/Main_Page ] Week 8: Threat Tactics and Techniques Monday, 10/14: Bill Marczak, \u201cTechnical Investigations and Techniques\u201d Wednesday, 10/16: Midterm Project Presentations Assignments: 10/18 6:00 PM: Work Plan and Partner Report to Partner [Team] 10/20 11:59 PM: Phishing Simulation Plan and Test Read (by end of week): IFTF \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51.[ http://www.iftf.org/statesponsoredtrolling ] Cindy Otis. USA Today. \u201cAmericans could be a bigger fake news threat than Russians in the 2020 presidential campaign\u201d [ https://www.usatoday.com/story/opinion/2019/07/19/disinformation-attacks-americans-threaten-2020-election-column/1756092001/ ] Sarah Jeong, Charlie Warzel, Brianna Wu, Joan Donovan. New York Times. \u201cEverything is GamerGate\u201d [ https://www.nytimes.com/interactive/2019/08/15/opinion/gamergate-twitter.html ] - Read all of the four essays. InterAction \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Optional) Tahmina Ansari. First Draft. \u201cThis Muslim journalist embraced social media until it \u2018ruined\u2019 his life\u201d [ https://firstdraftnews.org/this-muslim-journalist-embraced-social-media-until-it-ruined-his-life/ ] Week 9: Beyond Hacking -- Disinformation and Harassment Monday, 10/21: Organizational Risks of Harmful Information Wednesday, 10/23: Mitigations for the Risks of Harmful Information Read (by end of week): Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] EFF. \u201cAm I the Right Person?\u201d [https://sec.eff.org/articles/right-person-to-train] EFF. \u201cHow to Teach Adults\u201d [ https://sec.eff.org/articles/how-to-teach-adults ] (Skim) Weidinger et al. \u201cDigital Security Training Resources for Security Trainers, Fall 2019 Edition\u201d [ https://medium.com/cryptofriends/digital-security-training-resources-for-security-trainers-spring-2017-edition-e95d9e50065e ] (Explore) Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] (Explore) The rest of EFF\u2019s Security Education Companion.[ https://sec.eff.org/ ] (Explore) Mitre\u2019s Common Vulnerabilities and Exposures search. [ https://cve.mitre.org/cve/ ] Week 10: Security Control Selection Monday, 10/28: Studying and Evaluating Security Tools Wednesday, 10/30: \u201cBeing a Good Security Educator\u201d (Cancelled due to Power Outage) Read (by end of week): Angela Chen. The Verge. \u201cModerating content doesn\u2019t have to be so traumatic\u201d [ https://www.theverge.com/2019/2/27/18243359/content-moderation-mental-health-ptsd-psychology-science-facebook ] Sam Dubberley & Michele Grant. First Draft. \u201cJournalism and Vicarious Trauma\u201d [ https://firstdraftnews.org/wp-content/uploads/2017/04/vicarioustrauma.pdf ] Week 11: Additional Topics Monday, 11/4: Clinic Core Hours \u201cClinic Core Hours\u201d refers to the required student attendance of official class meeting hours between 1:30PM and 3:30PM that will be reserved for instruction specific to partner needs, feedback and guidance from the teaching team, and ad-hoc lectures. Every Monday (unless there\u2019s a holiday), each team will have a 20-minute check-in with the teaching team. Each team member will provide a ~5 minute update on the progress of their assigned partner work. Wednesday, 11/6: Psychosocial Resiliency & Trauma, Andrea Lampros & Gisela Perez de Acha Assignments: * 11/5 11:59PM: Phishing / OSINT Analysis Report [Team] (Optional) Week 12: Clinic Work Monday, 11/11: No class. Wednesday, 11/13: Clinic Core Hours / Team Check-in Week 13: Clinic Work Monday, 11/18: Clinic Core Hours / Team Check-in Wednesday, 11/20: Clinic Core Hours Week 14: Clinic Work Monday, 11/25: Clinic Core Hours / Team Check-in Wednesday, 11/27: No Class Assignments: 12/1 11:59PM: Final Partner Report (for Teaching Team Review) [Team] Week 15: Clinic Work Monday, 12/2: Clinic Core Hours / Team Check-in Wednesday, 12/4: Clinic Core Hours / Final Report Feedback Week 16 (RRR): Wrap-up & Project Presentations Monday, 12/9 - Course Wrap-up: Feedback on deliverables, submit all final deliverables. Wednesday, 12/11 - Project Presentations: Assignments: 12/9 6:00PM: Final Partner Report (to Partner) [Team] 12/10 11:59PM: Project Presentations [Team] 12/15 11:59PM: Final Individual Write-up [Individual] 12/15 11:59PM: Team Evaluation 2 [Individual] Course policies Workload. This is a 4-unit class. Coursework will primarily focus on partner-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the partner. Evaluation. Assignments will largely be evaluated on the following rubric that emphasizes (1) sound rationale in assessments, recommendations, and reflections, (2) \u201cpartner-ready\u201d work products which reflect professional quality, and (3) completing the instructions of the assignment or the requirements agreed upon work plan with the partner. General Grading Rubric. Component 0 points 5 points 10 points Rationale Does not meet partner needs, introduces serious harms to partner, shows limited or inappropriate consideration for context Addresses most of partner needs, some oversight of potential harms to partner, mostly appropriate for given context. All partner needs are met, feasible & effective rationale that addresses all major threats, appropriate for given context. Professionalism Hard to understand, full of jargon, serious writing/format errors present, tone / design unsuitable for its audience Writing is mostly understandable; minor writing/format errors (typos), mostly appropriate tone / design \u201cpartner-ready,\u201d clear and concise writing, almost no writing/formatting errors, appropriate tone & design for its audience Requirements Some requirements in assignment or work plan not met; no insights or connections to readings/lectures; for group work: no evidence of group work Most requirements met, some evidence for connections with readings/lectures; for group work: some evidence of group work All requirements met, with clear, thoughtful insights and multiple cited connections to relevant readings/lectures; for group work: full evidence of strong, equitable collaboration Note: Students taking the course for P/NP or S/U are expected to participate in classes and complete all work to the same level of quality as students taking the course for a letter grade. Assignments. 1. Partner Deliverables - 60% The largest portion of graded evaluation will be based upon your team\u2019s work and support for its assigned partner. These deliverables may include assessments, recommendations, and guides, each tailored towards the partner\u2019s needs. Each team will also deliver a final report summarizing work performed with their partner. 2. Individual Assignments - 10% Two individual assignments will be given: Discussion Topic Leader (5%): Each student will sign up to be a discussion leader for select lectures. That student will be expected to generate interesting questions and guide class conversation around that week\u2019s assigned readings and lecture topic. You will also be expected to locate and share at least one news article about a recent, current event relevant to that discussion. Community Office Hours (5%): Students, in pairs, will sign up to hold a single two hour-block of \u201coffice hours\u201d to advise and assist the security practice of various cross-campus partners conducting politically-sensitive work. Those students will consider the partner\u2019s needs and threat model, make recommendations, and reachback for support as needed. 3. Final Individual Write-Up - 10% We want students to be able to discuss and share their experience in the course with others, including future employers. We also want our partners to remain confidential and protected. This being said, each student will submit a write-up of work performed and takeaways with sensitive information removed. The teaching team will review to ensure your experience is captured in an effective & safe manner. 4. Participation - 10% You are expected to attend each official class meeting and contribute substantially to class discussions. While you may not be able to attend every team meeting and partner engagement outside of normal class hours, you are expected to attend and contribute to your team\u2019s effort as often as possible. Absences from class meetings (including Clinic Core Hours) should be excused by the teaching team in advance. Not showing up to team check-ins will also negatively impact this grade. As a rule, two people from your team must attend any partner meeting or call. 5. Team Evaluations - 10% If there are difficulties with any team member, discuss the matter within your team and seek resolution. If you cannot resolve the problem, immediately contact any faculty member, so that we can make an appointment to discuss the situation individually or with the entire group as needed. Throughout the course, you will submit confidential evaluation forms which ask you to evaluate the contributions of each team member including yourself. Your final course grade will be adjusted, higher or lower, if you are contributing more or less than those within your group. Late assignments. As we want to respect the time of our partners and ensure a high level of quality control (the teaching team will review deliverables before it reaches the partner), we expect students to adhere to timelines and due dates. Each day an assignment is late will result in a letter grade deduction. Recognizing that emergencies arise and partners may require schedule adjustments, exceptions will be made on a case-by-case basis. Code of Conduct. Each student enrolled in the course must agree in writing to the Citizen Clinic\u2019s Code of Conduct (to be distributed) for maintaining a safe and secure learning experience and partner relationship. This Code of Conduct will be respected by all students, the teaching team, and CLTC staff and it is the responsibility of all personnel to report possible violations of the Code of Conduct to the teaching team. Additionally, we expect all students to abide by the Berkeley Student Code of Conduct (see https://sa.berkeley.edu/student-code-of-conduct ) and act with honesty, integrity, and respect for others. (See also https://diversity.berkeley.edu/principles-community ). The consequences for failing to act within these standards may include failing an assignment, a referral to the Center for Student Conduct and Community Standards, a failed grade in the course, and even immediate expulsion. A note on plagiarism: even in the scope of providing a partner with a walkthrough for securing a certain account or system, you are expected not to copy material from another guide, website, article or book (word-for-word or paraphrased) without citing the source - it\u2019s a small community and we should give credit where it is due. Other examples of unacceptable conduct include turning in deliverables created by students not currently in the course, work found on the Internet, or created by a commercial service. Disability Accommodation . If you need disability-related accommodations in this class, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please inform us as soon as possible.","title":"Fall 2019"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#course-description","text":"For individuals and organizations involved in political advocacy, cybersecurity threats are an increasingly common reality of operating in the digital world. Civil society has always been under attack from ideological, political, and governmental opponents who seek to silence dissenting opinions, but the widespread adoption of connected technologies by the individuals and organizations that make up civil society creates a new class of vulnerabilities. Citizen Clinic at the Center for Long-Term Cybersecurity provides students with real-world experience assisting politically vulnerable organizations and persons around the world to develop and implement sound cybersecurity practices. Clinic students will participate in both a classroom and clinic component. In the classroom, students will study the basic theories and practices of digital security, the intricacies of protecting largely under-resourced organizations, and the tools needed to manage risk in complex political, sociological, legal, and ethical contexts. In the clinic component, students will work in teams supervised by the Clinic staff to provide direct cybersecurity assistance to civil society organizations. Students\u2019 clinic responsibilities will include learning about an organization\u2019s mission and context, assessing its vulnerabilities, and ultimately recommending and implementing mitigations to the identified security risks. The emphasis will be on pragmatic, workable solutions that take into account the unique operational needs of each partner organization.Weekly lectures will provide students with the background information and tools they will need to engage with partners. Coursework will focus on partner-facing, hands-on projects. Students will be expected to work an average of 12 hours per week, although the distribution of this workload may fluctuate based upon the availability and needs of the partner. Schedule. In the first half of the semester, class meetings will be a mix of lectures & discussions with more technical & project-oriented labs. In the second half of the semester, these class times will be reserved for work with the teaching team and check-ins tailored to the specific needs of your partner organization. Note: This schedule is tentative and may be adjusted - assignment dates may change, additional readings may be assigned, speakers/lectures may be shuffled, etc. The teaching team will announce when changes are made.","title":"Course Description."},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-1-introduction-what-is-public-interest-cybersecurity","text":"Wednesday 8/28: Introduction to Public Interest Cybersecurity: We will introduce the content and methods of the course, answer your questions, and everyone will introduce themselves to one another. Assignments: Due Friday 8/30 11:59PM: Submit application materials to enroll in this course. You will be notified of your enrollment status prior to the next class meeting on September 4th. Due Wednesday 9/4 before class: Read pages 7 - 21 & 48 - 52 of \u201cAn Introduction to Cybersecurity Ethics\u201d (Shannon Vallor, The Markkula Center for Applied Ethics) [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Prepare answers to questions on pages 15 - 17 and page 53 for in-class discussion. Read (by end of week): Shannon Vallor, The Markkula Center for Applied Ethics, \u201cAn Introduction to Cybersecurity Ethics\u201d pages 7 - 21 & 48 - 52. [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] Netgain \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] Sean Brooks \u201cDefending Politically Vulnerable Organizations Online\u201d [ https://cltc.berkeley.edu/wp-content/uploads/2018/07/CLTC_Defending_PVOs.pdf ] (Skim) Citizen Lab\u2019s \u201cAbout Us\u201d Paper. [ https://citizenlab.ca/wp-content/uploads/2018/05/18033-Citizen-Lab-booklet-p-E.pdf ] (Skim) Tactical Tech's Annual Report [ https://cdn.ttc.io/s/tacticaltech.org/Tactical-Tech-2018-Annual-Report.pdf ]","title":"Week 1: Introduction / What is Public-Interest Cybersecurity?"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-2-code-of-conduct-and-ethics-in-cybersecurity","text":"Monday 9/2: No class. Wednesday 9/4: Ethics and \u201cRules of the Road\u201d: Citizen Clinic Code of Conduct. Ethical Considerations. Security Response Plan. Partner Overview Personal Communications setup and equipment issue Assignments: Due 9/4 before class: Prepare answers to questions on pages 15 - 17 and page 53 of \u201cIntro to Cybersecurity Ethics\u201d for in-class discussion. [Individual] Due 9/4 In-Class: Code of Conduct Signed [Individual] Read (by end of week): (Watch) CLTC / TechSoup. Webinar. \u201cCybersecurity in Low-Risk Organizations: Understanding Your Risk and Making Practical Improvements.\u201d linked here: [ https://cltc.berkeley.edu/2019/02/25/cltc-and-citizen-clinic-present-cybersecurity-in-low-risk-organizations-webinar/ ] Jorge Luis Sierra \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://freedomhouse.org/sites/default/files/Digital%20and%20Mobile%20Security%20for%20Mexican%20Journalists%20and%20Bloggers.pdf ] Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] Arthur Turner. \u201cConsulting Is More Than Giving Advice.\u201d [ https://hbr.org/1982/09/consulting-is-more-than-giving-advice ] (Optional) Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] (Optional) Rus Shuler. \u201cHow Does the Internet Work?\u201d [ web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm ]","title":"Week 2: Code of Conduct and Ethics in Cybersecurity"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-3-integrating-outside-expertise-within-civil-society-organizations","text":"Monday 9/9: Problem diagnosis and reframing - Deloitte Wednesday 9/11: Strategies for effective meetings - PWC Assignments: Due 9/8 11:59PM: Equipment Setup & Partner Preference Submitted [Individual] Due 9/15 11:59PM: Collaborative Plan [Team] Due 9/13 6:00PM : Partner Communications Established [Team] Read (by end of week): Electronic Frontier Foundation, \u201cSurveillance Self-Defense: Your Security Plan\u201d [ https://ssd.eff.org/en/playlist/activist-or-protester#your-security-plan ] - know the definitions of underlined terms. Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Silver & Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] (Explore) MSFT\u2019s STRIDE and related blog posts. [ https://cloudblogs.microsoft.com/microsoftsecure/2007/09/11/stride-chart/ ] (Optional) Joseph Cox. \u201cI Gave a Bounty Hunter $300. Then He Located Our Phone\u201d [ https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile ] (Optional) Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ]","title":"Week 3: Integrating Outside Expertise within Civil Society Organizations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-4-understanding-threats-to-civil-society-organizations","text":"Monday 9/16: Threat Modeling & Bounding Risk Assessments Wednesday 9/18: Bill Marczak, \u201cDigital Surveillance of PVOs - The Threat Landscape\u201d Read (by end of week): Amnesty International. \u201cDigitally dissecting atrocities \u2013 Amnesty International\u2019s open source investigations.\u201d [ https://www.amnesty.org/en/latest/news/2018/09/digitally-dissecting-atrocities-amnesty-internationals-open-source-investigations/ ] Protective Intelligence. \u201cPart I: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt1 ] Protective Intelligence. \u201cPart 2: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt2 ] Ian Barwise. \u201cOpen-Source Intelligence (OSINT) Reconnaissance\u201d [ https://medium.com/@z3roTrust/open-source-intelligence-osint-reconnaissance-75edd7f7dada ] (Explore) About PESTLE. [ http://guides.ucf.edu/industryanalysis/PESTLE ] (Explore) OSINT Framework [ https://osintframework.com/ ] (Explore) OSINT.link [ https://osint.link ]","title":"Week 4: Understanding Threats to Civil Society Organizations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-5-contextual-research-and-osint-collection","text":"Monday 9/23: Contextual Factors and Frameworks SAFETAG PESTLE-M PMESII Wednesday 9/25: Open Source Research Methods, Safety, and Tools Burner Profiles w/ Raj Read (by end of week): Example Risk Assessment shared via email. * SAFETAG Guide. Read to Section 4.4, skim rest. [ https://safetag.org/guide/ read to Section 4.4] Julian Cohen. \u201cPlaybook Based Testing.\u201d [ https://medium.com/@HockeyInJune/playbook-based-testing-5df4b656113a ] NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf or Shutdown Mirror ] (Skim) NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf or Shutdown Mirror ] (Skim) NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf or Shutdown Mirror ]","title":"Week 5: Contextual Research and OSINT Collection"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-6-threat-scenario-development","text":"Monday 9/30: Adversary Persona Development Wednesday 10/2: Threat Scenario Development \u201cHow to Hack\u201d: Capture the Flag Activity Read (by end of week): Engine Room. \u201cTies That Bind: Organisational Security for Civil Society\u201d - read Full Report. [ https://www.theengineroom.org/civil-society-digital-security-new-research/ ] APF et al. \u201cImproving SSL Warnings: Comprehension and Adherence\u201d [ https://dl.acm.org/citation.cfm?id=2702442 ] Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] (Watch) Rachel Tobac. \u201cHow I would Hack You: Social Engineering Step-by-Step\u201d [ https://www.youtube.com/watch?v=L5J2PgGOLtE ] (Optional) Scott, James C. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ]","title":"Week 6: Threat Scenario Development"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-7-changing-security-behaviors","text":"Monday 10/7: Phishing from Context; Phishing Simulators (Raj) Wednesday 10/9: Steve Weber, \u201cChanging Behaviors within PVOs\u201d (Cancelled to Power Outage) Assignments: Due 10/11 6:00PM Draft Work Plan and Partner Report [Team] Due 10/13 11:59PM Team Evaluation 1 [Individual] Read (by end of week): Bill Marczak and John Scott-Railton. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] Micah Lee. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] (Explore) Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/wiki/Main_Page ]","title":"Week 7: Changing Security Behaviors"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-8-threat-tactics-and-techniques","text":"Monday, 10/14: Bill Marczak, \u201cTechnical Investigations and Techniques\u201d Wednesday, 10/16: Midterm Project Presentations Assignments: 10/18 6:00 PM: Work Plan and Partner Report to Partner [Team] 10/20 11:59 PM: Phishing Simulation Plan and Test Read (by end of week): IFTF \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51.[ http://www.iftf.org/statesponsoredtrolling ] Cindy Otis. USA Today. \u201cAmericans could be a bigger fake news threat than Russians in the 2020 presidential campaign\u201d [ https://www.usatoday.com/story/opinion/2019/07/19/disinformation-attacks-americans-threaten-2020-election-column/1756092001/ ] Sarah Jeong, Charlie Warzel, Brianna Wu, Joan Donovan. New York Times. \u201cEverything is GamerGate\u201d [ https://www.nytimes.com/interactive/2019/08/15/opinion/gamergate-twitter.html ] - Read all of the four essays. InterAction \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Optional) Tahmina Ansari. First Draft. \u201cThis Muslim journalist embraced social media until it \u2018ruined\u2019 his life\u201d [ https://firstdraftnews.org/this-muslim-journalist-embraced-social-media-until-it-ruined-his-life/ ]","title":"Week 8: Threat Tactics and Techniques"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-9-beyond-hacking-disinformation-and-harassment","text":"Monday, 10/21: Organizational Risks of Harmful Information Wednesday, 10/23: Mitigations for the Risks of Harmful Information Read (by end of week): Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] EFF. \u201cAm I the Right Person?\u201d [https://sec.eff.org/articles/right-person-to-train] EFF. \u201cHow to Teach Adults\u201d [ https://sec.eff.org/articles/how-to-teach-adults ] (Skim) Weidinger et al. \u201cDigital Security Training Resources for Security Trainers, Fall 2019 Edition\u201d [ https://medium.com/cryptofriends/digital-security-training-resources-for-security-trainers-spring-2017-edition-e95d9e50065e ] (Explore) Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] (Explore) The rest of EFF\u2019s Security Education Companion.[ https://sec.eff.org/ ] (Explore) Mitre\u2019s Common Vulnerabilities and Exposures search. [ https://cve.mitre.org/cve/ ]","title":"Week 9: Beyond Hacking -- Disinformation and Harassment"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-10-security-control-selection","text":"Monday, 10/28: Studying and Evaluating Security Tools Wednesday, 10/30: \u201cBeing a Good Security Educator\u201d (Cancelled due to Power Outage) Read (by end of week): Angela Chen. The Verge. \u201cModerating content doesn\u2019t have to be so traumatic\u201d [ https://www.theverge.com/2019/2/27/18243359/content-moderation-mental-health-ptsd-psychology-science-facebook ] Sam Dubberley & Michele Grant. First Draft. \u201cJournalism and Vicarious Trauma\u201d [ https://firstdraftnews.org/wp-content/uploads/2017/04/vicarioustrauma.pdf ]","title":"Week 10: Security Control Selection"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-11-additional-topics","text":"Monday, 11/4: Clinic Core Hours \u201cClinic Core Hours\u201d refers to the required student attendance of official class meeting hours between 1:30PM and 3:30PM that will be reserved for instruction specific to partner needs, feedback and guidance from the teaching team, and ad-hoc lectures. Every Monday (unless there\u2019s a holiday), each team will have a 20-minute check-in with the teaching team. Each team member will provide a ~5 minute update on the progress of their assigned partner work. Wednesday, 11/6: Psychosocial Resiliency & Trauma, Andrea Lampros & Gisela Perez de Acha Assignments: * 11/5 11:59PM: Phishing / OSINT Analysis Report [Team] (Optional)","title":"Week 11: Additional Topics"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-12-clinic-work","text":"Monday, 11/11: No class. Wednesday, 11/13: Clinic Core Hours / Team Check-in","title":"Week 12: Clinic Work"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-13-clinic-work","text":"Monday, 11/18: Clinic Core Hours / Team Check-in Wednesday, 11/20: Clinic Core Hours","title":"Week 13: Clinic Work"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-14-clinic-work","text":"Monday, 11/25: Clinic Core Hours / Team Check-in Wednesday, 11/27: No Class Assignments: 12/1 11:59PM: Final Partner Report (for Teaching Team Review) [Team]","title":"Week 14: Clinic Work"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-15-clinic-work","text":"Monday, 12/2: Clinic Core Hours / Team Check-in Wednesday, 12/4: Clinic Core Hours / Final Report Feedback","title":"Week 15: Clinic Work"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#week-16-rrr-wrap-up-project-presentations","text":"Monday, 12/9 - Course Wrap-up: Feedback on deliverables, submit all final deliverables. Wednesday, 12/11 - Project Presentations: Assignments: 12/9 6:00PM: Final Partner Report (to Partner) [Team] 12/10 11:59PM: Project Presentations [Team] 12/15 11:59PM: Final Individual Write-up [Individual] 12/15 11:59PM: Team Evaluation 2 [Individual]","title":"Week 16 (RRR): Wrap-up &amp; Project Presentations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Fall_2019/#course-policies","text":"Workload. This is a 4-unit class. Coursework will primarily focus on partner-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the partner. Evaluation. Assignments will largely be evaluated on the following rubric that emphasizes (1) sound rationale in assessments, recommendations, and reflections, (2) \u201cpartner-ready\u201d work products which reflect professional quality, and (3) completing the instructions of the assignment or the requirements agreed upon work plan with the partner. General Grading Rubric. Component 0 points 5 points 10 points Rationale Does not meet partner needs, introduces serious harms to partner, shows limited or inappropriate consideration for context Addresses most of partner needs, some oversight of potential harms to partner, mostly appropriate for given context. All partner needs are met, feasible & effective rationale that addresses all major threats, appropriate for given context. Professionalism Hard to understand, full of jargon, serious writing/format errors present, tone / design unsuitable for its audience Writing is mostly understandable; minor writing/format errors (typos), mostly appropriate tone / design \u201cpartner-ready,\u201d clear and concise writing, almost no writing/formatting errors, appropriate tone & design for its audience Requirements Some requirements in assignment or work plan not met; no insights or connections to readings/lectures; for group work: no evidence of group work Most requirements met, some evidence for connections with readings/lectures; for group work: some evidence of group work All requirements met, with clear, thoughtful insights and multiple cited connections to relevant readings/lectures; for group work: full evidence of strong, equitable collaboration Note: Students taking the course for P/NP or S/U are expected to participate in classes and complete all work to the same level of quality as students taking the course for a letter grade. Assignments. 1. Partner Deliverables - 60% The largest portion of graded evaluation will be based upon your team\u2019s work and support for its assigned partner. These deliverables may include assessments, recommendations, and guides, each tailored towards the partner\u2019s needs. Each team will also deliver a final report summarizing work performed with their partner. 2. Individual Assignments - 10% Two individual assignments will be given: Discussion Topic Leader (5%): Each student will sign up to be a discussion leader for select lectures. That student will be expected to generate interesting questions and guide class conversation around that week\u2019s assigned readings and lecture topic. You will also be expected to locate and share at least one news article about a recent, current event relevant to that discussion. Community Office Hours (5%): Students, in pairs, will sign up to hold a single two hour-block of \u201coffice hours\u201d to advise and assist the security practice of various cross-campus partners conducting politically-sensitive work. Those students will consider the partner\u2019s needs and threat model, make recommendations, and reachback for support as needed. 3. Final Individual Write-Up - 10% We want students to be able to discuss and share their experience in the course with others, including future employers. We also want our partners to remain confidential and protected. This being said, each student will submit a write-up of work performed and takeaways with sensitive information removed. The teaching team will review to ensure your experience is captured in an effective & safe manner. 4. Participation - 10% You are expected to attend each official class meeting and contribute substantially to class discussions. While you may not be able to attend every team meeting and partner engagement outside of normal class hours, you are expected to attend and contribute to your team\u2019s effort as often as possible. Absences from class meetings (including Clinic Core Hours) should be excused by the teaching team in advance. Not showing up to team check-ins will also negatively impact this grade. As a rule, two people from your team must attend any partner meeting or call. 5. Team Evaluations - 10% If there are difficulties with any team member, discuss the matter within your team and seek resolution. If you cannot resolve the problem, immediately contact any faculty member, so that we can make an appointment to discuss the situation individually or with the entire group as needed. Throughout the course, you will submit confidential evaluation forms which ask you to evaluate the contributions of each team member including yourself. Your final course grade will be adjusted, higher or lower, if you are contributing more or less than those within your group. Late assignments. As we want to respect the time of our partners and ensure a high level of quality control (the teaching team will review deliverables before it reaches the partner), we expect students to adhere to timelines and due dates. Each day an assignment is late will result in a letter grade deduction. Recognizing that emergencies arise and partners may require schedule adjustments, exceptions will be made on a case-by-case basis. Code of Conduct. Each student enrolled in the course must agree in writing to the Citizen Clinic\u2019s Code of Conduct (to be distributed) for maintaining a safe and secure learning experience and partner relationship. This Code of Conduct will be respected by all students, the teaching team, and CLTC staff and it is the responsibility of all personnel to report possible violations of the Code of Conduct to the teaching team. Additionally, we expect all students to abide by the Berkeley Student Code of Conduct (see https://sa.berkeley.edu/student-code-of-conduct ) and act with honesty, integrity, and respect for others. (See also https://diversity.berkeley.edu/principles-community ). The consequences for failing to act within these standards may include failing an assignment, a referral to the Center for Student Conduct and Community Standards, a failed grade in the course, and even immediate expulsion. A note on plagiarism: even in the scope of providing a partner with a walkthrough for securing a certain account or system, you are expected not to copy material from another guide, website, article or book (word-for-word or paraphrased) without citing the source - it\u2019s a small community and we should give credit where it is due. Other examples of unacceptable conduct include turning in deliverables created by students not currently in the course, work found on the Internet, or created by a commercial service. Disability Accommodation . If you need disability-related accommodations in this class, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please inform us as soon as possible.","title":"Course policies"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/","text":"New in Spring 2019! Removed two individual reflection assignments. Added Red Team OSINT assignment. Conducted hands-on cybersecurity workshop with School of Journalism. Info 290. Public Interest Cybersecurity: The Citizen Clinic Practicum. Spring 2019. Course description. For individuals and organizations involved in political advocacy, cybersecurity threats are an increasingly common reality of operating in the digital world. Civil society has always been under attack from ideological, political, and governmental opponents who seek to silence dissenting opinions, but the widespread adoption of connected technologies by the individuals and organizations that make up civil society creates a new class of vulnerabilities. Citizen Clinic at the Center for Long-Term Cybersecurity provides students with real-world experience assisting politically vulnerable organizations and persons around the world to develop and implement sound cybersecurity practices. Clinic students will participate in both a classroom and clinic component. In the classroom, students will study the basic theories and practices of digital security, the intricacies of protecting largely under-resourced organizations, and the tools needed to manage risk in complex political, sociological, legal, and ethical contexts. In the clinic component, students will work in teams supervised by the Clinic staff to provide direct cybersecurity assistance to civil society organizations. Students\u2019 clinic responsibilities will include learning about an organization\u2019s mission and context, assessing its vulnerabilities, and ultimately recommending and implementing mitigations to the identified security risks. The emphasis will be on pragmatic, workable solutions that take into account the unique operational needs of each partner organization.Weekly lectures will provide students with the background information and tools they will need to engage with partners. Coursework will focus on partner-facing, hands-on projects. Students will be expected to work an average of 12 hours per week, although the distribution of this workload may fluctuate based upon the availability and needs of the partner. Schedule. In the first half of the semester, class meetings will be a mix of lectures & discussions with more technical & project-oriented labs. In the second half of the semester, these class times will be reserved for work with the teaching team and check-ins tailored to the specific needs of your partner organization. Note: This schedule is tentative and may be adjusted - assignment dates may change, additional readings may be assigned, speakers/lectures may be shuffled, etc. The teaching team will announce when changes are made. Week 1: Introduction / What is Public-Interest Cybersecurity? Read: Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] Jorge Luis Sierra \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://freedomhouse.org/sites/default/files/Digital%20and%20Mobile%20Security%20for%20Mexican%20Journalists%20and%20Bloggers.pdf ] Netgain \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] (Skim) Citizen Lab\u2019s \u201cAbout Us\u201d Paper. [ https://citizenlab.ca/wp-content/uploads/2018/05/18033-Citizen-Lab-booklet-p-E.pdf ] (Skim) Tactical Tech's Annual Report [ https://tacticaltech.org/media/news/annual-report-2017.pdf ] (Optional) Sean Brooks \u201cDefending Politically Vulnerable Organizations Online\u201d [ https://cltc.berkeley.edu/wp-content/uploads/2018/07/CLTC_Defending_PVOs.pdf ] (Optional) Rus Shuler. \u201cHow Does the Internet Work?\u201d [ web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm ] Assignments Due: 1/22 11:59PM: Submit application materials to enroll in this course. You will be notified of your enrollment status prior to the next class meeting on January 24th. 1/24 In-Class : Code of Conduct Signed [Individual] 1/27 11:59PM: Equipment Setup Completed (with Reflection & Partner Preference Submitted) [Individual] Tuesday 1/22: We will introduce the content and methods of the course, answer your questions, and everyone will introduce themselves to one another. Introduction to Public Interest Cybersecurity Thursday 1/24: Citizen Clinic \u201cRules of the Road\u201d: Citizen Clinic Code of Conduct. Personal Risk of Citizen Clinic. How to talk about Citizen Clinic. Ethical Considerations. Security Response Plan. Personal Communications setup and equipment issue Partner Overview Week 2: Threats to Civil Society\u2019s Cybersecurity Read: Electronic Frontier Foundation, \u201cSurveillance Self-Defense: Your Security Plan\u201d [ https://ssd.eff.org/en/playlist/activist-or-protester#your-security-plan ] - know the definitions of underlined terms. Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Silver & Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] (Explore) MSFT\u2019s STRIDE and related blog posts. [ https://cloudblogs.microsoft.com/microsoftsecure/2007/09/11/stride-chart/ ] (Optional) Joseph Cox. \u201cI Gave a Bounty Hunter $300. Then He Located Our Phone\u201d [ https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile ] (Optional) Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ] (Optional) Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] Assignments Due: 2/1 6:00PM : Partner Communications Instructions (for Review) [Team] Tuesday 1/29: Threat Modeling Partner Communication Workshop Thursday 1/31: Bill Marczak, \u201cDigital Surveillance of PVOs - The Threat Landscape\u201d Week 3: Information Collection Read: Amnesty International. \u201cDigitally dissecting atrocities \u2013 Amnesty International\u2019s open source investigations.\u201d [ https://www.amnesty.org/en/latest/news/2018/09/digitally-dissecting-atrocities-amnesty-internationals-open-source-investigations/ ] Protective Intelligence. \u201cPart I: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt1 ] Protective Intelligence. \u201cPart 2: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt2 ] Ian Barwise. \u201cOpen-Source Intelligence (OSINT) Reconnaissance\u201d [ https://medium.com/@z3roTrust/open-source-intelligence-osint-reconnaissance-75edd7f7dada ] (Explore) OSINT Framework [ https://osintframework.com/ ] (Explore) Bellingcat Online Investigation Toolkit [ https://docs.google.com/document/d/1BfLPJpRtyq4RFtHJoNpvWQjmGnyVkfE2HYoICKOGguA/edit ] Assignments Due: 2/8 6:00PM: Collaborative Plan [Team] Swapped - Tuesday 2/5: Open Source Research Methods, Safety, and Tools Thursday 2/7: F\u00e9lim McMahon, Technology Director, Human Rights Center \u201cDeploying Security Controls in a High-Risk Environment\u201d Week 4: Risk Assessment for Cybersecurity Read: Example Risk Assessment shared via email. SAFETAG Guide. Read to Section 4.4, skim rest. [ https://safetag.org/guide/ read to Section 4.4] Julian Cohen. \u201cPlaybook Based Testing.\u201d [ https://medium.com/@HockeyInJune/playbook-based-testing-5df4b656113a ] NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf or Shutdown Mirror ] (Explore) About PESTLE. [ http://guides.ucf.edu/industryanalysis/PESTLE ] (Skim) NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf or Shutdown Mirror ] (Skim) NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf or Shutdown Mirror ] Assignments Due: By end of week (2/15) : First Call with Partner [Team] 2/15 6:00PM : OSINT Assignment [Team] Tuesday 2/12: Contextual Factors and Frameworks SAFETAG PESTLE-M PMESII Thursday 2/14: Bounding Risk Assessments Week 5: Changing Security Behaviors Read: Engine Room. \u201cTies That Bind: Organisational Security for Civil Society\u201d - read Full Report. [ https://www.theengineroom.org/civil-society-digital-security-new-research/ ] APF et al. \u201cImproving SSL Warnings: Comprehension and Adherence\u201d [ https://dl.acm.org/citation.cfm?id=2702442 ] Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] (Watch) Rachel Tobac. \u201cHow I would Hack You: Social Engineering Step-by-Step\u201d [ https://www.youtube.com/watch?v=L5J2PgGOLtE ] (Optional) Scott, James C. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ] Assignments Due: By end of week (2/22) : 1st Contextual Research Briefs [Individual] Tuesday 2/19: Steve Weber, \u201cChanging Behaviors within PVOs\u201d Thursday 2/21: Phishing for Context Week 6: Establishing Baseline Digital Security (Part 1) Read: Bill Marczak and John Scott-Railton. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] Micah Lee. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] Arthur Turner. \u201cConsulting Is More Than Giving Advice.\u201d [ https://hbr.org/1982/09/consulting-is-more-than-giving-advice ] Assignments Due: 3/1 6:00PM : Draft Work Plan (to Teaching Team) [Team] 3/3 11:59PM : Phishing Email Template [Individual] Tuesday 2/26: Managing an Effective Consulting Relationship Designing your Work Plan Thursday 2/28: Bill Marczak, \u201cTechnical Investigations and Techniques\u201d Week 7: Establishing Baseline Digital Security (Part 2) Read: IFTF \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51. [ http://www.iftf.org/statesponsoredtrolling ] InterAction \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Emma L. Backe. \u201cLeft to their Own Devices: Gender, Cyberviolence, and the Internet\u201d [ https://thenewinquiry.com/blog/left-to-their-own-devices-gender-cyberviolence-and-the-internet/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Explore) Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/wiki/Main_Page ] Assignments Due: 3/5 11:59PM : Phishing Email Template [Individual] By end of week (3/8) : Work Plan Call with Partner [Team] 3/8 6:00PM : Final Work Plan Approved by Partner [Team] Tuesday 3/5: Adversary Persona and Threat Scenario Development (Nick Merrill\u2019s Security Game) Thursday 3/7: Leigh Honeywell, Founder/CEO, Tall Poppy \u201cOnline Harassment and Trolling\u201d Week 8: Digital Security Training (Part 1) Read: Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] EFF. \u201cAm I the Right Person?\u201d [https://sec.eff.org/articles/right-person-to-train] EFF. \u201cHow to Teach Adults\u201d [ https://sec.eff.org/articles/how-to-teach-adults ] (Explore) Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] (Explore) The rest of EFF\u2019s Security Education Companion. [ https://sec.eff.org/ ] (Explore) Mitre\u2019s Common Vulnerabilities and Exposures search. [ https://cve.mitre.org/cve/ ] Assignments Due: By end of week (3/15) : 2nd Contextual Research Briefs [Individual] Tuesday 3/12: Adult Education for Security Studying and Evaluating Security Tools (Yubikey), Indiana University Thursday 3/14: Eva Galperin, Director of Cybersecurity, EFF - \u201cBeing a good security educator\u201d Week 9: Digital Security Training (Part 2) Assignments Due: 3/21 11:59PM : Team Evaluation 1 [Individual] Tuesday 3/19: Community Clinic with the School of Journalism (School of Journalism Library, Lunch will be provided) Thursday 3/21: Community Clinic Discussion Third-Party Tool Evaluation Week 10 - \u201cSpring Break\u201d: Tuesday 3/26: No Class Thursday 3/28: No Class Week 11: Tuesday 4/2: Clinic Core Hours / Team Check-in \u201cClinic Core Hours\u201d refers to the required student attendance of official class meeting hours between 12PM and 2PM that will be reserved for instruction specific to partner needs, feedback and guidance from the teaching team, and ad-hoc lectures. Every Tuesday (starting on April 2nd), each team will have a 30-minute check-in with the teaching team. Each team member will provide a ~5 minute update on the progress of their assigned partner work. Thursday 4/4: Clinic Core Hours Week 12: Tuesday 4/9: Clinic Core Hours / Team Check-in Thursday 4/11: Clinic Core Hours Week 13: Tuesday 4/16: Clinic Core Hours / Team Check-in Thursday 4/18: Clinic Core Hours Week 14: Tuesday 4/23: Clinic Core Hours / Team Check-in Thursday 4/25: Clinic Core Hours Week 15: Assignments Due: 4/30 11:59PM: Final Partner Report (for Teaching Team Review) [Team] Tuesday 4/30: Clinic Core Hours Thursday 5/2: Clinic Core Hours / Final Report Feedback Week 16 (RRR): Wrap-up & Project Presentations Assignments Due: 5/10 6:00PM: Final Partner Report (to Partner) [Team] 5/8 11:59PM : Project Presentations [Team] 5/12 11:59PM : Final Individual Write-up [Individual] 5/12 11:59PM: Team Evaluation 2 [Individual] Tuesday 5/7 - Course Wrap-up: Feedback on deliverables, submit all final deliverables. Thursday 5/9 - Project Presentations: An overview of partner work, findings, recommendations delivered to CLTC and stakeholders. Course policies Workload. This is a 4-unit class. Coursework will primarily focus on partner-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the partner. Evaluation. Assignments will largely be evaluated on the following rubric that emphasizes (1) sound rationale in assessments, recommendations, and reflections, (2) \u201cpartner-ready\u201d work products which reflect professional quality, and (3) completing the instructions of the assignment or the requirements agreed upon work plan with the partner. General Grading Rubric Component 0 points 5 points 10 points Rationale Does not meet partner needs, introduces serious harms to partner, shows limited or inappropriate consideration for context Addresses most of partner needs, some oversight of potential harms to partner, mostly appropriate for given context. All partner needs are met, feasible & effective rationale that addresses all major threats, appropriate for given context. Professionalism Hard to understand, full of jargon, serious writing/format errors present, tone / design unsuitable for its audience Writing is mostly understandable; minor writing/format errors (typos), mostly appropriate tone / design \u201cpartner-ready,\u201d clear and concise writing, almost no writing/formatting errors, appropriate tone & design for its audience Requirements Some requirements in assignment or work plan not met; no insights or connections to readings/lectures; for group work: no evidence of group work Most requirements met, some evidence for connections with readings/lectures; for group work: some evidence of group work All requirements met, with clear, thoughtful insights and multiple cited connections to relevant readings/lectures; for group work: full evidence of strong, equitable collaboration Note: Students taking the course for P/NP or S/U are expected to participate in classes and complete all work to the same level of quality as students taking the course for a letter grade. Assignments. 1. Partner Deliverables - 60% The largest portion of graded evaluation will be based upon your team\u2019s work and support for its assigned partner. These deliverables may include assessments, recommendations, and guides, each tailored towards the partner\u2019s needs. Each team will also deliver a final report summarizing work performed with their partner. 2. Individual Assignments - 10% A small number of individual assignments will be given, mostly within the first half of the course. 3. Final Individual Write-Up - 10% We want students to be able to discuss and share their experience in the course with others, including future employers. We also want our partners to remain confidential and protected. This being said, each student will submit a write-up of work performed and takeaways with sensitive information removed. The teaching team will review to ensure your experience is captured in an effective & safe manner. 4. Participation - 10% You are expected to attend each official class meeting and contribute substantially to class discussions. While you may not be able to attend every team meeting and partner engagement outside of normal class hours, you are expected to attend and contribute to your team\u2019s effort as often as possible. Absences from class meetings (including Clinic Core Hours) should be excused by the teaching team in advance. Not showing up to team check-ins every Thursday after Spring Break will also negatively impact this grade. As a rule, two people from your team must attend any partner meeting or call. 5. Team Evaluations - 10% If there are difficulties with any team member, discuss the matter within your team and seek resolution. If you cannot resolve the problem, immediately contact any faculty member, so that we can make an appointment to discuss the situation individually or with the entire group as needed. Throughout the course, you will submit confidential evaluation forms which ask you to evaluate the contributions of each team member including yourself. Your final course grade will be adjusted, higher or lower, if you are contributing more or less than those within your group. Late assignments. As we want to respect the time of our partners and ensure a high level of quality control (the teaching team will review deliverables before it reaches the partner), we expect students to adhere to timelines and due dates. Each day an assignment is late will result in a letter grade deduction. Recognizing that emergencies arise and partners may require schedule adjustments, exceptions will be made on a case-by-case basis. Code of Conduct. Each student enrolled in the course must agree in writing to the Citizen Clinic\u2019s Code of Conduct (to be distributed) for maintaining a safe and secure learning experience and partner relationship. This Code of Conduct will be respected by all students, the teaching team, and CLTC staff and it is the responsibility of all personnel to report possible violations of the Code of Conduct to the teaching team. Additionally, we expect all students to abide by the Berkeley Student Code of Conduct (see https://sa.berkeley.edu/student-code-of-conduct ) and act with honesty, integrity, and respect for others. (See also https://diversity.berkeley.edu/principles-community ). The consequences for failing to act within these standards may include failing an assignment, a referral to the Center for Student Conduct and Community Standards, a failed grade in the course, and even immediate expulsion. A note on plagiarism: even in the scope of providing a partners with a walkthrough for securing a certain account or system, you are expected not to copy material from another guide, website, article or book (word-for-word or paraphrased) without citing the source - it\u2019s a small community and we should give credit where it is due. Other examples of unacceptable conduct include turning in deliverables created by students not currently in the course, work found on the Internet, or created by a commercial service. Disability Accommodation . If you need disability-related accommodations in this class, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please inform us as soon as possible.","title":"Spring 2019"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#course-description","text":"For individuals and organizations involved in political advocacy, cybersecurity threats are an increasingly common reality of operating in the digital world. Civil society has always been under attack from ideological, political, and governmental opponents who seek to silence dissenting opinions, but the widespread adoption of connected technologies by the individuals and organizations that make up civil society creates a new class of vulnerabilities. Citizen Clinic at the Center for Long-Term Cybersecurity provides students with real-world experience assisting politically vulnerable organizations and persons around the world to develop and implement sound cybersecurity practices. Clinic students will participate in both a classroom and clinic component. In the classroom, students will study the basic theories and practices of digital security, the intricacies of protecting largely under-resourced organizations, and the tools needed to manage risk in complex political, sociological, legal, and ethical contexts. In the clinic component, students will work in teams supervised by the Clinic staff to provide direct cybersecurity assistance to civil society organizations. Students\u2019 clinic responsibilities will include learning about an organization\u2019s mission and context, assessing its vulnerabilities, and ultimately recommending and implementing mitigations to the identified security risks. The emphasis will be on pragmatic, workable solutions that take into account the unique operational needs of each partner organization.Weekly lectures will provide students with the background information and tools they will need to engage with partners. Coursework will focus on partner-facing, hands-on projects. Students will be expected to work an average of 12 hours per week, although the distribution of this workload may fluctuate based upon the availability and needs of the partner. Schedule. In the first half of the semester, class meetings will be a mix of lectures & discussions with more technical & project-oriented labs. In the second half of the semester, these class times will be reserved for work with the teaching team and check-ins tailored to the specific needs of your partner organization. Note: This schedule is tentative and may be adjusted - assignment dates may change, additional readings may be assigned, speakers/lectures may be shuffled, etc. The teaching team will announce when changes are made.","title":"Course description."},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-1-introduction-what-is-public-interest-cybersecurity","text":"Read: Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] Jorge Luis Sierra \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://freedomhouse.org/sites/default/files/Digital%20and%20Mobile%20Security%20for%20Mexican%20Journalists%20and%20Bloggers.pdf ] Netgain \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] (Skim) Citizen Lab\u2019s \u201cAbout Us\u201d Paper. [ https://citizenlab.ca/wp-content/uploads/2018/05/18033-Citizen-Lab-booklet-p-E.pdf ] (Skim) Tactical Tech's Annual Report [ https://tacticaltech.org/media/news/annual-report-2017.pdf ] (Optional) Sean Brooks \u201cDefending Politically Vulnerable Organizations Online\u201d [ https://cltc.berkeley.edu/wp-content/uploads/2018/07/CLTC_Defending_PVOs.pdf ] (Optional) Rus Shuler. \u201cHow Does the Internet Work?\u201d [ web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm ] Assignments Due: 1/22 11:59PM: Submit application materials to enroll in this course. You will be notified of your enrollment status prior to the next class meeting on January 24th. 1/24 In-Class : Code of Conduct Signed [Individual] 1/27 11:59PM: Equipment Setup Completed (with Reflection & Partner Preference Submitted) [Individual] Tuesday 1/22: We will introduce the content and methods of the course, answer your questions, and everyone will introduce themselves to one another. Introduction to Public Interest Cybersecurity Thursday 1/24: Citizen Clinic \u201cRules of the Road\u201d: Citizen Clinic Code of Conduct. Personal Risk of Citizen Clinic. How to talk about Citizen Clinic. Ethical Considerations. Security Response Plan. Personal Communications setup and equipment issue Partner Overview","title":"Week 1: Introduction / What is Public-Interest Cybersecurity?"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-2-threats-to-civil-societys-cybersecurity","text":"Read: Electronic Frontier Foundation, \u201cSurveillance Self-Defense: Your Security Plan\u201d [ https://ssd.eff.org/en/playlist/activist-or-protester#your-security-plan ] - know the definitions of underlined terms. Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Silver & Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] (Explore) MSFT\u2019s STRIDE and related blog posts. [ https://cloudblogs.microsoft.com/microsoftsecure/2007/09/11/stride-chart/ ] (Optional) Joseph Cox. \u201cI Gave a Bounty Hunter $300. Then He Located Our Phone\u201d [ https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile ] (Optional) Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ] (Optional) Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] Assignments Due: 2/1 6:00PM : Partner Communications Instructions (for Review) [Team] Tuesday 1/29: Threat Modeling Partner Communication Workshop Thursday 1/31: Bill Marczak, \u201cDigital Surveillance of PVOs - The Threat Landscape\u201d","title":"Week 2: Threats to Civil Society\u2019s Cybersecurity"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-3-information-collection","text":"Read: Amnesty International. \u201cDigitally dissecting atrocities \u2013 Amnesty International\u2019s open source investigations.\u201d [ https://www.amnesty.org/en/latest/news/2018/09/digitally-dissecting-atrocities-amnesty-internationals-open-source-investigations/ ] Protective Intelligence. \u201cPart I: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt1 ] Protective Intelligence. \u201cPart 2: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt2 ] Ian Barwise. \u201cOpen-Source Intelligence (OSINT) Reconnaissance\u201d [ https://medium.com/@z3roTrust/open-source-intelligence-osint-reconnaissance-75edd7f7dada ] (Explore) OSINT Framework [ https://osintframework.com/ ] (Explore) Bellingcat Online Investigation Toolkit [ https://docs.google.com/document/d/1BfLPJpRtyq4RFtHJoNpvWQjmGnyVkfE2HYoICKOGguA/edit ] Assignments Due: 2/8 6:00PM: Collaborative Plan [Team] Swapped - Tuesday 2/5: Open Source Research Methods, Safety, and Tools Thursday 2/7: F\u00e9lim McMahon, Technology Director, Human Rights Center \u201cDeploying Security Controls in a High-Risk Environment\u201d","title":"Week 3: Information Collection"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-4-risk-assessment-for-cybersecurity","text":"Read: Example Risk Assessment shared via email. SAFETAG Guide. Read to Section 4.4, skim rest. [ https://safetag.org/guide/ read to Section 4.4] Julian Cohen. \u201cPlaybook Based Testing.\u201d [ https://medium.com/@HockeyInJune/playbook-based-testing-5df4b656113a ] NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf or Shutdown Mirror ] (Explore) About PESTLE. [ http://guides.ucf.edu/industryanalysis/PESTLE ] (Skim) NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf or Shutdown Mirror ] (Skim) NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf or Shutdown Mirror ] Assignments Due: By end of week (2/15) : First Call with Partner [Team] 2/15 6:00PM : OSINT Assignment [Team] Tuesday 2/12: Contextual Factors and Frameworks SAFETAG PESTLE-M PMESII Thursday 2/14: Bounding Risk Assessments","title":"Week 4: Risk Assessment for Cybersecurity"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-5-changing-security-behaviors","text":"Read: Engine Room. \u201cTies That Bind: Organisational Security for Civil Society\u201d - read Full Report. [ https://www.theengineroom.org/civil-society-digital-security-new-research/ ] APF et al. \u201cImproving SSL Warnings: Comprehension and Adherence\u201d [ https://dl.acm.org/citation.cfm?id=2702442 ] Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] (Watch) Rachel Tobac. \u201cHow I would Hack You: Social Engineering Step-by-Step\u201d [ https://www.youtube.com/watch?v=L5J2PgGOLtE ] (Optional) Scott, James C. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ] Assignments Due: By end of week (2/22) : 1st Contextual Research Briefs [Individual] Tuesday 2/19: Steve Weber, \u201cChanging Behaviors within PVOs\u201d Thursday 2/21: Phishing for Context","title":"Week 5: Changing Security Behaviors"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-6-establishing-baseline-digital-security-part-1","text":"Read: Bill Marczak and John Scott-Railton. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] Micah Lee. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] Arthur Turner. \u201cConsulting Is More Than Giving Advice.\u201d [ https://hbr.org/1982/09/consulting-is-more-than-giving-advice ] Assignments Due: 3/1 6:00PM : Draft Work Plan (to Teaching Team) [Team] 3/3 11:59PM : Phishing Email Template [Individual] Tuesday 2/26: Managing an Effective Consulting Relationship Designing your Work Plan Thursday 2/28: Bill Marczak, \u201cTechnical Investigations and Techniques\u201d","title":"Week 6: Establishing Baseline Digital Security (Part 1)"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-7-establishing-baseline-digital-security-part-2","text":"Read: IFTF \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51. [ http://www.iftf.org/statesponsoredtrolling ] InterAction \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Emma L. Backe. \u201cLeft to their Own Devices: Gender, Cyberviolence, and the Internet\u201d [ https://thenewinquiry.com/blog/left-to-their-own-devices-gender-cyberviolence-and-the-internet/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Explore) Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/wiki/Main_Page ] Assignments Due: 3/5 11:59PM : Phishing Email Template [Individual] By end of week (3/8) : Work Plan Call with Partner [Team] 3/8 6:00PM : Final Work Plan Approved by Partner [Team] Tuesday 3/5: Adversary Persona and Threat Scenario Development (Nick Merrill\u2019s Security Game) Thursday 3/7: Leigh Honeywell, Founder/CEO, Tall Poppy \u201cOnline Harassment and Trolling\u201d","title":"Week 7: Establishing Baseline Digital Security (Part 2)"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-8-digital-security-training-part-1","text":"Read: Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] EFF. \u201cAm I the Right Person?\u201d [https://sec.eff.org/articles/right-person-to-train] EFF. \u201cHow to Teach Adults\u201d [ https://sec.eff.org/articles/how-to-teach-adults ] (Explore) Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] (Explore) The rest of EFF\u2019s Security Education Companion. [ https://sec.eff.org/ ] (Explore) Mitre\u2019s Common Vulnerabilities and Exposures search. [ https://cve.mitre.org/cve/ ]","title":"Week 8: Digital Security Training (Part 1)"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#assignments-due","text":"By end of week (3/15) : 2nd Contextual Research Briefs [Individual] Tuesday 3/12: Adult Education for Security Studying and Evaluating Security Tools (Yubikey), Indiana University Thursday 3/14: Eva Galperin, Director of Cybersecurity, EFF - \u201cBeing a good security educator\u201d","title":"Assignments Due:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-9-digital-security-training-part-2","text":"","title":"Week 9: Digital Security Training (Part 2)"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#assignments-due_1","text":"3/21 11:59PM : Team Evaluation 1 [Individual] Tuesday 3/19: Community Clinic with the School of Journalism (School of Journalism Library, Lunch will be provided) Thursday 3/21: Community Clinic Discussion Third-Party Tool Evaluation","title":"Assignments Due:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-10-spring-break","text":"Tuesday 3/26: No Class Thursday 3/28: No Class","title":"Week 10 - \u201cSpring Break\u201d:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-11","text":"Tuesday 4/2: Clinic Core Hours / Team Check-in \u201cClinic Core Hours\u201d refers to the required student attendance of official class meeting hours between 12PM and 2PM that will be reserved for instruction specific to partner needs, feedback and guidance from the teaching team, and ad-hoc lectures. Every Tuesday (starting on April 2nd), each team will have a 30-minute check-in with the teaching team. Each team member will provide a ~5 minute update on the progress of their assigned partner work. Thursday 4/4: Clinic Core Hours","title":"Week 11:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-12","text":"Tuesday 4/9: Clinic Core Hours / Team Check-in Thursday 4/11: Clinic Core Hours","title":"Week 12:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-13","text":"Tuesday 4/16: Clinic Core Hours / Team Check-in Thursday 4/18: Clinic Core Hours","title":"Week 13:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-14","text":"Tuesday 4/23: Clinic Core Hours / Team Check-in Thursday 4/25: Clinic Core Hours","title":"Week 14:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-15","text":"Assignments Due: 4/30 11:59PM: Final Partner Report (for Teaching Team Review) [Team] Tuesday 4/30: Clinic Core Hours Thursday 5/2: Clinic Core Hours / Final Report Feedback","title":"Week 15:"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#week-16-rrr-wrap-up-project-presentations","text":"Assignments Due: 5/10 6:00PM: Final Partner Report (to Partner) [Team] 5/8 11:59PM : Project Presentations [Team] 5/12 11:59PM : Final Individual Write-up [Individual] 5/12 11:59PM: Team Evaluation 2 [Individual] Tuesday 5/7 - Course Wrap-up: Feedback on deliverables, submit all final deliverables. Thursday 5/9 - Project Presentations: An overview of partner work, findings, recommendations delivered to CLTC and stakeholders.","title":"Week 16 (RRR): Wrap-up &amp; Project Presentations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2019/#course-policies","text":"Workload. This is a 4-unit class. Coursework will primarily focus on partner-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the partner. Evaluation. Assignments will largely be evaluated on the following rubric that emphasizes (1) sound rationale in assessments, recommendations, and reflections, (2) \u201cpartner-ready\u201d work products which reflect professional quality, and (3) completing the instructions of the assignment or the requirements agreed upon work plan with the partner. General Grading Rubric Component 0 points 5 points 10 points Rationale Does not meet partner needs, introduces serious harms to partner, shows limited or inappropriate consideration for context Addresses most of partner needs, some oversight of potential harms to partner, mostly appropriate for given context. All partner needs are met, feasible & effective rationale that addresses all major threats, appropriate for given context. Professionalism Hard to understand, full of jargon, serious writing/format errors present, tone / design unsuitable for its audience Writing is mostly understandable; minor writing/format errors (typos), mostly appropriate tone / design \u201cpartner-ready,\u201d clear and concise writing, almost no writing/formatting errors, appropriate tone & design for its audience Requirements Some requirements in assignment or work plan not met; no insights or connections to readings/lectures; for group work: no evidence of group work Most requirements met, some evidence for connections with readings/lectures; for group work: some evidence of group work All requirements met, with clear, thoughtful insights and multiple cited connections to relevant readings/lectures; for group work: full evidence of strong, equitable collaboration Note: Students taking the course for P/NP or S/U are expected to participate in classes and complete all work to the same level of quality as students taking the course for a letter grade. Assignments. 1. Partner Deliverables - 60% The largest portion of graded evaluation will be based upon your team\u2019s work and support for its assigned partner. These deliverables may include assessments, recommendations, and guides, each tailored towards the partner\u2019s needs. Each team will also deliver a final report summarizing work performed with their partner. 2. Individual Assignments - 10% A small number of individual assignments will be given, mostly within the first half of the course. 3. Final Individual Write-Up - 10% We want students to be able to discuss and share their experience in the course with others, including future employers. We also want our partners to remain confidential and protected. This being said, each student will submit a write-up of work performed and takeaways with sensitive information removed. The teaching team will review to ensure your experience is captured in an effective & safe manner. 4. Participation - 10% You are expected to attend each official class meeting and contribute substantially to class discussions. While you may not be able to attend every team meeting and partner engagement outside of normal class hours, you are expected to attend and contribute to your team\u2019s effort as often as possible. Absences from class meetings (including Clinic Core Hours) should be excused by the teaching team in advance. Not showing up to team check-ins every Thursday after Spring Break will also negatively impact this grade. As a rule, two people from your team must attend any partner meeting or call. 5. Team Evaluations - 10% If there are difficulties with any team member, discuss the matter within your team and seek resolution. If you cannot resolve the problem, immediately contact any faculty member, so that we can make an appointment to discuss the situation individually or with the entire group as needed. Throughout the course, you will submit confidential evaluation forms which ask you to evaluate the contributions of each team member including yourself. Your final course grade will be adjusted, higher or lower, if you are contributing more or less than those within your group. Late assignments. As we want to respect the time of our partners and ensure a high level of quality control (the teaching team will review deliverables before it reaches the partner), we expect students to adhere to timelines and due dates. Each day an assignment is late will result in a letter grade deduction. Recognizing that emergencies arise and partners may require schedule adjustments, exceptions will be made on a case-by-case basis. Code of Conduct. Each student enrolled in the course must agree in writing to the Citizen Clinic\u2019s Code of Conduct (to be distributed) for maintaining a safe and secure learning experience and partner relationship. This Code of Conduct will be respected by all students, the teaching team, and CLTC staff and it is the responsibility of all personnel to report possible violations of the Code of Conduct to the teaching team. Additionally, we expect all students to abide by the Berkeley Student Code of Conduct (see https://sa.berkeley.edu/student-code-of-conduct ) and act with honesty, integrity, and respect for others. (See also https://diversity.berkeley.edu/principles-community ). The consequences for failing to act within these standards may include failing an assignment, a referral to the Center for Student Conduct and Community Standards, a failed grade in the course, and even immediate expulsion. A note on plagiarism: even in the scope of providing a partners with a walkthrough for securing a certain account or system, you are expected not to copy material from another guide, website, article or book (word-for-word or paraphrased) without citing the source - it\u2019s a small community and we should give credit where it is due. Other examples of unacceptable conduct include turning in deliverables created by students not currently in the course, work found on the Internet, or created by a commercial service. Disability Accommodation . If you need disability-related accommodations in this class, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please inform us as soon as possible.","title":"Course policies"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/","text":"New in Spring 2020! Added student-led current events kickoff discussions. Added student-led community-focused security training event in place of student \"office hours.\" Developed (with EFF) hands-on Security Training design module for community-focused workshop. Moved Resiliency module earlier in semester. Added collaborative discussion with Policy & Legal experts. Info 289. Public Interest Cybersecurity: The Citizen Clinic Practicum. Spring 2020 Course Description. For individuals and organizations involved in political advocacy, cybersecurity threats are an increasingly common reality of operating in the digital world. Civil society has always been under attack from ideological, political, and governmental opponents who seek to silence dissenting opinions, but the widespread adoption of connected technologies by the individuals and organizations that make up civil society creates a new class of vulnerabilities. Citizen Clinic at the Center for Long-Term Cybersecurity provides students with real-world experience assisting politically vulnerable organizations and persons around the world to develop and implement sound cybersecurity practices. Clinic students will participate in both a classroom and clinic component. In the classroom, students will study the basic theories and practices of digital security, the intricacies of protecting largely under-resourced organizations, and the tools needed to manage risk in complex political, sociological, legal, and ethical contexts. In the clinic component, students will work in teams supervised by the Clinic staff to provide direct cybersecurity assistance to civil society organizations. Students\u2019 clinic responsibilities will include learning about an organization\u2019s mission and context, assessing its vulnerabilities, and ultimately recommending and implementing mitigations to the identified security risks. The emphasis will be on pragmatic, workable solutions that take into account the unique operational needs of each partner organization.Weekly lectures will provide students with the background information and tools they will need to engage with partners. Coursework will focus on partner-facing, hands-on projects. Students will be expected to work an average of 12 hours per week, although the distribution of this workload may fluctuate based upon the availability and needs of the partner. Schedule. In the first half of the semester, class meetings will be a mix of lectures & discussions with more technical & project-oriented labs. In the second half of the semester, these class times will be reserved for work with the teaching team and check-ins tailored to the specific needs of your partner organization. Note: This schedule is tentative and may be adjusted - assignment dates may change, additional readings may be assigned, speakers/lectures may be shuffled, etc. The teaching team will announce when changes are made. Week 0: Introduction / What is Public-Interest Cybersecurity? Wednesday 1/22: Introduction to Public Interest Cybersecurity: We will introduce the content and methods of the course, answer your questions, and everyone will introduce themselves to one another. Assignments: Due Friday 1/24 6:00PM: Submit application materials to enroll in this course. You will be notified of your enrollment status prior to the next class meeting on January 27th. Due Monday 1/27 before class: Read pages 7 - 21 & 48 - 52 of \u201cAn Introduction to Cybersecurity Ethics\u201d (Shannon Vallor, The Markkula Center for Applied Ethics) [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Prepare answers to questions on pages 15 - 17 and page 53 for in-class discussion. Read (by next week): Shannon Vallor, The Markkula Center for Applied Ethics, \u201cAn Introduction to Cybersecurity Ethics\u201d pages 7 - 21 & 48 - 52. [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Sandro Contenta, Toronto Star, \u201cHow these Toronto sleuths are exposing the world\u2019s digital spies while risking their own lives\u201d [ https://www.thestar.com/news/canada/2019/12/13/from-a-tower-in-toronto-they-watch-the-watchers-how-citizen-lab-sleuths-are-exposing-the-worlds-digital-spies-while-risking-their-own-lives.html ] Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] (Explore & use) Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] (Skim) Tactical Tech's Annual Report [ https://cdn.ttc.io/s/tacticaltech.org/Tactical-Tech-2018-Annual-Report.pdf ] (Optional) Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] (Optional) Rus Shuler. \u201cHow Does the Internet Work?\u201d [ web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm ] Week 1: Code of Conduct and Ethics in Cybersecurity Monday 1/27: Ethics and \u201cRules of the Road\u201d - Steve Citizen Clinic Code of Conduct. Ethical Considerations. Security Response Plan. Wednesday 1/29: Old School INFOSEC: Basic (& Some Outdated) Controls - Steve & Sean Clinic Communications Setup - Steve Partner Overview - Sean Assignments: Due 1/27 before class: Prepare answers to questions on pages 15 - 17 and page 53 of \u201cIntro to Cybersecurity Ethics\u201d for in-class discussion. [Individual] Due 1/27 In-Class: Code of Conduct Signed [Individual] Due 1/31 6:00PM: Equipment Setup Completed & Partner Preference Submitted [Individual] Read (by next week): Electronic Frontier Foundation, \u201cSurveillance Self-Defense: Your Security Plan\u201d [ https://ssd.eff.org/en/playlist/activist-or-protester#your-security-plan ] - know the definitions of underlined terms. Jorge Luis Sierra \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://freedomhouse.org/sites/default/files/Digital%20and%20Mobile%20Security%20for%20Mexican%20Journalists%20and%20Bloggers.pdf ] Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] SAFETAG Guide. Skim to Section 2.2, then read Section 2.2 and Section 2.3. [ https://safetag.org/guide/ ] (Read and Explore Examples) About PESTLE (use an ad-blocker!) [ https://pestleanalysis.com/what-is-pestle-analysis/ ] (Optionally Watch) CLTC / TechSoup. Webinar. \u201cCybersecurity in Low-Risk Organizations: Understanding Your Risk and Making Practical Improvements.\u201d: [ https://cltc.berkeley.edu/2019/02/25/cltc-and-citizen-clinic-present-cybersecurity-in-low-risk-organizations-webinar/ ] Week 2: Assessing Civil Society Organizations Monday 2/3: Threat Modeling & Bounding Risk Assessments - Sean Wednesday 2/5: Contextual & Capacity Research - Steve SAFETAG PESTLE-M Assignments: Due 2/5 6:00PM: Internal Collaborative Plan [Team] Due 2/7 6:00PM: Mentor Communications Established [Team] Read (by next week): Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Silver & Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] Arthur Turner. \u201cConsulting Is More Than Giving Advice.\u201d [ https://hbr.org/1982/09/consulting-is-more-than-giving-advice ] Netgain \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] (Optional) Thomas Wedell-Wedellsborg. \u201cAre You Solving the Right Problems?\u201d [ https://hbr.org/2017/01/are-you-solving-the-right-problems ] (Optional) Joseph Cox. \u201cI Gave a Bounty Hunter $300. Then He Located Our Phone\u201d [ https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile ] (Optional) Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ] Week 3: Understanding Threats to Civil Society Organizations Monday 2/10: Digital Surveillance of PVOs: The Threat Landscape - Bill Marczak, Citizen Lab, Citizen Clinic Resident Wednesday 2/12: Contextual Research Recap & Information Gathering - Steve Problem Diagnosis and Reframing - Sean Assignments: Due 2/14 6:00PM : Partner Communications Established [Team] Read (by next week): NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf or Shutdown Mirror ] (Skim) NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf or Shutdown Mirror ] (Skim) NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf or Shutdown Mirror ] Protective Intelligence. \u201cPart I: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt1 ] Protective Intelligence. \u201cPart 2: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt2 ] Ian Barwise. \u201cOpen-Source Intelligence (OSINT) Reconnaissance\u201d [ https://medium.com/@z3roTrust/open-source-intelligence-osint-reconnaissance-75edd7f7dada ] (Explore) OSINT Framework [ https://osintframework.com/ ] (Explore) OSINT.link [ https://osint.link ] (Explore) Awesome OSINT [ https://github.com/jivoi/awesome-osint ] (Try) SECALERTS - Automated Security Audit [ https://secalerts.co/security-audit ] Week 4: OSINT Collection Monday 2/17: No Class Wednesday 2/19: Open Source Research Methods, Safety, and Tools - Steve Virtual Networks: VPNs vs TOR Virtual Machines Virtual Identities Manual Searches & Google Hacking Automated Tools Read (by next week): Example Risk Assessment shared via email. Julian Cohen. \u201cPlaybook Based Testing.\u201d [ https://medium.com/@HockeyInJune/playbook-based-testing-5df4b656113a ] MSFT\u2019s STRIDE and related blog posts. [ https://cloudblogs.microsoft.com/microsoftsecure/2007/09/11/stride-chart/ ] Bill Marczak and John Scott-Railton. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] The Engine Room. \u201cTies That Bind: Organisational Security for Civil Society\u201d - read Full Report. [ https://www.theengineroom.org/civil-society-digital-security-new-research/ ] APF et al. \u201cImproving SSL Warnings: Comprehension and Adherence\u201d [ https://dl.acm.org/citation.cfm?id=2702442 ] Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] Week 5: Changing Security Behaviors Monday 2/24: Adversary Persona Development - Steve & Sean ( Adversary Cards ) Threat Scenario Development - Sean & Steve ( Resource Game ) Wednesday 2/26: Changing Behaviors within PVOs - Steve Weber, Professor, School of Information & Department of Political Science Read (by next week): Micah Lee. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] (Watch) Rachel Tobac. \u201cHow I would Hack You: Social Engineering Step-by-Step\u201d [ https://www.youtube.com/watch?v=L5J2PgGOLtE ] Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] EFF. \u201cAm I the Right Person?\u201d [https://sec.eff.org/articles/right-person-to-train] EFF. \u201cHow to Teach Adults\u201d [ https://sec.eff.org/articles/how-to-teach-adults ] (Skim) Weidinger et al. \u201cDigital Security Training Resources for Security Trainers, Fall 2019 Edition\u201d [ https://medium.com/cryptofriends/digital-security-training-resources-for-security-trainers-spring-2017-edition-e95d9e50065e ] Week 6: Security Control Selection Monday 3/2: Social Engineering (Phishing Sim Demonstration) - Steve Wednesday 3/4: Designing Security Training - Alexis Hancock (Staff Technologist, Electronic Frontier Foundation) & Soraya Okuda (Designer, Security Education Companion, EFF) Assignments: Due 3/6 6:00PM Draft Work Plan and Partner Report to Teaching Team [Team] Due 3/6 6:00PM Team Evaluation 1 [Individual] Read (by next week): Additional Readings To Be Added (Explore) Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/wiki/Main_Page ] (Explore) Mitre\u2019s Common Vulnerabilities and Exposures search.[ https://cve.mitre.org/cve/ ] (Optional) Scott, James C. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ] Week 7: Legal and Policy Considerations Monday, 3/9: Legal and Policy Factors For Non-Profits\u2019 Cybersecurity - Kristin Berdan, Clinic Fellow, former Google Security Legal Counsel Wednesday, 3/11: Midterm Project Presentations with Special Guest(s) Assignments: 3/13 6:00 PM: Work Plan and Partner Report to Partner [Team] Read (by next week): Amnesty International. \u201cDigitally dissecting atrocities \u2013 Amnesty International\u2019s open source investigations.\u201d [ https://www.amnesty.org/en/latest/news/2018/09/digitally-dissecting-atrocities-amnesty-internationals-open-source-investigations/ ] Sarah Jeong, Charlie Warzel, Brianna Wu, Joan Donovan. New York Times. \u201cEverything is GamerGate\u201d [ https://www.nytimes.com/interactive/2019/08/15/opinion/gamergate-twitter.html ] - Read all of the four essays. Angela Chen. The Verge. \u201cModerating content doesn\u2019t have to be so traumatic\u201d [ https://www.theverge.com/2019/2/27/18243359/content-moderation-mental-health-ptsd-psychology-science-facebook ] Sam Dubberley & Michele Grant. First Draft. \u201cJournalism and Vicarious Trauma\u201d [ https://firstdraftnews.org/wp-content/uploads/2017/04/vicarioustrauma.pdf ] (Explore) The rest of EFF\u2019s Security Education Companion. [ https://sec.eff.org/ ] Week 8: Resiliency -- Self and Community Care Monday, 3/16: Psychosocial Resilience, Andrea Lampros & Gisela Perez de Acha, Human Rights Center Wednesday, 3/18: SAVE THE DATE: Community Service Assignment Week 9: Spring Break Monday, 3/23: No Class Wednesday, 3/25: No Class Read (by next week): IFTF \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51. [ http://www.iftf.org/statesponsoredtrolling ] Cindy Otis. USA Today. \u201cAmericans could be a bigger fake news threat than Russians in the 2020 presidential campaign\u201d [ https://www.usatoday.com/story/opinion/2019/07/19/disinformation-attacks-americans-threaten-2020-election-column/1756092001/ ] InterAction \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Optional) Tahmina Ansari. First Draft. \u201cThis Muslim journalist embraced social media until it \u2018ruined\u2019 his life\u201d [ https://firstdraftnews.org/this-muslim-journalist-embraced-social-media-until-it-ruined-his-life/ ] Week 10: Beyond Hacking -- Disinformation and Harassment Monday, 3/30: Organizational Risks of Harmful Information - Steve Wednesday, 4/1: Mitigations for the Risks of Harmful Information - Steve Week 11: Clinic Work \u201cClinic Core Hours\u201d refers to the required student work during official class meeting hours between 12:00PM and 2:00PM. Mondays will usually be reserved for instruction specific to partner needs, feedback and guidance from the teaching team, and ad-hoc lectures. Every Monday, each team will have a 15 to 20-minute check-in with the teaching team. Each team member will provide a ~5 minute update on the progress of their assigned partner-related work. Students will usually be able to schedule team or partner meetings on Wednesdays pending adjustments by the teaching team. Monday, 4/6: Clinic Core Hours / Team Check-In Wednesday, 4/8: Clinic Core Hours Week 12: Clinic Work Monday, 4/13: Clinic Core Hours / Team Check-in Wednesday, 4/15: Clinic Core Hours Week 13: Clinic Work Monday, 4/20: Clinic Core Hours / Team Check-in Wednesday, 4/22: Clinic Core Hours Week 14: Clinic Work Monday, 4/27: Clinic Core Hours / Team Check-in Wednesday, 4/29: Clinic Core Hours Assignments: 5/1 6:00PM: Final Partner Report for Teaching Team Review [Team] Week 15 (RRR Week): Wrap-up & Project Presentations Monday, 5/4 - Course Wrap-up: Feedback on deliverables, submit all final deliverables. Wednesday, 5/6 - Project Presentations: An overview of partner work, findings, recommendations delivered to CLTC and stakeholders. Assignments: 5/5 6:00PM : Final Presentation Slides Submitted [Team] 5/8 6:00PM: Final Partner Report Submitted to Partner [Team] 5/8 6:00PM: Case Study Write-up [Team] 5/8 6:00PM: Team Evaluation 2 [Individual] Course policies Workload. This is a 4-unit class. Coursework will primarily focus on partner-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the partner. Evaluation. Assignments will largely be evaluated on the following rubric that emphasizes (1) sound rationale in assessments, recommendations, and reflections, (2) \u201cpartner-ready\u201d work products which reflect professional quality, and (3) completing the instructions of the assignment or the requirements agreed upon work plan with the partner. General Grading Rubric. Component 0 points 5 points 10 points Rationale Does not meet partner needs, introduces serious harms to partner, shows limited or inappropriate consideration for context Addresses most of partner needs, some oversight of potential harms to partner, mostly appropriate for given context. All partner needs are met, feasible & effective rationale that addresses all major threats, appropriate for given context. Professionalism Hard to understand, full of jargon, serious writing/format errors present, tone / design unsuitable for its audience Writing is mostly understandable; minor writing/format errors (typos), mostly appropriate tone / design \u201cpartner-ready,\u201d clear and concise writing, almost no writing/formatting errors, appropriate tone & design for its audience Requirements Some requirements in assignment or work plan not met; no insights or connections to readings/lectures; for group work: no evidence of group work Most requirements met, some evidence for connections with readings/lectures; for group work: some evidence of group work All requirements met, with clear, thoughtful insights and multiple cited connections to relevant readings/lectures; for group work: full evidence of strong, equitable collaboration Note: Students taking the course for P/NP or S/U are expected to participate in classes and complete all work to the same level of quality as students taking the course for a letter grade. Assignments. 1. Partner Deliverables - 60% The largest portion of graded evaluation will be based upon your team\u2019s work and support for its assigned partner. These deliverables may include assessments, recommendations, and guides, each tailored towards the partner\u2019s needs. Each team will also deliver a final report summarizing work performed with their partner. 2. Individual Assignments - 10% Two individual assignments will be given: Current Event Topic Leader (5%): Each student will sign up to lead one 15 minute discussion at the beginning of most lectures. Students will be expected to locate and share about a recent, current event relevant to the day\u2019s lecture topic. Topic leaders will emphasize interesting or relevant points while other students are expected to ask questions and comment. Community Service (5%): Students will be expected to participate in a project or event that contributes to assist the security practice of various cross-campus or community partners conducting politically-sensitive work. The teaching team will direct this contribution. 3. Team Case Study - 10% We want students to be able to discuss and share their experience in the course with others, including future employers. We also want our partners to remain confidential and protected. This being said, each student team will submit a write-up of work performed and takeaways with sensitive information removed. The teaching team will review to ensure your experience is captured in an effective & safe manner. 4. Participation - 10% We consider \u201cparticipation\u201d in three major components: participating in regular class discussions, participating in weekly mentor meetings, and participating in team & partner meeting outside of class hours. You are expected to attend each official class meeting and contribute substantially to class discussions. The teaching team should be notified in advance of absences from class meetings (including Clinic Core Hours). You do not need to share the reason for the absence. Not showing up to team check-ins will also negatively impact this grade. You are expected to meet with your mentor team at least once a week. This meeting may take place via teleconference. We will get feedback from mentors if they have not met with you without reasonable cause. As a rule, two people from your team must attend any partner meeting or call. While you may not be able to attend every team meeting and partner engagement outside of normal class hours, you are expected to attend and contribute to your team\u2019s effort as often as possible. 5. Team Evaluations - 10% Throughout the course, you will submit confidential evaluation forms which ask you to evaluate the contributions of each team member including yourself. Your final course grade will be adjusted, higher or lower, if you are contributing more or less than those within your group. If there are difficulties with any team member, discuss the matter within your team and seek resolution. If you cannot resolve the problem, immediately contact any faculty member, so that we can make an appointment to discuss the situation individually or with the entire group as needed. Late assignments. As we want to respect the time of our partners and ensure a high level of quality control (the teaching team will review deliverables before it reaches the partner), we expect students to adhere to timelines and due dates. Each day an assignment is late will result in a letter grade deduction. Recognizing that emergencies arise and partners may require schedule adjustments, exceptions will be made on a case-by-case basis. Code of Conduct. Each student enrolled in the course must agree in writing to the Citizen Clinic\u2019s Code of Conduct (to be distributed) for maintaining a safe and secure learning experience and partner relationship. This Code of Conduct will be respected by all students, the teaching team, and CLTC staff and it is the responsibility of all personnel to report possible violations of the Code of Conduct to the teaching team. Additionally, we expect all students to abide by the Berkeley Student Code of Conduct (see https://sa.berkeley.edu/student-code-of-conduct ) and act with honesty, integrity, and respect for others. (See also https://diversity.berkeley.edu/principles-community ). The consequences for failing to act within these standards may include failing an assignment, a referral to the Center for Student Conduct and Community Standards, a failed grade in the course, and even immediate expulsion. A note on plagiarism: even in the scope of providing a partner with a walkthrough for securing a certain account or system, you are expected not to copy material from another guide, website, article or book (word-for-word or paraphrased) without citing the source - it\u2019s a small community and we should give credit where it is due. Other examples of unacceptable conduct include turning in deliverables created by students not currently in the course, work found on the Internet, or created by a commercial service. Disability Accommodation . If you need disability-related accommodations in this class, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please inform us as soon as possible.","title":"Spring 2020"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#course-description","text":"For individuals and organizations involved in political advocacy, cybersecurity threats are an increasingly common reality of operating in the digital world. Civil society has always been under attack from ideological, political, and governmental opponents who seek to silence dissenting opinions, but the widespread adoption of connected technologies by the individuals and organizations that make up civil society creates a new class of vulnerabilities. Citizen Clinic at the Center for Long-Term Cybersecurity provides students with real-world experience assisting politically vulnerable organizations and persons around the world to develop and implement sound cybersecurity practices. Clinic students will participate in both a classroom and clinic component. In the classroom, students will study the basic theories and practices of digital security, the intricacies of protecting largely under-resourced organizations, and the tools needed to manage risk in complex political, sociological, legal, and ethical contexts. In the clinic component, students will work in teams supervised by the Clinic staff to provide direct cybersecurity assistance to civil society organizations. Students\u2019 clinic responsibilities will include learning about an organization\u2019s mission and context, assessing its vulnerabilities, and ultimately recommending and implementing mitigations to the identified security risks. The emphasis will be on pragmatic, workable solutions that take into account the unique operational needs of each partner organization.Weekly lectures will provide students with the background information and tools they will need to engage with partners. Coursework will focus on partner-facing, hands-on projects. Students will be expected to work an average of 12 hours per week, although the distribution of this workload may fluctuate based upon the availability and needs of the partner. Schedule. In the first half of the semester, class meetings will be a mix of lectures & discussions with more technical & project-oriented labs. In the second half of the semester, these class times will be reserved for work with the teaching team and check-ins tailored to the specific needs of your partner organization. Note: This schedule is tentative and may be adjusted - assignment dates may change, additional readings may be assigned, speakers/lectures may be shuffled, etc. The teaching team will announce when changes are made.","title":"Course Description."},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-0-introduction-what-is-public-interest-cybersecurity","text":"Wednesday 1/22: Introduction to Public Interest Cybersecurity: We will introduce the content and methods of the course, answer your questions, and everyone will introduce themselves to one another. Assignments: Due Friday 1/24 6:00PM: Submit application materials to enroll in this course. You will be notified of your enrollment status prior to the next class meeting on January 27th. Due Monday 1/27 before class: Read pages 7 - 21 & 48 - 52 of \u201cAn Introduction to Cybersecurity Ethics\u201d (Shannon Vallor, The Markkula Center for Applied Ethics) [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Prepare answers to questions on pages 15 - 17 and page 53 for in-class discussion. Read (by next week): Shannon Vallor, The Markkula Center for Applied Ethics, \u201cAn Introduction to Cybersecurity Ethics\u201d pages 7 - 21 & 48 - 52. [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Sandro Contenta, Toronto Star, \u201cHow these Toronto sleuths are exposing the world\u2019s digital spies while risking their own lives\u201d [ https://www.thestar.com/news/canada/2019/12/13/from-a-tower-in-toronto-they-watch-the-watchers-how-citizen-lab-sleuths-are-exposing-the-worlds-digital-spies-while-risking-their-own-lives.html ] Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] (Explore & use) Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] (Skim) Tactical Tech's Annual Report [ https://cdn.ttc.io/s/tacticaltech.org/Tactical-Tech-2018-Annual-Report.pdf ] (Optional) Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] (Optional) Rus Shuler. \u201cHow Does the Internet Work?\u201d [ web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm ]","title":"Week 0: Introduction / What is Public-Interest Cybersecurity?"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-1-code-of-conduct-and-ethics-in-cybersecurity","text":"Monday 1/27: Ethics and \u201cRules of the Road\u201d - Steve Citizen Clinic Code of Conduct. Ethical Considerations. Security Response Plan. Wednesday 1/29: Old School INFOSEC: Basic (& Some Outdated) Controls - Steve & Sean Clinic Communications Setup - Steve Partner Overview - Sean Assignments: Due 1/27 before class: Prepare answers to questions on pages 15 - 17 and page 53 of \u201cIntro to Cybersecurity Ethics\u201d for in-class discussion. [Individual] Due 1/27 In-Class: Code of Conduct Signed [Individual] Due 1/31 6:00PM: Equipment Setup Completed & Partner Preference Submitted [Individual] Read (by next week): Electronic Frontier Foundation, \u201cSurveillance Self-Defense: Your Security Plan\u201d [ https://ssd.eff.org/en/playlist/activist-or-protester#your-security-plan ] - know the definitions of underlined terms. Jorge Luis Sierra \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://freedomhouse.org/sites/default/files/Digital%20and%20Mobile%20Security%20for%20Mexican%20Journalists%20and%20Bloggers.pdf ] Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] SAFETAG Guide. Skim to Section 2.2, then read Section 2.2 and Section 2.3. [ https://safetag.org/guide/ ] (Read and Explore Examples) About PESTLE (use an ad-blocker!) [ https://pestleanalysis.com/what-is-pestle-analysis/ ] (Optionally Watch) CLTC / TechSoup. Webinar. \u201cCybersecurity in Low-Risk Organizations: Understanding Your Risk and Making Practical Improvements.\u201d: [ https://cltc.berkeley.edu/2019/02/25/cltc-and-citizen-clinic-present-cybersecurity-in-low-risk-organizations-webinar/ ]","title":"Week 1: Code of Conduct and Ethics in Cybersecurity"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-2-assessing-civil-society-organizations","text":"Monday 2/3: Threat Modeling & Bounding Risk Assessments - Sean Wednesday 2/5: Contextual & Capacity Research - Steve SAFETAG PESTLE-M Assignments: Due 2/5 6:00PM: Internal Collaborative Plan [Team] Due 2/7 6:00PM: Mentor Communications Established [Team] Read (by next week): Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Silver & Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] Arthur Turner. \u201cConsulting Is More Than Giving Advice.\u201d [ https://hbr.org/1982/09/consulting-is-more-than-giving-advice ] Netgain \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] (Optional) Thomas Wedell-Wedellsborg. \u201cAre You Solving the Right Problems?\u201d [ https://hbr.org/2017/01/are-you-solving-the-right-problems ] (Optional) Joseph Cox. \u201cI Gave a Bounty Hunter $300. Then He Located Our Phone\u201d [ https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile ] (Optional) Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ]","title":"Week 2: Assessing Civil Society Organizations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-3-understanding-threats-to-civil-society-organizations","text":"Monday 2/10: Digital Surveillance of PVOs: The Threat Landscape - Bill Marczak, Citizen Lab, Citizen Clinic Resident Wednesday 2/12: Contextual Research Recap & Information Gathering - Steve Problem Diagnosis and Reframing - Sean Assignments: Due 2/14 6:00PM : Partner Communications Established [Team] Read (by next week): NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf or Shutdown Mirror ] (Skim) NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf or Shutdown Mirror ] (Skim) NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf or Shutdown Mirror ] Protective Intelligence. \u201cPart I: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt1 ] Protective Intelligence. \u201cPart 2: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt2 ] Ian Barwise. \u201cOpen-Source Intelligence (OSINT) Reconnaissance\u201d [ https://medium.com/@z3roTrust/open-source-intelligence-osint-reconnaissance-75edd7f7dada ] (Explore) OSINT Framework [ https://osintframework.com/ ] (Explore) OSINT.link [ https://osint.link ] (Explore) Awesome OSINT [ https://github.com/jivoi/awesome-osint ] (Try) SECALERTS - Automated Security Audit [ https://secalerts.co/security-audit ]","title":"Week 3: Understanding Threats to Civil Society Organizations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-4-osint-collection","text":"Monday 2/17: No Class Wednesday 2/19: Open Source Research Methods, Safety, and Tools - Steve Virtual Networks: VPNs vs TOR Virtual Machines Virtual Identities Manual Searches & Google Hacking Automated Tools Read (by next week): Example Risk Assessment shared via email. Julian Cohen. \u201cPlaybook Based Testing.\u201d [ https://medium.com/@HockeyInJune/playbook-based-testing-5df4b656113a ] MSFT\u2019s STRIDE and related blog posts. [ https://cloudblogs.microsoft.com/microsoftsecure/2007/09/11/stride-chart/ ] Bill Marczak and John Scott-Railton. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] The Engine Room. \u201cTies That Bind: Organisational Security for Civil Society\u201d - read Full Report. [ https://www.theengineroom.org/civil-society-digital-security-new-research/ ] APF et al. \u201cImproving SSL Warnings: Comprehension and Adherence\u201d [ https://dl.acm.org/citation.cfm?id=2702442 ] Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ]","title":"Week 4: OSINT Collection"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-5-changing-security-behaviors","text":"Monday 2/24: Adversary Persona Development - Steve & Sean ( Adversary Cards ) Threat Scenario Development - Sean & Steve ( Resource Game ) Wednesday 2/26: Changing Behaviors within PVOs - Steve Weber, Professor, School of Information & Department of Political Science Read (by next week): Micah Lee. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] (Watch) Rachel Tobac. \u201cHow I would Hack You: Social Engineering Step-by-Step\u201d [ https://www.youtube.com/watch?v=L5J2PgGOLtE ] Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] EFF. \u201cAm I the Right Person?\u201d [https://sec.eff.org/articles/right-person-to-train] EFF. \u201cHow to Teach Adults\u201d [ https://sec.eff.org/articles/how-to-teach-adults ] (Skim) Weidinger et al. \u201cDigital Security Training Resources for Security Trainers, Fall 2019 Edition\u201d [ https://medium.com/cryptofriends/digital-security-training-resources-for-security-trainers-spring-2017-edition-e95d9e50065e ]","title":"Week 5: Changing Security Behaviors"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-6-security-control-selection","text":"Monday 3/2: Social Engineering (Phishing Sim Demonstration) - Steve Wednesday 3/4: Designing Security Training - Alexis Hancock (Staff Technologist, Electronic Frontier Foundation) & Soraya Okuda (Designer, Security Education Companion, EFF) Assignments: Due 3/6 6:00PM Draft Work Plan and Partner Report to Teaching Team [Team] Due 3/6 6:00PM Team Evaluation 1 [Individual] Read (by next week): Additional Readings To Be Added (Explore) Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/wiki/Main_Page ] (Explore) Mitre\u2019s Common Vulnerabilities and Exposures search.[ https://cve.mitre.org/cve/ ] (Optional) Scott, James C. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ]","title":"Week 6: Security Control Selection"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-7-legal-and-policy-considerations","text":"Monday, 3/9: Legal and Policy Factors For Non-Profits\u2019 Cybersecurity - Kristin Berdan, Clinic Fellow, former Google Security Legal Counsel Wednesday, 3/11: Midterm Project Presentations with Special Guest(s) Assignments: 3/13 6:00 PM: Work Plan and Partner Report to Partner [Team] Read (by next week): Amnesty International. \u201cDigitally dissecting atrocities \u2013 Amnesty International\u2019s open source investigations.\u201d [ https://www.amnesty.org/en/latest/news/2018/09/digitally-dissecting-atrocities-amnesty-internationals-open-source-investigations/ ] Sarah Jeong, Charlie Warzel, Brianna Wu, Joan Donovan. New York Times. \u201cEverything is GamerGate\u201d [ https://www.nytimes.com/interactive/2019/08/15/opinion/gamergate-twitter.html ] - Read all of the four essays. Angela Chen. The Verge. \u201cModerating content doesn\u2019t have to be so traumatic\u201d [ https://www.theverge.com/2019/2/27/18243359/content-moderation-mental-health-ptsd-psychology-science-facebook ] Sam Dubberley & Michele Grant. First Draft. \u201cJournalism and Vicarious Trauma\u201d [ https://firstdraftnews.org/wp-content/uploads/2017/04/vicarioustrauma.pdf ] (Explore) The rest of EFF\u2019s Security Education Companion. [ https://sec.eff.org/ ]","title":"Week 7: Legal and Policy Considerations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-8-resiliency-self-and-community-care","text":"Monday, 3/16: Psychosocial Resilience, Andrea Lampros & Gisela Perez de Acha, Human Rights Center Wednesday, 3/18: SAVE THE DATE: Community Service Assignment","title":"Week 8: Resiliency -- Self and Community Care"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-9-spring-break","text":"Monday, 3/23: No Class Wednesday, 3/25: No Class Read (by next week): IFTF \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51. [ http://www.iftf.org/statesponsoredtrolling ] Cindy Otis. USA Today. \u201cAmericans could be a bigger fake news threat than Russians in the 2020 presidential campaign\u201d [ https://www.usatoday.com/story/opinion/2019/07/19/disinformation-attacks-americans-threaten-2020-election-column/1756092001/ ] InterAction \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Optional) Tahmina Ansari. First Draft. \u201cThis Muslim journalist embraced social media until it \u2018ruined\u2019 his life\u201d [ https://firstdraftnews.org/this-muslim-journalist-embraced-social-media-until-it-ruined-his-life/ ]","title":"Week 9: Spring Break"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-10-beyond-hacking-disinformation-and-harassment","text":"Monday, 3/30: Organizational Risks of Harmful Information - Steve Wednesday, 4/1: Mitigations for the Risks of Harmful Information - Steve","title":"Week 10: Beyond Hacking -- Disinformation and Harassment"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-11-clinic-work","text":"\u201cClinic Core Hours\u201d refers to the required student work during official class meeting hours between 12:00PM and 2:00PM. Mondays will usually be reserved for instruction specific to partner needs, feedback and guidance from the teaching team, and ad-hoc lectures. Every Monday, each team will have a 15 to 20-minute check-in with the teaching team. Each team member will provide a ~5 minute update on the progress of their assigned partner-related work. Students will usually be able to schedule team or partner meetings on Wednesdays pending adjustments by the teaching team. Monday, 4/6: Clinic Core Hours / Team Check-In Wednesday, 4/8: Clinic Core Hours","title":"Week 11: Clinic Work"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-12-clinic-work","text":"Monday, 4/13: Clinic Core Hours / Team Check-in Wednesday, 4/15: Clinic Core Hours","title":"Week 12: Clinic Work"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-13-clinic-work","text":"Monday, 4/20: Clinic Core Hours / Team Check-in Wednesday, 4/22: Clinic Core Hours","title":"Week 13: Clinic Work"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-14-clinic-work","text":"Monday, 4/27: Clinic Core Hours / Team Check-in Wednesday, 4/29: Clinic Core Hours Assignments: 5/1 6:00PM: Final Partner Report for Teaching Team Review [Team]","title":"Week 14: Clinic Work"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#week-15-rrr-week-wrap-up-project-presentations","text":"Monday, 5/4 - Course Wrap-up: Feedback on deliverables, submit all final deliverables. Wednesday, 5/6 - Project Presentations: An overview of partner work, findings, recommendations delivered to CLTC and stakeholders. Assignments: 5/5 6:00PM : Final Presentation Slides Submitted [Team] 5/8 6:00PM: Final Partner Report Submitted to Partner [Team] 5/8 6:00PM: Case Study Write-up [Team] 5/8 6:00PM: Team Evaluation 2 [Individual]","title":"Week 15 (RRR Week): Wrap-up &amp; Project Presentations"},{"location":"Clinic_Curriculum/Clinic_Syllabus_Spring_2020/#course-policies","text":"Workload. This is a 4-unit class. Coursework will primarily focus on partner-facing projects while weekly lectures will be used to inform and engage with students\u2019 hands-on experiences. Students are expected to work an average of 12 hours per week on this course, however the distribution of this workload may fluctuate based on the availability and needs of the partner. Evaluation. Assignments will largely be evaluated on the following rubric that emphasizes (1) sound rationale in assessments, recommendations, and reflections, (2) \u201cpartner-ready\u201d work products which reflect professional quality, and (3) completing the instructions of the assignment or the requirements agreed upon work plan with the partner. General Grading Rubric. Component 0 points 5 points 10 points Rationale Does not meet partner needs, introduces serious harms to partner, shows limited or inappropriate consideration for context Addresses most of partner needs, some oversight of potential harms to partner, mostly appropriate for given context. All partner needs are met, feasible & effective rationale that addresses all major threats, appropriate for given context. Professionalism Hard to understand, full of jargon, serious writing/format errors present, tone / design unsuitable for its audience Writing is mostly understandable; minor writing/format errors (typos), mostly appropriate tone / design \u201cpartner-ready,\u201d clear and concise writing, almost no writing/formatting errors, appropriate tone & design for its audience Requirements Some requirements in assignment or work plan not met; no insights or connections to readings/lectures; for group work: no evidence of group work Most requirements met, some evidence for connections with readings/lectures; for group work: some evidence of group work All requirements met, with clear, thoughtful insights and multiple cited connections to relevant readings/lectures; for group work: full evidence of strong, equitable collaboration Note: Students taking the course for P/NP or S/U are expected to participate in classes and complete all work to the same level of quality as students taking the course for a letter grade. Assignments. 1. Partner Deliverables - 60% The largest portion of graded evaluation will be based upon your team\u2019s work and support for its assigned partner. These deliverables may include assessments, recommendations, and guides, each tailored towards the partner\u2019s needs. Each team will also deliver a final report summarizing work performed with their partner. 2. Individual Assignments - 10% Two individual assignments will be given: Current Event Topic Leader (5%): Each student will sign up to lead one 15 minute discussion at the beginning of most lectures. Students will be expected to locate and share about a recent, current event relevant to the day\u2019s lecture topic. Topic leaders will emphasize interesting or relevant points while other students are expected to ask questions and comment. Community Service (5%): Students will be expected to participate in a project or event that contributes to assist the security practice of various cross-campus or community partners conducting politically-sensitive work. The teaching team will direct this contribution. 3. Team Case Study - 10% We want students to be able to discuss and share their experience in the course with others, including future employers. We also want our partners to remain confidential and protected. This being said, each student team will submit a write-up of work performed and takeaways with sensitive information removed. The teaching team will review to ensure your experience is captured in an effective & safe manner. 4. Participation - 10% We consider \u201cparticipation\u201d in three major components: participating in regular class discussions, participating in weekly mentor meetings, and participating in team & partner meeting outside of class hours. You are expected to attend each official class meeting and contribute substantially to class discussions. The teaching team should be notified in advance of absences from class meetings (including Clinic Core Hours). You do not need to share the reason for the absence. Not showing up to team check-ins will also negatively impact this grade. You are expected to meet with your mentor team at least once a week. This meeting may take place via teleconference. We will get feedback from mentors if they have not met with you without reasonable cause. As a rule, two people from your team must attend any partner meeting or call. While you may not be able to attend every team meeting and partner engagement outside of normal class hours, you are expected to attend and contribute to your team\u2019s effort as often as possible. 5. Team Evaluations - 10% Throughout the course, you will submit confidential evaluation forms which ask you to evaluate the contributions of each team member including yourself. Your final course grade will be adjusted, higher or lower, if you are contributing more or less than those within your group. If there are difficulties with any team member, discuss the matter within your team and seek resolution. If you cannot resolve the problem, immediately contact any faculty member, so that we can make an appointment to discuss the situation individually or with the entire group as needed. Late assignments. As we want to respect the time of our partners and ensure a high level of quality control (the teaching team will review deliverables before it reaches the partner), we expect students to adhere to timelines and due dates. Each day an assignment is late will result in a letter grade deduction. Recognizing that emergencies arise and partners may require schedule adjustments, exceptions will be made on a case-by-case basis. Code of Conduct. Each student enrolled in the course must agree in writing to the Citizen Clinic\u2019s Code of Conduct (to be distributed) for maintaining a safe and secure learning experience and partner relationship. This Code of Conduct will be respected by all students, the teaching team, and CLTC staff and it is the responsibility of all personnel to report possible violations of the Code of Conduct to the teaching team. Additionally, we expect all students to abide by the Berkeley Student Code of Conduct (see https://sa.berkeley.edu/student-code-of-conduct ) and act with honesty, integrity, and respect for others. (See also https://diversity.berkeley.edu/principles-community ). The consequences for failing to act within these standards may include failing an assignment, a referral to the Center for Student Conduct and Community Standards, a failed grade in the course, and even immediate expulsion. A note on plagiarism: even in the scope of providing a partner with a walkthrough for securing a certain account or system, you are expected not to copy material from another guide, website, article or book (word-for-word or paraphrased) without citing the source - it\u2019s a small community and we should give credit where it is due. Other examples of unacceptable conduct include turning in deliverables created by students not currently in the course, work found on the Internet, or created by a commercial service. Disability Accommodation . If you need disability-related accommodations in this class, if you have emergency medical information you wish to share with us, or if you need special arrangements in case the building must be evacuated, please inform us as soon as possible.","title":"Course policies"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/","text":"All Citizen Clinic currently or previously assigned readings in one place. Introduction to Public Interest Cybersecurity Sean Brooks, Center for Long-Term Cybersecurity. \u201cDefending Politically Vulnerable Organizations Online\u201d [ https://cltc.berkeley.edu/wp-content/uploads/2018/07/CLTC_Defending_PVOs.pdf ] Citizen Lab\u2019s \u201cAbout Us\u201d Paper. [ https://citizenlab.ca/wp-content/uploads/2018/05/18033-Citizen-Lab-booklet-p-E.pdf ] Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] Sandro Contenta, Toronto Star. \u201cHow these Toronto sleuths are exposing the world\u2019s digital spies while risking their own lives\u201d [ https://www.thestar.com/news/canada/2019/12/13/from-a-tower-in-toronto-they-watch-the-watchers-how-citizen-lab-sleuths-are-exposing-the-worlds-digital-spies-while-risking-their-own-lives.html ] Deji Olukotun, Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] Tactical Tech's Annual Report [ https://cdn.ttc.io/s/tacticaltech.org/Tactical-Tech-2018-Annual-Report.pdf ] Ethics and the Citizen Clinic Code of Conduct Citizen Clinic. \"Student Code of Conduct\" [ https://www.citizenclinic.io/Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/ ] Shannon Vallor, The Markkula Center for Applied Ethics. \u201cAn Introduction to Cybersecurity Ethics\u201d [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Old School INFOSEC: Basic (& Some Outdated) Controls Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] Sean Brooks, CLTC, TechSoup Webinar. \u201cCybersecurity in Low-Risk Organizations: Understanding Your Risk and Making Practical Improvements.\u201d: [ https://cltc.berkeley.edu/2019/02/25/cltc-and-citizen-clinic-present-cybersecurity-in-low-risk-organizations-webinar/ ] Electronic Frontier Foundation\u2019s Surveillance Self-Defense guide. [ https://ssd.eff.org/ ] Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] Rus Shuler. \u201cHow Does the Internet Work?\u201d [ web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm ] Digital Surveillance of Politically Vulnerable Organizations: The Threat Landscape Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ] Joseph Cox. \u201cI Gave a Bounty Hunter $300. Then He Located Our Phone\u201d [ https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile ] Vernon Silver and Ben Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] John Scott-Railton et al, Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ] Problem Diagnosis and Reframing Netgain. \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] Arthur Turner. \u201cConsulting Is More Than Giving Advice\u201d [ https://hbr.org/1982/09/consulting-is-more-than-giving-advice ] Thomas Wedell-Wedellsborg. \u201cAre You Solving the Right Problems?\u201d [ https://hbr.org/2017/01/are-you-solving-the-right-problems ] Threat Modeling & Bounding Risk Assessments Electronic Frontier Foundation, \u201cSurveillance Self-Defense: Your Security Plan\u201d [ https://ssd.eff.org/en/playlist/activist-or-protester#your-security-plan ] NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf or Shutdown Mirror ] NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf or Shutdown Mirror ] NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf or Shutdown Mirror ] Contextual & Capacity Research SAFETAG, Internews. \"SAFETAG Guide\" Skim to Section 2.2, then read Section 2.2 and Section 2.3. [ https://safetag.org/guide/ ] Read and Explore Examples About PESTLE. (use an ad-blocker!) [ https://pestleanalysis.com/what-is-pestle-analysis/ ] Jorge Luis Sierra. \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://freedomhouse.org/sites/default/files/Digital%20and%20Mobile%20Security%20for%20Mexican%20Journalists%20and%20Bloggers.pdf ] Information Gathering Ruba Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] Jeanette Blomberg et al. \"An Ethnographic Approach to Design\" [ https://www.researchgate.net/publication/262363851_An_Ethnographic_Approach_to_Design ] Jenna Burrell. \"The Field Site as a Network: A Strategy for Locating Ethnographic Research\" [ https://doi.org/10.1177/1525822X08329699 ] Collaboration on International ICT Policy in East and Southern Africa. \u201cSafeguarding Civil Society: Assessing Internet Freedom and the Digital Resilience of Civil Society in East Africa\u201d - Read each chapter, but for one country only. [ https://cipesa.org/?wpfb_dl=237 ] Lofland and Lofland. Read Chapter 5 (66-98) \"Logging Data\" in \"Analyzing social settings: A guide to qualitative observation and analysis\" [ https://searchworks.stanford.edu/view/10531063 ] Open Source Research Methods, Safety, and Tools Awesome OSINT [ https://github.com/jivoi/awesome-osint ] Ian Barwise. \u201cOpen-Source Intelligence (OSINT) Reconnaissance\u201d [ https://medium.com/@z3roTrust/open-source-intelligence-osint-reconnaissance-75edd7f7dada ] Conor Fortune, Amnesty International. \u201cDigitally dissecting atrocities \u2013 Amnesty International\u2019s open source investigations.\u201d [ https://www.amnesty.org/en/latest/news/2018/09/digitally-dissecting-atrocities-amnesty-internationals-open-source-investigations/ ] OSINT Framework [ https://osintframework.com/ ] OSINT.link [ https://osint.link ] Travis Lishok, Protective Intelligence. \u201cPart I: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt1 ] Travis Lishok, Protective Intelligence. \u201cPart 2: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt2 ] SECALERTS - Automated Security Audit [ https://secalerts.co/security-audit ] Security Law and Policy Factors James C. Scott. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ] Kim Fong et al. \u201cA CRIMSon Tide of Data: An Assessment of Potential Privacy Problems of the Consolidate Records Information Management System\u201d [ http://people.ischool.berkeley.edu/~strush/CRIMS_FongRowlandTrush_Feb2018.pdf ] Adversary Persona Development Julian Cohen. \u201cPlaybook Based Testing.\u201d [ https://medium.com/@HockeyInJune/playbook-based-testing-5df4b656113a ] Bill Marczak and John Scott-Railton, Citizen Lab. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] Nick Merrill, Daylight Security Research Lab. \"Adversary Personas\" [ https://daylight.berkeley.edu/adversary-personas/ ] Microsoft\u2019s STRIDE and related blog posts. [ https://cloudblogs.microsoft.com/microsoftsecure/2007/09/11/stride-chart/ ] Threat Scenario Development Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/ ] Mitre\u2019s PRE-ATT&CK Techniques. [ https://attack.mitre.org/techniques/pre/ ] Mitre\u2019s Common Vulnerabilities and Exposures search.[ https://cve.mitre.org/cve/ ] Changing Security Behaviors The Engine Room. \u201cTies That Bind: Organisational Security for Civil Society\u201d [ https://www.theengineroom.org/civil-society-digital-security-new-research/ ] Adrienne Porter Felt et al. \u201cImproving SSL Warnings: Comprehension and Adherence\u201d [ https://dl.acm.org/citation.cfm?id=2702442 ] Francesca Musiani and Ksenia Ermoshina. \u201cWhat is a Good Secure Messaging Tool? The EFF Secure Messaging Scorecard and the Shaping of Digital (Usable) Security\u201d [ https://www.westminsterpapers.org/articles/10.16997/wpcc.265/ ] Alma Whitten and Doug Tygar. \u201cWhy Johnny Can\u2019t Encrypt\u201d [ https://www.usenix.org/legacy/publications/library/proceedings/sec99/full_papers/whitten/whitten_html/index.html ] Social Engineering and Phishing Citizen Clinic. \"Phishing Simulation Policy\" [ https://www.citizenclinic.io/Clinic_Infrastructure/Phishing_Simulation/ ] Masashi Crete-Nishihata et al, Citizen Lab. \"Spying on a Budget: Inside a Phishing Operation with Targets in the Tibetan Community\" [https://citizenlab.ca/2018/01/spying-on-a-budget-inside-a-phishing-operation-with-targets-in-the-tibetan-community/] ] Micah Lee, The Intercept. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] Rachel Tobac. Social Proof Security. \u201cHow I would Hack You: Social Engineering Step-by-Step\u201d [ https://www.youtube.com/watch?v=L5J2PgGOLtE ] Designing Security Training Electronic Frontier Foundation. \u201cAm I the Right Person?\u201d [https://sec.eff.org/articles/right-person-to-train] Electronic Frontier Foundation. \u201cHow to Teach Adults\u201d [ https://sec.eff.org/articles/how-to-teach-adults ] Browse the rest of EFF\u2019s Security Education Companion. [ https://sec.eff.org/ ] Rachel Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] Rachel Weidinger et al. \u201cDigital Security Training Resources for Security Trainers, Fall 2019 Edition\u201d [ https://medium.com/cryptofriends/digital-security-training-resources-for-security-trainers-spring-2017-edition-e95d9e50065e ] Psychosocial Resilience Angela Chen. The Verge. \u201cModerating content doesn\u2019t have to be so traumatic\u201d [ https://www.theverge.com/2019/2/27/18243359/content-moderation-mental-health-ptsd-psychology-science-facebook ] Sam Dubberley and Michele Grant. First Draft. \u201cJournalism and Vicarious Trauma\u201d [ https://firstdraftnews.org/wp-content/uploads/2017/04/vicarioustrauma.pdf ] Sarah Jeong, Charlie Warzel, Brianna Wu, Joan Donovan. New York Times. \u201cEverything is GamerGate\u201d [ https://www.nytimes.com/interactive/2019/08/15/opinion/gamergate-twitter.html ] - Read all of the four essays. Beyond Hacking: Harmful Information (Misinformation and Harassment) Tahmina Ansari, First Draft. \u201cThis Muslim journalist embraced social media until it \u2018ruined\u2019 his life\u201d [ https://firstdraftnews.org/this-muslim-journalist-embraced-social-media-until-it-ruined-his-life/ ] Nicholas Monaco and Carly Nyst. Institute For The Future. \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51. [ http://www.iftf.org/statesponsoredtrolling ] Sarah Oh and Travis L. Adkins. InterAction. \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Cindy Otis. USA Today. \u201cAmericans could be a bigger fake news threat than Russians in the 2020 presidential campaign\u201d [ https://www.usatoday.com/story/opinion/2019/07/19/disinformation-attacks-americans-threaten-2020-election-column/1756092001/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ]","title":"Course Readings"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#introduction-to-public-interest-cybersecurity","text":"Sean Brooks, Center for Long-Term Cybersecurity. \u201cDefending Politically Vulnerable Organizations Online\u201d [ https://cltc.berkeley.edu/wp-content/uploads/2018/07/CLTC_Defending_PVOs.pdf ] Citizen Lab\u2019s \u201cAbout Us\u201d Paper. [ https://citizenlab.ca/wp-content/uploads/2018/05/18033-Citizen-Lab-booklet-p-E.pdf ] Citizen Lab\u2019s Security Planner. [ https://securityplanner.org/ ] Sandro Contenta, Toronto Star. \u201cHow these Toronto sleuths are exposing the world\u2019s digital spies while risking their own lives\u201d [ https://www.thestar.com/news/canada/2019/12/13/from-a-tower-in-toronto-they-watch-the-watchers-how-citizen-lab-sleuths-are-exposing-the-worlds-digital-spies-while-risking-their-own-lives.html ] Deji Olukotun, Access Now. \u201cSpyware in Mexico: an interview with Luis Fernando Garc\u00eda of R3D Mexico\u201d [ https://www.accessnow.org/spyware-mexico-interview-luis-fernando-garcia-r3d-mexico/ ] Tactical Tech's Annual Report [ https://cdn.ttc.io/s/tacticaltech.org/Tactical-Tech-2018-Annual-Report.pdf ]","title":"Introduction to Public Interest Cybersecurity"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#ethics-and-the-citizen-clinic-code-of-conduct","text":"Citizen Clinic. \"Student Code of Conduct\" [ https://www.citizenclinic.io/Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/ ] Shannon Vallor, The Markkula Center for Applied Ethics. \u201cAn Introduction to Cybersecurity Ethics\u201d [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ]","title":"Ethics and the Citizen Clinic Code of Conduct"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#old-school-infosec-basic-some-outdated-controls","text":"Le Blond et al. \u201cA look at targeted attacks through the lense of an NGO\u201d [ www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-blond.pdf ] Sean Brooks, CLTC, TechSoup Webinar. \u201cCybersecurity in Low-Risk Organizations: Understanding Your Risk and Making Practical Improvements.\u201d: [ https://cltc.berkeley.edu/2019/02/25/cltc-and-citizen-clinic-present-cybersecurity-in-low-risk-organizations-webinar/ ] Electronic Frontier Foundation\u2019s Surveillance Self-Defense guide. [ https://ssd.eff.org/ ] Alex Gaynor. \u201cWhat happens when you type google.com into your browser's address box and press enter?\" [ https://github.com/alex/what-happens-when ] Rus Shuler. \u201cHow Does the Internet Work?\u201d [ web.stanford.edu/class/msande91si/www-spr04/readings/week1/InternetWhitepaper.htm ]","title":"Old School INFOSEC: Basic (&amp; Some Outdated) Controls"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#digital-surveillance-of-politically-vulnerable-organizations-the-threat-landscape","text":"Stephen Arnold. \u201cTelestrategies - An Interview with Dr. Jerry Lucas\u201d [ http://www.arnoldit.com/search-wizards-speak/telestrategies-2.html ] Joseph Cox. \u201cI Gave a Bounty Hunter $300. Then He Located Our Phone\u201d [ https://motherboard.vice.com/en_us/article/nepxbz/i-gave-a-bounty-hunter-300-dollars-located-phone-microbilt-zumigo-tmobile ] Vernon Silver and Ben Elgin. \u201cTorture in Bahrain Becomes Routine With Help From Nokia Siemens\u201d [ https://web.archive.org/web/20111006185329/http://www.bloomberg.com/news/2011-08-22/torture-in-bahrain-becomes-routine-with-help-from-nokia-siemens-networking.html ] John Scott-Railton et al, Citizen Lab. \u201cBittersweet: Supporters of Mexico\u2019s soda tax targeted with NSO exploit links\u201d [ https://citizenlab.ca/2017/02/bittersweet-nso-mexico-spyware/ ]","title":"Digital Surveillance of Politically Vulnerable Organizations: The Threat Landscape"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#problem-diagnosis-and-reframing","text":"Netgain. \u201cDigital Security and Grantcraft Guide\u201d [ fordfoundation.org/media/3334/digital-security-grantcraft-guide-v10-final-22317.pdf ] Arthur Turner. \u201cConsulting Is More Than Giving Advice\u201d [ https://hbr.org/1982/09/consulting-is-more-than-giving-advice ] Thomas Wedell-Wedellsborg. \u201cAre You Solving the Right Problems?\u201d [ https://hbr.org/2017/01/are-you-solving-the-right-problems ]","title":"Problem Diagnosis and Reframing"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#threat-modeling-bounding-risk-assessments","text":"Electronic Frontier Foundation, \u201cSurveillance Self-Defense: Your Security Plan\u201d [ https://ssd.eff.org/en/playlist/activist-or-protester#your-security-plan ] NIST SP 800-37 \u201cRisk Management Framework for Information Systems and Organizations.\u201d Chapter 2 only. [ https://csrc.nist.gov/CSRC/media/Publications/sp/800-37/rev-2/draft/documents/sp800-37r2-draft-ipd.pdf or Shutdown Mirror ] NIST SP 800-39 \u201cManaging Information Security Risk.\u201d Chapter 2 only. [ https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-39.pdf or Shutdown Mirror ] NISTIR 8062 \u201cAn Introduction to Privacy Engineering and Risk Management in Federal Systems.\u201d [ https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8062.pdf or Shutdown Mirror ]","title":"Threat Modeling &amp; Bounding Risk Assessments"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#contextual-capacity-research","text":"SAFETAG, Internews. \"SAFETAG Guide\" Skim to Section 2.2, then read Section 2.2 and Section 2.3. [ https://safetag.org/guide/ ] Read and Explore Examples About PESTLE. (use an ad-blocker!) [ https://pestleanalysis.com/what-is-pestle-analysis/ ] Jorge Luis Sierra. \u201cDigital and Mobile Security for Mexican Journalists and Bloggers\u201d [ https://freedomhouse.org/sites/default/files/Digital%20and%20Mobile%20Security%20for%20Mexican%20Journalists%20and%20Bloggers.pdf ]","title":"Contextual &amp; Capacity Research"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#information-gathering","text":"Ruba Abu-Salma et al. \u201cObstacles to the Adoption of Secure Communication Tools\u201d [ https://ieeexplore.ieee.org/abstract/document/7958575/ ] Jeanette Blomberg et al. \"An Ethnographic Approach to Design\" [ https://www.researchgate.net/publication/262363851_An_Ethnographic_Approach_to_Design ] Jenna Burrell. \"The Field Site as a Network: A Strategy for Locating Ethnographic Research\" [ https://doi.org/10.1177/1525822X08329699 ] Collaboration on International ICT Policy in East and Southern Africa. \u201cSafeguarding Civil Society: Assessing Internet Freedom and the Digital Resilience of Civil Society in East Africa\u201d - Read each chapter, but for one country only. [ https://cipesa.org/?wpfb_dl=237 ] Lofland and Lofland. Read Chapter 5 (66-98) \"Logging Data\" in \"Analyzing social settings: A guide to qualitative observation and analysis\" [ https://searchworks.stanford.edu/view/10531063 ]","title":"Information Gathering"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#open-source-research-methods-safety-and-tools","text":"Awesome OSINT [ https://github.com/jivoi/awesome-osint ] Ian Barwise. \u201cOpen-Source Intelligence (OSINT) Reconnaissance\u201d [ https://medium.com/@z3roTrust/open-source-intelligence-osint-reconnaissance-75edd7f7dada ] Conor Fortune, Amnesty International. \u201cDigitally dissecting atrocities \u2013 Amnesty International\u2019s open source investigations.\u201d [ https://www.amnesty.org/en/latest/news/2018/09/digitally-dissecting-atrocities-amnesty-internationals-open-source-investigations/ ] OSINT Framework [ https://osintframework.com/ ] OSINT.link [ https://osint.link ] Travis Lishok, Protective Intelligence. \u201cPart I: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt1 ] Travis Lishok, Protective Intelligence. \u201cPart 2: An Introduction To OSINT Research For Protective Intelligence Professionals\u201d [ https://www.protectiveintelligence.com/blog/osint-intro-for-protective-intelligence-pt2 ] SECALERTS - Automated Security Audit [ https://secalerts.co/security-audit ]","title":"Open Source Research Methods, Safety, and Tools"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#security-law-and-policy-factors","text":"James C. Scott. \u201cSeeing Like a State\u201d - Chapter 9 [ https://libcom.org/files/Seeing%20Like%20a%20State%20-%20James%20C.%20Scott.pdf ] Kim Fong et al. \u201cA CRIMSon Tide of Data: An Assessment of Potential Privacy Problems of the Consolidate Records Information Management System\u201d [ http://people.ischool.berkeley.edu/~strush/CRIMS_FongRowlandTrush_Feb2018.pdf ]","title":"Security Law and Policy Factors"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#adversary-persona-development","text":"Julian Cohen. \u201cPlaybook Based Testing.\u201d [ https://medium.com/@HockeyInJune/playbook-based-testing-5df4b656113a ] Bill Marczak and John Scott-Railton, Citizen Lab. \u201cKeep Calm and (Don\u2019t) Enable Macros: A New Threat Actor Targets UAE Dissidents\u201d [ https://citizenlab.ca/2016/05/stealth-falcon/ ] Nick Merrill, Daylight Security Research Lab. \"Adversary Personas\" [ https://daylight.berkeley.edu/adversary-personas/ ] Microsoft\u2019s STRIDE and related blog posts. [ https://cloudblogs.microsoft.com/microsoftsecure/2007/09/11/stride-chart/ ]","title":"Adversary Persona Development"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#threat-scenario-development","text":"Mitre\u2019s ATT&CK Wiki. [ https://attack.mitre.org/ ] Mitre\u2019s PRE-ATT&CK Techniques. [ https://attack.mitre.org/techniques/pre/ ] Mitre\u2019s Common Vulnerabilities and Exposures search.[ https://cve.mitre.org/cve/ ]","title":"Threat Scenario Development"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#changing-security-behaviors","text":"The Engine Room. \u201cTies That Bind: Organisational Security for Civil Society\u201d [ https://www.theengineroom.org/civil-society-digital-security-new-research/ ] Adrienne Porter Felt et al. \u201cImproving SSL Warnings: Comprehension and Adherence\u201d [ https://dl.acm.org/citation.cfm?id=2702442 ] Francesca Musiani and Ksenia Ermoshina. \u201cWhat is a Good Secure Messaging Tool? The EFF Secure Messaging Scorecard and the Shaping of Digital (Usable) Security\u201d [ https://www.westminsterpapers.org/articles/10.16997/wpcc.265/ ] Alma Whitten and Doug Tygar. \u201cWhy Johnny Can\u2019t Encrypt\u201d [ https://www.usenix.org/legacy/publications/library/proceedings/sec99/full_papers/whitten/whitten_html/index.html ]","title":"Changing Security Behaviors"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#social-engineering-and-phishing","text":"Citizen Clinic. \"Phishing Simulation Policy\" [ https://www.citizenclinic.io/Clinic_Infrastructure/Phishing_Simulation/ ] Masashi Crete-Nishihata et al, Citizen Lab. \"Spying on a Budget: Inside a Phishing Operation with Targets in the Tibetan Community\" [https://citizenlab.ca/2018/01/spying-on-a-budget-inside-a-phishing-operation-with-targets-in-the-tibetan-community/] ] Micah Lee, The Intercept. \u201cIt\u2019s Impossible To Prove Your Laptop Hasn\u2019t Been Hacked. I Spent Two Years Finding Out.\u201d [ https://theintercept.com/2018/04/28/computer-malware-tampering/ ] Rachel Tobac. Social Proof Security. \u201cHow I would Hack You: Social Engineering Step-by-Step\u201d [ https://www.youtube.com/watch?v=L5J2PgGOLtE ]","title":"Social Engineering and Phishing"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#designing-security-training","text":"Electronic Frontier Foundation. \u201cAm I the Right Person?\u201d [https://sec.eff.org/articles/right-person-to-train] Electronic Frontier Foundation. \u201cHow to Teach Adults\u201d [ https://sec.eff.org/articles/how-to-teach-adults ] Browse the rest of EFF\u2019s Security Education Companion. [ https://sec.eff.org/ ] Rachel Weidinger et al. \u201cHow To Give A Digital Security Training\u201d [ https://medium.com/@geminiimatt/how-to-give-a-digital-security-training-4c83af667d40 ] Rachel Weidinger et al. \u201cDigital Security Training Resources for Security Trainers, Fall 2019 Edition\u201d [ https://medium.com/cryptofriends/digital-security-training-resources-for-security-trainers-spring-2017-edition-e95d9e50065e ]","title":"Designing Security Training"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#psychosocial-resilience","text":"Angela Chen. The Verge. \u201cModerating content doesn\u2019t have to be so traumatic\u201d [ https://www.theverge.com/2019/2/27/18243359/content-moderation-mental-health-ptsd-psychology-science-facebook ] Sam Dubberley and Michele Grant. First Draft. \u201cJournalism and Vicarious Trauma\u201d [ https://firstdraftnews.org/wp-content/uploads/2017/04/vicarioustrauma.pdf ] Sarah Jeong, Charlie Warzel, Brianna Wu, Joan Donovan. New York Times. \u201cEverything is GamerGate\u201d [ https://www.nytimes.com/interactive/2019/08/15/opinion/gamergate-twitter.html ] - Read all of the four essays.","title":"Psychosocial Resilience"},{"location":"Clinic_Curriculum/Consolidated_Bibliography/#beyond-hacking-harmful-information-misinformation-and-harassment","text":"Tahmina Ansari, First Draft. \u201cThis Muslim journalist embraced social media until it \u2018ruined\u2019 his life\u201d [ https://firstdraftnews.org/this-muslim-journalist-embraced-social-media-until-it-ruined-his-life/ ] Nicholas Monaco and Carly Nyst. Institute For The Future. \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51. [ http://www.iftf.org/statesponsoredtrolling ] Sarah Oh and Travis L. Adkins. InterAction. \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Cindy Otis. USA Today. \u201cAmericans could be a bigger fake news threat than Russians in the 2020 presidential campaign\u201d [ https://www.usatoday.com/story/opinion/2019/07/19/disinformation-attacks-americans-threaten-2020-election-column/1756092001/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ]","title":"Beyond Hacking: Harmful Information (Misinformation and Harassment)"},{"location":"Clinic_Curriculum/Lesson_Modules/","text":"Lesson Modules Citizen Clinic modules consist of lectures, in-class activities, and homework assignments. These modules will be described, linked, and/or outlined below. Stay tuned for new modules added regularly! Published Modules. New! Module 2. Ethics and the Citizen Clinic Code of Conduct New! Module 7. Contextual & Capacity Research New! Module 11. Adversary Persona Development Upcoming Modules. Module 1. Introduction to Public Interest Cybersecurity Module 3. Old School INFOSEC: Basic (& Some Outdated) Controls Module 4. Digital Surveillance of Politically Vulnerable Organizations: The Threat Landscape Module 5. Problem Diagnosis and Reframing Module 6. Threat Modeling & Bounding Risk Assessments Module 8. Information Gathering Module 9. Open Source Research Methods, Safety, and Tools Module 10. Security Law and Policy Factors Module 12. Threat Scenario Development Module 13. Changing Security Behaviors Module 14. Social Engineering and Phishing Module 15. Designing Security Training Module 16. Psychosocial Resilience Module 17. Beyond Hacking: Harmful Information (Misinformation and Harassment)","title":"Index"},{"location":"Clinic_Curriculum/Lesson_Modules/#lesson-modules","text":"Citizen Clinic modules consist of lectures, in-class activities, and homework assignments. These modules will be described, linked, and/or outlined below. Stay tuned for new modules added regularly!","title":"Lesson Modules"},{"location":"Clinic_Curriculum/Lesson_Modules/#published-modules","text":"","title":"Published Modules."},{"location":"Clinic_Curriculum/Lesson_Modules/#new-module-2-ethics-and-the-citizen-clinic-code-of-conduct","text":"","title":"New! Module 2. Ethics and the Citizen Clinic Code of Conduct"},{"location":"Clinic_Curriculum/Lesson_Modules/#new-module-7-contextual-capacity-research","text":"","title":"New! Module 7. Contextual &amp; Capacity Research"},{"location":"Clinic_Curriculum/Lesson_Modules/#new-module-11-adversary-persona-development","text":"","title":"New! Module 11. Adversary Persona Development"},{"location":"Clinic_Curriculum/Lesson_Modules/#upcoming-modules","text":"Module 1. Introduction to Public Interest Cybersecurity Module 3. Old School INFOSEC: Basic (& Some Outdated) Controls Module 4. Digital Surveillance of Politically Vulnerable Organizations: The Threat Landscape Module 5. Problem Diagnosis and Reframing Module 6. Threat Modeling & Bounding Risk Assessments Module 8. Information Gathering Module 9. Open Source Research Methods, Safety, and Tools Module 10. Security Law and Policy Factors Module 12. Threat Scenario Development Module 13. Changing Security Behaviors Module 14. Social Engineering and Phishing Module 15. Designing Security Training Module 16. Psychosocial Resilience Module 17. Beyond Hacking: Harmful Information (Misinformation and Harassment)","title":"Upcoming Modules."},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/","text":"Summary What are adversary personas and why do we use them? Learning Objectives Enable students to think broadly and creatively about potential cybersecurity threats. Understand and build a realistic \"who\" behind security threats considering their identity, motivations, and resources. Pre-Readings See Course Readings for \"Adversary Personas\" Resources Daylight Security Research Lab's Adversary Persona Cards Activities Adversary Personas ( https://daylight.berkeley.edu/adversary-personas/ ) is an improvisational role-playing game designed to help teams think broadly and creatively about their cybersecurity threats. Developed by researchers from UC Berkeley's Daylight Security Research Lab ( https://daylight.berkeley.edu/adversary-personas/ ), the game focuses on the who of security, by forcing players to ask: who might our adversaries be, what do they want, and what would they be willing to go through to get it? The game can be played by teams of employees in any organization. It is recommended for groups of between 2-10 people. Download the game here . Follow the instructions listed here Discussion Input Deepening Synthesis Assignments","title":"Adversary Personas Overview"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#summary","text":"What are adversary personas and why do we use them?","title":"Summary"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#learning-objectives","text":"Enable students to think broadly and creatively about potential cybersecurity threats. Understand and build a realistic \"who\" behind security threats considering their identity, motivations, and resources.","title":"Learning Objectives"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#pre-readings","text":"See Course Readings for \"Adversary Personas\"","title":"Pre-Readings"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#resources","text":"Daylight Security Research Lab's Adversary Persona Cards","title":"Resources"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#activities","text":"Adversary Personas ( https://daylight.berkeley.edu/adversary-personas/ ) is an improvisational role-playing game designed to help teams think broadly and creatively about their cybersecurity threats. Developed by researchers from UC Berkeley's Daylight Security Research Lab ( https://daylight.berkeley.edu/adversary-personas/ ), the game focuses on the who of security, by forcing players to ask: who might our adversaries be, what do they want, and what would they be willing to go through to get it? The game can be played by teams of employees in any organization. It is recommended for groups of between 2-10 people. Download the game here . Follow the instructions listed here","title":"Activities"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#discussion","text":"","title":"Discussion"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#input","text":"","title":"Input"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#deepening","text":"","title":"Deepening"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#synthesis","text":"","title":"Synthesis"},{"location":"Clinic_Curriculum/Modules/Adversary_Personas/Adversary_Personas/#assignments","text":"","title":"Assignments"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/","text":"BACKGROUND Understand the history of the organization and its mission How did your organization form? What are its objectives? Mission: Year established: Brief history: Summary of current programs? Upcoming campaigns? INTERNAL FACTORS Understand the assets used to achieve the organization\u2019s goals PHYSICAL Where are you headquartered? Address(es): Reason for chosen location(s): Do you share this space with anyone outside the organization? Do you rent, own, borrow this space? What other facilities do you own or occupy? E.g. Satellite offices, warehouses, intermittent environments (temporary workspaces, conferences, workshops) What equipment do you rely on? (Will be explored more deeply in Device Inventory) Devices (computers, phones, tablets, routers, TVs, any other IoT like thermostat, alexa, etc.) Provided to employees? Or do employees use their own? Vehicles Own, rent? What other physical infrastructure does the organization depend upon? Power What is the regular system for providing power to the organization? On-grid, generator, solar? What backup power systems are available to the organization? Travel Are employees allowed to travel with organization-owned devices? What devices are they likely to travel with? Are \"travel devices\" available for employees to use? What is the organizational expectation of their use? Are employees likely to travel to locations where device theft is common? Are employees travelling through checkpoints (government, private, bandits, international)? Trash removal and other janitorial services & recycling How does the organization dispose of trash? How does the organization dispose of sensitive documents? How does the organization manage janitorial services for their workspace? How does the organization perform cleaning their offices or other workspace? Who conducts maintenance of physical infrastructure (plumbing, electricity)? POLITICAL How are you structured? Leadership team (executives): Board: Management structure: What politics are in play within the organization? What are the political affiliations of its board members and leaders? (in general, or any heavily political advisors) What are current political aspirations of current employees? Is anyone running for office? What are the internal relationships between members? Describe past and current internal conflicts -- organizational changes, layoffs & firing Immigration/Citizenship/Refugee status: Staff: Beneficiaries: ECONOMIC What is your business model? Corporate Structure (Non-profit, for-profit, hybrid) Dependencies Who are your Clients / Customers / Beneficiaries? Who are your Donors? Who are your other Funders (Grantors, Governments)? Who are your partners for Contracted Services? Current Financial Situation Describe your organization\u2019s Financial Health including inputs/outputs What is your Financial Infrastructure - Where/How are funds stored? Do you use Formal banking? Do you keep Cash on hand? Do you use Informal value transfer? Seasonality Are there specific times of year where you conduct certain programs or when fundraising or operations will intensify? Advertising and Publicity Operations (Avenues for advertising, press, publicity - how is your organization known?) Current Financial Situation What is your Internal Cash Flow & Funding Streams? What are your sources of Funding, grants, & Initiatives? SOCIAL Who keeps your organization running? Number of employees: Types of employees: Full-time, part-time, intern, volunteer, contractor Occupations & Salaries paid Demographics (ages, genders, ethnicities, tribes): Staff: Beneficiaries: Education Formal education of staff members Literacy of staff members Technological knowledge and proficiency Living Situations Geographic dispersal - where do staff live in relation to work? Where do they live in relation to beneficiaries? In relation to their family (Diaspora?)? Living conditions - what are the living conditions for staff? What is your organization\u2019s culture? Organizational Practices (of Staff or Beneficiaries) Which languages are used? What perspectives on Security exist? What perspectives on Privacy exist? Working environment Office bound? Remote workers? \u201cWork from home\u201d culture? Organizational Practices (of Staff or Beneficiaries) What norms are realized? What taboos exist? Hiring Practices Describe current hiring practices. How are people screened before employment? Describe current recruiting initiatives. How are people recruited? Leisure Activities Health Conditions Current issues Clinic / Medical Care Providers Insurance Providers TECHNOLOGICAL See Device Inventory and Technical assessment Do you currently have organizational policies for... Technology Use? System Access? Privacy or data protection? What are your future plans... For acquiring replacement technologies or solutions? For digitization of paper records or other assets? For conducting software upgrades? LEGAL Do you have an internal legal team or rely on outside counsel? What are your statutory & regulatory commitments for... Business / Financial? Ethical? Environmental? Data protection regulations (GDPR, etc)? Others? What are your current contractual obligations? Have there been past breaches of contract? Describe your organization\u2019s lawsuits & legal challenges in the... Past? Present? Future (Expected/Planned)? THREATS Consider... Organized Crime Nation State Professional Hacker (Individual / Collective) Hacktivists Corporations Terrorism Criminal (Scammer / Opportunist) Who were your past threats? What persons, groups, or organizations have threatened, attacked, or harmed your organization, its employees, or beneficiaries in the past? Cyberattacks Physical harms Other Crimes What prior attacks has your organization experienced in the past? Cyberattacks Physical harms Other Crimes Who are your current threats? What persons, groups, or organizations are your current threats to your organization? Cyberattacks Physical harms Other Crimes Which persons, groups, or organizations do you feel may harm your organization in the future? EXTERNAL FACTORS Factors beyond the organization\u2019s Control, but that are highly relevant to their functioning POLITICAL Support from Government Leadership of Organization\u2019s Missions or Causes Who are their supporters? Who are their opponents? Government Stability Any recent shifts of power or structure? Is there turmoil expected turmoil in the future? Are there ongoing or nascent insurgencies? External Stakeholders in Organization\u2019s Mission What other politicians or political groups are involved or impacted by the organization\u2019s work? What home pressure groups / lobbyists are for / against the organization\u2019s work? What international pressure groups / lobbyists are for / against the organization\u2019s work? Corruption in Government What is the country\u2019s general propensity & accountability for bribery, graft, etc? Are there past or current corruption scandals involving the above stakeholders? ECONOMIC Home economic situation Describe the general economic conditions in the home country. Are there ongoing crises related to recession, hyperinflation, or other decline? What is the unemployment rate? Trade Agreements What other countries are relevant trade partners? Are any countries involved in an ongoing trade war with the home country? SOCIAL Cultural Practices What other languages are used in the area of interest? Are there any prevalent perspectives on Security in this area? Are there any prevalent perspectives on Privacy in this area? What cultural norms are relevant? What cultural taboos are relevant? Ethnic issues Are there any ethnic groups that suffer from discrimination? TECHNOLOGICAL Law Enforcement What means do the area\u2019s law enforcement use to access private digital systems? What technologies do law enforcement or other government forces use to monitor or collect information on the populace? Supply chains for Information-sharing How is information transmitted between community members? Are there any prevalent attitudes towards online security tools in this area? LEGAL What protections exist for Freedom of Speech? What are the relevant Privacy Laws? What are the relevant Data Protection Laws? (GDPR, etc) What are the relevant Cybersecurity Laws? Criminality Who are the major organized crime groups? What other crimes may be relevant? MILITARY What are current or recent local conflicts? Include terrorism. Are there any international conflicts involving home country or partners\u2019 home countries? Are there nearby Installations and bases to the organization\u2019s work? What capabilities or equipment for collection or intercept may be present?","title":"Contextual Assessment Requirements"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#background","text":"Understand the history of the organization and its mission How did your organization form? What are its objectives? Mission: Year established: Brief history: Summary of current programs? Upcoming campaigns?","title":"BACKGROUND"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#internal-factors","text":"Understand the assets used to achieve the organization\u2019s goals","title":"INTERNAL FACTORS"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#physical","text":"Where are you headquartered? Address(es): Reason for chosen location(s): Do you share this space with anyone outside the organization? Do you rent, own, borrow this space? What other facilities do you own or occupy? E.g. Satellite offices, warehouses, intermittent environments (temporary workspaces, conferences, workshops) What equipment do you rely on? (Will be explored more deeply in Device Inventory) Devices (computers, phones, tablets, routers, TVs, any other IoT like thermostat, alexa, etc.) Provided to employees? Or do employees use their own? Vehicles Own, rent? What other physical infrastructure does the organization depend upon? Power What is the regular system for providing power to the organization? On-grid, generator, solar? What backup power systems are available to the organization? Travel Are employees allowed to travel with organization-owned devices? What devices are they likely to travel with? Are \"travel devices\" available for employees to use? What is the organizational expectation of their use? Are employees likely to travel to locations where device theft is common? Are employees travelling through checkpoints (government, private, bandits, international)? Trash removal and other janitorial services & recycling How does the organization dispose of trash? How does the organization dispose of sensitive documents? How does the organization manage janitorial services for their workspace? How does the organization perform cleaning their offices or other workspace? Who conducts maintenance of physical infrastructure (plumbing, electricity)?","title":"PHYSICAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#political","text":"How are you structured? Leadership team (executives): Board: Management structure: What politics are in play within the organization? What are the political affiliations of its board members and leaders? (in general, or any heavily political advisors) What are current political aspirations of current employees? Is anyone running for office? What are the internal relationships between members? Describe past and current internal conflicts -- organizational changes, layoffs & firing Immigration/Citizenship/Refugee status: Staff: Beneficiaries:","title":"POLITICAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#economic","text":"What is your business model? Corporate Structure (Non-profit, for-profit, hybrid) Dependencies Who are your Clients / Customers / Beneficiaries? Who are your Donors? Who are your other Funders (Grantors, Governments)? Who are your partners for Contracted Services? Current Financial Situation Describe your organization\u2019s Financial Health including inputs/outputs What is your Financial Infrastructure - Where/How are funds stored? Do you use Formal banking? Do you keep Cash on hand? Do you use Informal value transfer? Seasonality Are there specific times of year where you conduct certain programs or when fundraising or operations will intensify? Advertising and Publicity Operations (Avenues for advertising, press, publicity - how is your organization known?) Current Financial Situation What is your Internal Cash Flow & Funding Streams? What are your sources of Funding, grants, & Initiatives?","title":"ECONOMIC"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#social","text":"Who keeps your organization running? Number of employees: Types of employees: Full-time, part-time, intern, volunteer, contractor Occupations & Salaries paid Demographics (ages, genders, ethnicities, tribes): Staff: Beneficiaries: Education Formal education of staff members Literacy of staff members Technological knowledge and proficiency Living Situations Geographic dispersal - where do staff live in relation to work? Where do they live in relation to beneficiaries? In relation to their family (Diaspora?)? Living conditions - what are the living conditions for staff? What is your organization\u2019s culture? Organizational Practices (of Staff or Beneficiaries) Which languages are used? What perspectives on Security exist? What perspectives on Privacy exist? Working environment Office bound? Remote workers? \u201cWork from home\u201d culture? Organizational Practices (of Staff or Beneficiaries) What norms are realized? What taboos exist? Hiring Practices Describe current hiring practices. How are people screened before employment? Describe current recruiting initiatives. How are people recruited? Leisure Activities Health Conditions Current issues Clinic / Medical Care Providers Insurance Providers","title":"SOCIAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#technological","text":"See Device Inventory and Technical assessment Do you currently have organizational policies for... Technology Use? System Access? Privacy or data protection? What are your future plans... For acquiring replacement technologies or solutions? For digitization of paper records or other assets? For conducting software upgrades?","title":"TECHNOLOGICAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#legal","text":"Do you have an internal legal team or rely on outside counsel? What are your statutory & regulatory commitments for... Business / Financial? Ethical? Environmental? Data protection regulations (GDPR, etc)? Others? What are your current contractual obligations? Have there been past breaches of contract? Describe your organization\u2019s lawsuits & legal challenges in the... Past? Present? Future (Expected/Planned)?","title":"LEGAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#threats","text":"Consider... Organized Crime Nation State Professional Hacker (Individual / Collective) Hacktivists Corporations Terrorism Criminal (Scammer / Opportunist) Who were your past threats? What persons, groups, or organizations have threatened, attacked, or harmed your organization, its employees, or beneficiaries in the past? Cyberattacks Physical harms Other Crimes What prior attacks has your organization experienced in the past? Cyberattacks Physical harms Other Crimes Who are your current threats? What persons, groups, or organizations are your current threats to your organization? Cyberattacks Physical harms Other Crimes Which persons, groups, or organizations do you feel may harm your organization in the future?","title":"THREATS"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#external-factors","text":"Factors beyond the organization\u2019s Control, but that are highly relevant to their functioning","title":"EXTERNAL FACTORS"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#political_1","text":"Support from Government Leadership of Organization\u2019s Missions or Causes Who are their supporters? Who are their opponents? Government Stability Any recent shifts of power or structure? Is there turmoil expected turmoil in the future? Are there ongoing or nascent insurgencies? External Stakeholders in Organization\u2019s Mission What other politicians or political groups are involved or impacted by the organization\u2019s work? What home pressure groups / lobbyists are for / against the organization\u2019s work? What international pressure groups / lobbyists are for / against the organization\u2019s work? Corruption in Government What is the country\u2019s general propensity & accountability for bribery, graft, etc? Are there past or current corruption scandals involving the above stakeholders?","title":"POLITICAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#economic_1","text":"Home economic situation Describe the general economic conditions in the home country. Are there ongoing crises related to recession, hyperinflation, or other decline? What is the unemployment rate? Trade Agreements What other countries are relevant trade partners? Are any countries involved in an ongoing trade war with the home country?","title":"ECONOMIC"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#social_1","text":"Cultural Practices What other languages are used in the area of interest? Are there any prevalent perspectives on Security in this area? Are there any prevalent perspectives on Privacy in this area? What cultural norms are relevant? What cultural taboos are relevant? Ethnic issues Are there any ethnic groups that suffer from discrimination?","title":"SOCIAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#technological_1","text":"Law Enforcement What means do the area\u2019s law enforcement use to access private digital systems? What technologies do law enforcement or other government forces use to monitor or collect information on the populace? Supply chains for Information-sharing How is information transmitted between community members? Are there any prevalent attitudes towards online security tools in this area?","title":"TECHNOLOGICAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#legal_1","text":"What protections exist for Freedom of Speech? What are the relevant Privacy Laws? What are the relevant Data Protection Laws? (GDPR, etc) What are the relevant Cybersecurity Laws? Criminality Who are the major organized crime groups? What other crimes may be relevant?","title":"LEGAL"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Assessment_Info_Reqs/#military","text":"What are current or recent local conflicts? Include terrorism. Are there any international conflicts involving home country or partners\u2019 home countries? Are there nearby Installations and bases to the organization\u2019s work? What capabilities or equipment for collection or intercept may be present?","title":"MILITARY"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/","text":"Summary Security does not happen in a bubble. Every security policy, setting, and tool needs to be tailored for the specific context of the organization. Particularly with non-profit organizations that work with fewer resources, under different circumstances, and for different motivations than for-profit or government entities, \"industry best practice\" and boilerplate policies can actually cause more harm than good. Instead, security assistance providers must consider the context and capacity of their partner organizations, including political, economic, social, technological, legal, and environmental factors both within and beyond the organization. Learning Objectives Understand how contextual factors can impact an organization's security Understand methods to identify relevant contextual factors Understand methods to identify and categorize gaps and assumptions in one's analysis Understand how to use the PESTLE framework Pre-Readings See Course Readings for \"Contextual & Capacity Research\" Resources Contextual Factors (PESTLE-M) Worksheet Contextual Assessment Information Requirements Activities Assumptions Game (for small class size) Each student writes an interesting \"hard to guess\" fact about themselves (that they feel comfortable revealing to the class) on a sticky note and gives to the instructor (or private messages the instructor). The instructor displays all the \"facts\" (without the fact's owner) to the entire class. The class votes to match up each fact to a specific student. After each student is assigned a fact, the instructor asks which students have the correct fact assigned to them. When students are correctly matched with a fact, the class discusses why or why not they made that guess. Conduct multiple rounds until all students are assigned their correct fact. Assumptions Game (for large class size) Each student writes three interesting facts about themselves believed to be unique among the rest of the class. Ensure that students feel comfortable revealing this information to the rest of the class. One by one, have students state the three facts and then see, by show of hands, whether any facts might also describe other students. If a student raises their hand, the student that stated the three facts must guess which of the facts is shared between the two students. Discussion Why were some \"secrets\" figured out quickly while others took a long time? What assumptions did you make that helped or hurt your guesses? Consider the following perspectives: \u201cI shall reconsider human knowledge by starting from the fact that we can know more than we can tell\u201d Michael Polanyi, The Tacit Dimension (1966) \u201cNo man ever looks at the world with pristine eyes. He sees it edited by a definite set of customs and institutions and ways of thinking.\u201d Ruth Benedict, Patterns of Culture (1976) \u201cExperienced analysts have an imperfect understanding of what information they actually use in making judgments. They are unaware of the extent to which their judgments are determined by a few dominant factors, rather than by the systematic integration of all available information. Analysts actually use much less of the available information than they think they do.\u201d Richards J. Heuer, Jr., Psychology of Intelligence Analysis (2007) Would considering (ie, \"thinking hard\") these insights have impacted your guesses during the activities? Input There's an enormous range of factors that can impact and influence the security of an organization. We need a systematic approach to narrow relevant \u201ccontext\u201d down, including: What should we search for? How do we organize the information we collect? What relevant information are we missing? What are our assumptions? Existing frameworks include: 1) Frontline Defenders' Workbook on Security: Practical Steps for Human Rights Defenders at Risk. See CONTEXT ANALYSIS QUESTIONS. 2) SAFETAG. https://safetag.org/guide/ How to use SAFETAG: A \u201cHow-To\u201d A checklist A list of information resources SAFETAG (\u201cGuiding Questions\u201d from Section 2.2 \u201cContext\u201d): What infrastructural barriers exist in the region? What are the top, non-targeted digital threats in this region? What are the top targeted digital threats facing organizations doing this work in this region / country? Are there legal ramifications to digital security in the country? (e.g. legality of encryption, anonymity tools, etc.) Has any organization or individual made specific threats, or demonstrated intention or mindset to attack on the organization or similar organizations? SAFETAG (\u201cGuiding Questions\u201d from Section 2.3 \u201cCapacity\u201d): What is the organization's ability to adopt new technologies or practices? What resources does the organization have available to them? What is the environment that the organization works within like? What barriers, threat actors, and other aspects influence their work? Are there any specific considerations for the audit that would require modifying the overall approach, tools, preparation steps, or timeline? 3) PMESII-PT Operational Variables may be seen in some INFOSEC circles. Considers Political, Military, Economic, Social, Infrastructure, Information, Physical Environment, and Time factors, usually in a \"crosswalk\" matrix with \"ASCOPE civil considerations\" (Area, Structures, Capabilities, Organizations, People, Events). However, same as in describing threats, we'll want to avoid adopting militaristic terminology and methods. See example: [Image source: US Marine Corps Training Command] 4) Especially in the business world, PESTLE (or PEST) may be a good choice for categorizing contextual factors. [Source: Free Templates] Political, Economic, Social, Technological, Legal, Environment (and sometimes Military) factors can be displayed in a matrix bounded by: SWOT: Strength, Weaknesses, Opportunities, Threats Time: Past, Present, Future Control: Internal (within Organization\u2019s Control), External Factors (Within Organization\u2019s Influence), External Factors (Beyond Organization\u2019s Influence) Deepening As a class, work through the Contextual Factors (PESTLE-M) Worksheet for an example or actual partner organization. Additionally, discuss the following: In which ways could you discover this information? How do you do this securely? Collaboratively? What might cause you to stop the process? Synthesis Great example from STS ethnography on why this is important: \u201cThe [Xerox copier repair] technicians should be viewed as an occupational community (van Maanen and Barley 1984). They are focused on the work, not the organization, and the only valued status is that of full member of the community, that is, being considered a competent technician. In pursuit of this goal, they share information, assist in each other's diagnoses, and compete in terms of their relative expertise. Promotion out of the community is thought not to be worthwhile. The occupational community shares few cultural values with the corporation; technicians from all over the country are much more alike than a technician and a salesperson from the same district.\u201d Julian Orr, Talking About Machines (1996) Do the members of your client org consider themselves members of an occupational community before the organization? Assignments PESTLE Analysis Brief You will create a 10 minute brief on a contextual factor that is relevant to your client\u2019s organization. While you will receive individual credit for this assignment, do collaborate as a team in order to plan, collect, and analyze this information. Planning (As a Team). Create a game plan with your team so that each of your team members\u2019 efforts focus on a relevant PESTLE category of factors. Create a team collective document / spreadsheet where you can keep a running track of information / sources as you collect them. You will need to maintain this over the course of the semester and you will add to it as you complete your research & interviews with your client. Select topics that each team individually will research in breadth (eg. encompass a range of political factors that may affect your client) or in depth (eg. research how a specific data protection law might impact your client). Strive to meaningfully inform the other members of your team about content that is directly relevant to your client\u2019s security posture. You may need to perform some initial research as a team to understand what important topics may be to consider. Your client\u2019s website or other bits of information about your client organization may be a great place to start to do this planning - what is their mission? What recent work have they promoted? Collection. Seek open source information - this is a broad category that can include books, studies, websites, social media. Do not solely focus on gathering information from your client. This is the time to do your homework on the topic but also to figure out the best way for your team to collect / store this information. Remember: we are at one of the premier research universities in the world. There may be a subject matter expert available at UC Berkeley who can help you navigate a complex topic. Analysis. Perform some meaningful analysis on your topic instead of simply recalling information found online. For example, tell us why the education level or types of employees at the organization matter to their cybersecurity or to the Clinic\u2019s work. Focus on providing the answer to \u201cSo what? Why does this matter?\u201d when you provide information for your team.","title":"Contextual Research Overview"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#summary","text":"Security does not happen in a bubble. Every security policy, setting, and tool needs to be tailored for the specific context of the organization. Particularly with non-profit organizations that work with fewer resources, under different circumstances, and for different motivations than for-profit or government entities, \"industry best practice\" and boilerplate policies can actually cause more harm than good. Instead, security assistance providers must consider the context and capacity of their partner organizations, including political, economic, social, technological, legal, and environmental factors both within and beyond the organization.","title":"Summary"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#learning-objectives","text":"Understand how contextual factors can impact an organization's security Understand methods to identify relevant contextual factors Understand methods to identify and categorize gaps and assumptions in one's analysis Understand how to use the PESTLE framework","title":"Learning Objectives"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#pre-readings","text":"See Course Readings for \"Contextual & Capacity Research\"","title":"Pre-Readings"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#resources","text":"Contextual Factors (PESTLE-M) Worksheet Contextual Assessment Information Requirements","title":"Resources"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#activities","text":"Assumptions Game (for small class size) Each student writes an interesting \"hard to guess\" fact about themselves (that they feel comfortable revealing to the class) on a sticky note and gives to the instructor (or private messages the instructor). The instructor displays all the \"facts\" (without the fact's owner) to the entire class. The class votes to match up each fact to a specific student. After each student is assigned a fact, the instructor asks which students have the correct fact assigned to them. When students are correctly matched with a fact, the class discusses why or why not they made that guess. Conduct multiple rounds until all students are assigned their correct fact. Assumptions Game (for large class size) Each student writes three interesting facts about themselves believed to be unique among the rest of the class. Ensure that students feel comfortable revealing this information to the rest of the class. One by one, have students state the three facts and then see, by show of hands, whether any facts might also describe other students. If a student raises their hand, the student that stated the three facts must guess which of the facts is shared between the two students.","title":"Activities"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#discussion","text":"Why were some \"secrets\" figured out quickly while others took a long time? What assumptions did you make that helped or hurt your guesses? Consider the following perspectives: \u201cI shall reconsider human knowledge by starting from the fact that we can know more than we can tell\u201d Michael Polanyi, The Tacit Dimension (1966) \u201cNo man ever looks at the world with pristine eyes. He sees it edited by a definite set of customs and institutions and ways of thinking.\u201d Ruth Benedict, Patterns of Culture (1976) \u201cExperienced analysts have an imperfect understanding of what information they actually use in making judgments. They are unaware of the extent to which their judgments are determined by a few dominant factors, rather than by the systematic integration of all available information. Analysts actually use much less of the available information than they think they do.\u201d Richards J. Heuer, Jr., Psychology of Intelligence Analysis (2007) Would considering (ie, \"thinking hard\") these insights have impacted your guesses during the activities?","title":"Discussion"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#input","text":"There's an enormous range of factors that can impact and influence the security of an organization. We need a systematic approach to narrow relevant \u201ccontext\u201d down, including: What should we search for? How do we organize the information we collect? What relevant information are we missing? What are our assumptions? Existing frameworks include: 1) Frontline Defenders' Workbook on Security: Practical Steps for Human Rights Defenders at Risk. See CONTEXT ANALYSIS QUESTIONS. 2) SAFETAG. https://safetag.org/guide/ How to use SAFETAG: A \u201cHow-To\u201d A checklist A list of information resources SAFETAG (\u201cGuiding Questions\u201d from Section 2.2 \u201cContext\u201d): What infrastructural barriers exist in the region? What are the top, non-targeted digital threats in this region? What are the top targeted digital threats facing organizations doing this work in this region / country? Are there legal ramifications to digital security in the country? (e.g. legality of encryption, anonymity tools, etc.) Has any organization or individual made specific threats, or demonstrated intention or mindset to attack on the organization or similar organizations? SAFETAG (\u201cGuiding Questions\u201d from Section 2.3 \u201cCapacity\u201d): What is the organization's ability to adopt new technologies or practices? What resources does the organization have available to them? What is the environment that the organization works within like? What barriers, threat actors, and other aspects influence their work? Are there any specific considerations for the audit that would require modifying the overall approach, tools, preparation steps, or timeline? 3) PMESII-PT Operational Variables may be seen in some INFOSEC circles. Considers Political, Military, Economic, Social, Infrastructure, Information, Physical Environment, and Time factors, usually in a \"crosswalk\" matrix with \"ASCOPE civil considerations\" (Area, Structures, Capabilities, Organizations, People, Events). However, same as in describing threats, we'll want to avoid adopting militaristic terminology and methods. See example: [Image source: US Marine Corps Training Command] 4) Especially in the business world, PESTLE (or PEST) may be a good choice for categorizing contextual factors. [Source: Free Templates] Political, Economic, Social, Technological, Legal, Environment (and sometimes Military) factors can be displayed in a matrix bounded by: SWOT: Strength, Weaknesses, Opportunities, Threats Time: Past, Present, Future Control: Internal (within Organization\u2019s Control), External Factors (Within Organization\u2019s Influence), External Factors (Beyond Organization\u2019s Influence)","title":"Input"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#deepening","text":"As a class, work through the Contextual Factors (PESTLE-M) Worksheet for an example or actual partner organization. Additionally, discuss the following: In which ways could you discover this information? How do you do this securely? Collaboratively? What might cause you to stop the process?","title":"Deepening"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#synthesis","text":"Great example from STS ethnography on why this is important: \u201cThe [Xerox copier repair] technicians should be viewed as an occupational community (van Maanen and Barley 1984). They are focused on the work, not the organization, and the only valued status is that of full member of the community, that is, being considered a competent technician. In pursuit of this goal, they share information, assist in each other's diagnoses, and compete in terms of their relative expertise. Promotion out of the community is thought not to be worthwhile. The occupational community shares few cultural values with the corporation; technicians from all over the country are much more alike than a technician and a salesperson from the same district.\u201d Julian Orr, Talking About Machines (1996) Do the members of your client org consider themselves members of an occupational community before the organization?","title":"Synthesis"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/Contextual_Research/#assignments","text":"PESTLE Analysis Brief You will create a 10 minute brief on a contextual factor that is relevant to your client\u2019s organization. While you will receive individual credit for this assignment, do collaborate as a team in order to plan, collect, and analyze this information. Planning (As a Team). Create a game plan with your team so that each of your team members\u2019 efforts focus on a relevant PESTLE category of factors. Create a team collective document / spreadsheet where you can keep a running track of information / sources as you collect them. You will need to maintain this over the course of the semester and you will add to it as you complete your research & interviews with your client. Select topics that each team individually will research in breadth (eg. encompass a range of political factors that may affect your client) or in depth (eg. research how a specific data protection law might impact your client). Strive to meaningfully inform the other members of your team about content that is directly relevant to your client\u2019s security posture. You may need to perform some initial research as a team to understand what important topics may be to consider. Your client\u2019s website or other bits of information about your client organization may be a great place to start to do this planning - what is their mission? What recent work have they promoted? Collection. Seek open source information - this is a broad category that can include books, studies, websites, social media. Do not solely focus on gathering information from your client. This is the time to do your homework on the topic but also to figure out the best way for your team to collect / store this information. Remember: we are at one of the premier research universities in the world. There may be a subject matter expert available at UC Berkeley who can help you navigate a complex topic. Analysis. Perform some meaningful analysis on your topic instead of simply recalling information found online. For example, tell us why the education level or types of employees at the organization matter to their cybersecurity or to the Clinic\u2019s work. Focus on providing the answer to \u201cSo what? Why does this matter?\u201d when you provide information for your team.","title":"Assignments"},{"location":"Clinic_Curriculum/Modules/Contextual_Research/PESTLE-M_Worksheet/","text":"Status: Last updated 4/20/20 See Contextual Assessment Information Requirements for example questions. Internal Factors (ie. within the org\u2019s control, how the org functions) External Factors beyond the org\u2019s control but within an org\u2019s possible influence External Factors outside of org\u2019s influence but will impact the org Political (Ex: government type and stability, freedom of press, rule of law, levels of bureaucracy & corruption, social and employment legislation, tax policy and trade & tariff controls, likely changes in the political environment) Economic (Ex: stage of business cycle, current & projected economic growth, e.g. GDP / GNP growth inflation & interest rates, unemployment and labor supply, labor costs, levels of disposable income & income distribution, likely impact of technological or other change on the economy) Social (Ex: population health, education & social mobility, and attitudes to these population employment patterns, job market freedom & attitudes to work, press attitudes, public opinion, social attitudes & social taboos , lifestyle choices and attitudes to these socio-cultural changes health consciousness) Technology (Ex: impact of emerging technologies, impact of internet, reduction in communication costs & increased remote working, research & development (R&D) activity, impact of technology transfer, degree of automation, rate of technological change) Legal (Ex: antitrust law, consumer law, discrimination law, employment law, health & safety laws) Environmental (Ex: weather, natural disasters, climate, climate change, environmental taxes, demand for \"green\" products) Military (Ex: military equipment, personnel, operations or other presence in the area, foreign armies, paramilitaries, war, internal may be associations with military members, attitudes)","title":"PESTLE-M Worksheet"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/","text":"Summary This module introduces ethical considerations for clinical security work. Our look at ethics builds on the work of the Markulla Center for Applied Ethics, at Santa Clara University, and introduces a set of ethical considerations and norms specific to the work of Citizen Clinic. (For more information, see Citizen Clinic Code of Conduct .) Learning Objectives Identify ethically significant harms in cybersecurity (and the Clinic) Identify ethical challenges in cybersecurity (and the Clinic) Understand best practices for cybersecurity ethics including the three components of informed consent Understand one's mandate to regularly consider the ethics of their position and work Pre-Readings See Course Readings for \"Ethics and the Citizen Clinic Code of Conduct\" Resources Citizen Clinic Code of Conduct Activities Read pages 7-21 & 48-52 of \u201cAn Introduction to Cybersecurity Ethics\u201d (Shannon Vallor, The Markkula Center for Applied Ethics) [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Prepare answers to questions on pages 13-15 and page 53 for discussion. Question 1.1: What risks of ethically significant harm, as defined in Part One, are involved in this case? Who could be harmed if Leslie makes poor choices in this situation, and how? What potential benefits to others should she consider in thinking about BioHack\u2019s proposal? Question 1.2: Beyond the specific harms noted in your answer to 1.1, what are some ethical concerns that Leslie should have about the proposed arrangement with BioHack? Are there any ethical \u2018red flags\u2019 she should notice? Question 5.1: Of these 12 best practices for cybersecurity ethics, which two do you think are the most challenging to carry out? What do you think could be done (by an individual, team, or organization) to make those practices easier? Discussion What ethically significant harms should we consider? What ethical challenges (Vallor pg 15-20) might we encounter? Input Consider \u201cFirst, do no harm\u201d... ...but discuss the limitations of that guiding principle. We should be intentional about the decisions we make and intervene in ways that will not make the situation worse. Ultimately, the organization and its well-being should be your primary concern. However, you also have a duty to yourself, your family, and your team members. Sometimes it may seem like there are no good answers (for instance, doing nothing because there might be risk is not a resolution). If we view our interventions as already raising the risks for our partners and ourselves, what can we actively do to mitigate that? Informed Consent Discuss and define disclosure, comprehension, and voluntary participation. Understand the effect of your institutional affiliation and positioning. Tools and methods for good (ethical) can be used for bad (unethical). Important questions to regularly ask: Are you, your team, or your partner able to do this? Are you, your team, or your partner willing to do this? Do you, your team, or your partner have any conflicts of interest? Deepening What should our Code of Ethics look like? (Vallor pg 48) Synthesis Review the Citizen Clinic Code of Conduct. Highlights: Harassment and Discrimination Operational Security Confidentiality Professionalism Reporting Assignments Review and submit signed Code of Conduct.","title":"Ethics Overview"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#summary","text":"This module introduces ethical considerations for clinical security work. Our look at ethics builds on the work of the Markulla Center for Applied Ethics, at Santa Clara University, and introduces a set of ethical considerations and norms specific to the work of Citizen Clinic. (For more information, see Citizen Clinic Code of Conduct .)","title":"Summary"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#learning-objectives","text":"Identify ethically significant harms in cybersecurity (and the Clinic) Identify ethical challenges in cybersecurity (and the Clinic) Understand best practices for cybersecurity ethics including the three components of informed consent Understand one's mandate to regularly consider the ethics of their position and work","title":"Learning Objectives"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#pre-readings","text":"See Course Readings for \"Ethics and the Citizen Clinic Code of Conduct\"","title":"Pre-Readings"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#resources","text":"Citizen Clinic Code of Conduct","title":"Resources"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#activities","text":"Read pages 7-21 & 48-52 of \u201cAn Introduction to Cybersecurity Ethics\u201d (Shannon Vallor, The Markkula Center for Applied Ethics) [ https://www.scu.edu/media/ethics-center/technology-ethics/IntroToCybersecurityEthics.pdf ] Prepare answers to questions on pages 13-15 and page 53 for discussion. Question 1.1: What risks of ethically significant harm, as defined in Part One, are involved in this case? Who could be harmed if Leslie makes poor choices in this situation, and how? What potential benefits to others should she consider in thinking about BioHack\u2019s proposal? Question 1.2: Beyond the specific harms noted in your answer to 1.1, what are some ethical concerns that Leslie should have about the proposed arrangement with BioHack? Are there any ethical \u2018red flags\u2019 she should notice? Question 5.1: Of these 12 best practices for cybersecurity ethics, which two do you think are the most challenging to carry out? What do you think could be done (by an individual, team, or organization) to make those practices easier?","title":"Activities"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#discussion","text":"What ethically significant harms should we consider? What ethical challenges (Vallor pg 15-20) might we encounter?","title":"Discussion"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#input","text":"Consider \u201cFirst, do no harm\u201d... ...but discuss the limitations of that guiding principle. We should be intentional about the decisions we make and intervene in ways that will not make the situation worse. Ultimately, the organization and its well-being should be your primary concern. However, you also have a duty to yourself, your family, and your team members. Sometimes it may seem like there are no good answers (for instance, doing nothing because there might be risk is not a resolution). If we view our interventions as already raising the risks for our partners and ourselves, what can we actively do to mitigate that? Informed Consent Discuss and define disclosure, comprehension, and voluntary participation. Understand the effect of your institutional affiliation and positioning. Tools and methods for good (ethical) can be used for bad (unethical). Important questions to regularly ask: Are you, your team, or your partner able to do this? Are you, your team, or your partner willing to do this? Do you, your team, or your partner have any conflicts of interest?","title":"Input"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#deepening","text":"What should our Code of Ethics look like? (Vallor pg 48)","title":"Deepening"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#synthesis","text":"Review the Citizen Clinic Code of Conduct. Highlights: Harassment and Discrimination Operational Security Confidentiality Professionalism Reporting","title":"Synthesis"},{"location":"Clinic_Curriculum/Modules/Ethics/Ethics/#assignments","text":"Review and submit signed Code of Conduct.","title":"Assignments"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/","text":"Citizen Clinic Student Code of Conduct The Citizen Clinic is an inclusive course where students, mentors, and staff should feel comfortable sharing their work, opinions, and perspectives. All of us commit to engaging with each other mindfully to ensure an environment that promotes shared learning and collaboration. When does the Code of Conduct apply? This Code of Conduct governs participation at the Citizen Clinic. It applies to all Clinic participants during all class meetings, as well as to all Clinic participants at after-hours working sessions or social events. The internet is real life. This Code of Conduct applies in all digital spaces connected to the Clinic (e.g., group chat channels, mailing lists, collaborative documents) as well as physical ones. Participants who violate this Code may be excluded from this and future Clinic opportunities, and may be prohibited from attending Clinic social events. Clinic participants are expected to comply with the policies that govern all activities and behavior at UC Berkeley, in particular the Nondiscrimination Policies and Procedures, Sexual Violence and Harassment Policies and Procedures , the Student Code of Conduct , and the Computer Use Policy . In addition, we expect all Clinic participants to abide by the following parameters: Be respectful to others. Do not engage in homophobic/homomisic, racist, transphobic/transmisic, ageist, ableist, sexist, or otherwise exclusionary behavior. Honor individuals\u2019 preferences for how they prefer to be addressed. Use welcoming and inclusive language. Exclusionary comments or jokes, threats or violent language are not acceptable while working in the Clinic. Do not address others in an angry, intimidating, or demeaning manner. Be considerate of the ways the words you choose may impact others. Be patient and respectful of the fact that English may be a second (or third or fourth!) language for Clinic participants. Do not harass people. Harassment includes unwanted physical contact, sexual attention, or repeated social contact. Know that consent is explicit, conscious and continuous\u2014not implied. If you are unsure whether your behavior towards another person is welcome, ask them. If someone tells you to stop, do so. Respect the privacy and safety of others. Do not take photographs of others without their permission. Note that posting (or threatening to post) personally identifying information of others without their consent (\u201cdoxing\u201d) is a form of harassment. Be considerate of others\u2019 participation. Everyone should have an opportunity to be heard. While working in teams, please keep comments succinct so as to allow maximum engagement by all members. Be conscious and respectful of the fact that your team members may have different methods of communicating, and work to enable the most collaborative environment among your team. Don\u2019t be a bystander. If you see something inappropriate happening, speak up. If you don\u2019t feel comfortable intervening but feel someone should, please feel free to ask a member of the Clinic staff to intervene. As an overriding general rule, please be intentional in your actions and humble in your mistakes. Operational Security Working with the Citizen Clinic will require engagement with its partner organizations. These organizations and their staff, partners, and the communities they serve are often at risk of online or physical attacks. Therefore, adherence to Clinic operational security procedures is not just a requirement for academic success, but for safeguarding the lives and livelihoods of Clinic partners, students, staff, and their friends and families. In order to facilitate a secure, safe working environment, all Clinic participants are expected to: Adhere strictly to any operational security requirements set for partner communications by your team, by Clinic staff, or by the partner. Do not seek to undermine existing security controls. Should you feel a security measure is ineffective, bring your concerns to Clinic staff before taking measures to alter any security systems or policies. Respect partners\u2019 perspectives. Even if we do not agree with a partner\u2019s security concerns, we learn more about their security context by listening than telling. We do not know what we do not know. Keep track of any Clinic-owned devices assigned to you or your team. Ensure they are under the control of you or your team at all times, or are securely stored when not in use, and do not engage in any unlawful or unethical online or offline behavior with them. Do not change any device settings in ways that would reduce device security. These devices are the gateway to our partners and the Clinic\u2019s electronic infrastructure. You are the gatekeeper. Report any security incidents or concerns immediately to Clinic staff. This includes, but is not limited to, the loss, theft, or compromise of Clinic-owned devices or data stored on them. Confidentiality As a condition of allowing students to participate in the Clinic, including access to the Clinic\u2019s computers or other systems, all students agree to strictly protect any Confidential Information they receive as a result of their work with the Clinic. While the decision about whether information is \u201cConfidential Information\u201d depends on the specific information itself, some examples of Confidential Information include: The names of partner organizations, their staff or clients, or other persons related to a Clinic project, or information likely to indicate identity; Any information related to organizational assessments or policy findings and recommendations; Any private communication or information regarding a specific partner, a case, research data or analysis, including any underlying facts and circumstances not already revealed to the public; Any report or other written material, including that which the undersigned or their team has drafted, unless such document has been approved for release and properly redacted by a member of the Clinic supervising faculty or professional staff; and Identities or other personal information about partners required by applicable research protocols to remain confidential to minimize the risk to research subjects of participation in research. The undersigned student agrees that they will not violate the confidentiality of the Clinic\u2019s interests or those of the Clinic\u2019s partners by revealing Confidential Information to those outside the Clinic. By signing this agreement, the student agrees not to disclose Confidential Information orally or in writing, including through electronic media or any online forum, and not to write about any aspect of a Clinic case or project in any print or online publication without the express, prior permission of the Clinic\u2019s supervising faculty or professional staff. The obligation of each student to maintain the confidentiality of information is on-going and continues after the student\u2019s participation in the Clinic has ended. Clinic faculty and professional staff are available to answer any questions or concerns about this Agreement, or about disclosure of any specific information. Students who are uncertain about whether certain information is Confidential Information should ask mentors, Clinic faculty or professional staff before any disclosure. Professionalism Working with partner organizations is a position of significant privilege and trust. Your work does not just represent you, but your team, Citizen Clinic, the Center for Long-Term Cybersecurity, the School of Information, and UC Berkeley at-large. Students are expected to be on-time to all partner meetings ( remember: partners are not on Berkeley time ), and to be attentive and respectful during all external-facing engagements. Work product, communications, and other partner-facing materials you may produce over your time with the Clinic must adhere to a very high standard of quality. The work that is done in this course varies from team to team, but always keep in mind these three characteristics when preparing work for partners: Rigor: Be thorough in your research. Do not make recommendations for partners based on what you assume they need\u2014all recommendations should have a rigorous explanation behind them. Attention to Detail: Spelling, grammar, design, organization\u2014do not underestimate the importance of details. We want partners to rely on the materials we create when they are considering meaningful decisions about their security. Bad writing does not instill confidence. Contextualize: Think about who your audience is for any document or deliverable\u2014whether it is an email, an organizational policy, or a report. Who is reading it? Who might read it? How technical are they? Do they read English? How well? Tailoring your work to your audience is critical to making the work meaningfully received and understood. How do I report an issue related to the Code of Conduct? Please report any issues related to the Code of Conduct to: Sean Brooks - swb AT berkeley DOT edu Steve Trush - strush AT berkeley DOT edu Please speak to us if you encounter an issue\u2014whether related to a specific situation or to a more general aspect of the Citizen Clinic. You can contact the Citizen Clinic staff team as a group or individually, in person or by email. You can also report issues to the Citizen Clinic staff anonymously 1 \u2014 but please use an email address where you\u2019ll be able to receive replies. Many campus resources are also available for reporting incidents of harassment, violence, or discrimination. You can find information about those programs and contacts (including official reporting pathways) here: PATH to Care Center: http://survivorsupport.berkeley.edu/report Office for the Prevention of Harassment and Discrimination: https://ophd.berkeley.edu/home Conflicts of Interest - Reporting If an issue, complaint or concern involves a member of Clinic staff or mentors, that person will be removed from the issue response process and will not have access to documentation related to the issue. Conflicts of Interest \u2013 Partner Services Students must seriously consider their own political, religious, cultural, and social affiliations before agreeing to work with any given partner. If anything about a student\u2019s personal beliefs may cause a conflict of interest or prevent them from providing effective support to a partner, they are obligated to communicate with Clinic staff immediately so they can be assigned to a new team. Appropriate Responses Staff will address all complaints or concerns in a responsive and expedient manner. Each case will be processed as is contextually appropriate and in line with existing University procedures. If, at any point, a student feels a concern, complaint, or report is not being addressed appropriately, they should escalate issues to the CLTC Faculty Director or other campus resources (such as Office for the Prevention of Harassment and Discrimination). Based on the nature of the issue, the Clinic Staff will propose a course of action to the individual who made the report, and, where not prohibited by law or university policy, work with them to determine whether that proposal is an appropriate response before acting. An appropriate response is one which: Seeks to ensure the safety, dignity and security of all Clinic participants; Respects the autonomy, experience and judgment of those who decide to report an issue; Aims to provide a resolution that is meaningful and fair to all participants affected; Encourages accountability, responsibility, cooperation, honesty, personal growth and respect on the part of all participants affected; Is context-specific and aims to \u201cmake things right,\u201d repairing specific harms to affected individuals; Works toward greater inclusiveness in the Clinic; and Complies with UC Berkeley policies, and involves University staff as appropriate and required by those policies. The undersigned agrees to abide by the terms of this Code of Conduct for the duration of their involvement with the Citizen Clinic. Failure to do so may result in disciplinary action outlined within the code, or as required by UC Berkeley policy. Your Name (Printed): Your Signature: Date: Attribution Much of this Code of Conduct is based on the Citizen Lab Summer Institute Code of Conduct . Parts of this Code are based on the xvzf Code of Conduct , the Contributor Covenant , the Django Code of Conduct and Reporting Guide . This code has also been influenced by this guidance from Ada Initiative . Notes An example of how to anonymously report: Use Tor to create and log in to a new email address, use the address exclusively for the purpose of your report, and never provide information that would personally identify you\u2014to either the email service provider or to us. \u21a9","title":"Code of Conduct"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#citizen-clinic-student-code-of-conduct","text":"The Citizen Clinic is an inclusive course where students, mentors, and staff should feel comfortable sharing their work, opinions, and perspectives. All of us commit to engaging with each other mindfully to ensure an environment that promotes shared learning and collaboration. When does the Code of Conduct apply? This Code of Conduct governs participation at the Citizen Clinic. It applies to all Clinic participants during all class meetings, as well as to all Clinic participants at after-hours working sessions or social events. The internet is real life. This Code of Conduct applies in all digital spaces connected to the Clinic (e.g., group chat channels, mailing lists, collaborative documents) as well as physical ones. Participants who violate this Code may be excluded from this and future Clinic opportunities, and may be prohibited from attending Clinic social events. Clinic participants are expected to comply with the policies that govern all activities and behavior at UC Berkeley, in particular the Nondiscrimination Policies and Procedures, Sexual Violence and Harassment Policies and Procedures , the Student Code of Conduct , and the Computer Use Policy . In addition, we expect all Clinic participants to abide by the following parameters: Be respectful to others. Do not engage in homophobic/homomisic, racist, transphobic/transmisic, ageist, ableist, sexist, or otherwise exclusionary behavior. Honor individuals\u2019 preferences for how they prefer to be addressed. Use welcoming and inclusive language. Exclusionary comments or jokes, threats or violent language are not acceptable while working in the Clinic. Do not address others in an angry, intimidating, or demeaning manner. Be considerate of the ways the words you choose may impact others. Be patient and respectful of the fact that English may be a second (or third or fourth!) language for Clinic participants. Do not harass people. Harassment includes unwanted physical contact, sexual attention, or repeated social contact. Know that consent is explicit, conscious and continuous\u2014not implied. If you are unsure whether your behavior towards another person is welcome, ask them. If someone tells you to stop, do so. Respect the privacy and safety of others. Do not take photographs of others without their permission. Note that posting (or threatening to post) personally identifying information of others without their consent (\u201cdoxing\u201d) is a form of harassment. Be considerate of others\u2019 participation. Everyone should have an opportunity to be heard. While working in teams, please keep comments succinct so as to allow maximum engagement by all members. Be conscious and respectful of the fact that your team members may have different methods of communicating, and work to enable the most collaborative environment among your team. Don\u2019t be a bystander. If you see something inappropriate happening, speak up. If you don\u2019t feel comfortable intervening but feel someone should, please feel free to ask a member of the Clinic staff to intervene. As an overriding general rule, please be intentional in your actions and humble in your mistakes.","title":"Citizen Clinic Student Code of Conduct"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#operational-security","text":"Working with the Citizen Clinic will require engagement with its partner organizations. These organizations and their staff, partners, and the communities they serve are often at risk of online or physical attacks. Therefore, adherence to Clinic operational security procedures is not just a requirement for academic success, but for safeguarding the lives and livelihoods of Clinic partners, students, staff, and their friends and families. In order to facilitate a secure, safe working environment, all Clinic participants are expected to: Adhere strictly to any operational security requirements set for partner communications by your team, by Clinic staff, or by the partner. Do not seek to undermine existing security controls. Should you feel a security measure is ineffective, bring your concerns to Clinic staff before taking measures to alter any security systems or policies. Respect partners\u2019 perspectives. Even if we do not agree with a partner\u2019s security concerns, we learn more about their security context by listening than telling. We do not know what we do not know. Keep track of any Clinic-owned devices assigned to you or your team. Ensure they are under the control of you or your team at all times, or are securely stored when not in use, and do not engage in any unlawful or unethical online or offline behavior with them. Do not change any device settings in ways that would reduce device security. These devices are the gateway to our partners and the Clinic\u2019s electronic infrastructure. You are the gatekeeper. Report any security incidents or concerns immediately to Clinic staff. This includes, but is not limited to, the loss, theft, or compromise of Clinic-owned devices or data stored on them.","title":"Operational Security"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#confidentiality","text":"As a condition of allowing students to participate in the Clinic, including access to the Clinic\u2019s computers or other systems, all students agree to strictly protect any Confidential Information they receive as a result of their work with the Clinic. While the decision about whether information is \u201cConfidential Information\u201d depends on the specific information itself, some examples of Confidential Information include: The names of partner organizations, their staff or clients, or other persons related to a Clinic project, or information likely to indicate identity; Any information related to organizational assessments or policy findings and recommendations; Any private communication or information regarding a specific partner, a case, research data or analysis, including any underlying facts and circumstances not already revealed to the public; Any report or other written material, including that which the undersigned or their team has drafted, unless such document has been approved for release and properly redacted by a member of the Clinic supervising faculty or professional staff; and Identities or other personal information about partners required by applicable research protocols to remain confidential to minimize the risk to research subjects of participation in research. The undersigned student agrees that they will not violate the confidentiality of the Clinic\u2019s interests or those of the Clinic\u2019s partners by revealing Confidential Information to those outside the Clinic. By signing this agreement, the student agrees not to disclose Confidential Information orally or in writing, including through electronic media or any online forum, and not to write about any aspect of a Clinic case or project in any print or online publication without the express, prior permission of the Clinic\u2019s supervising faculty or professional staff. The obligation of each student to maintain the confidentiality of information is on-going and continues after the student\u2019s participation in the Clinic has ended. Clinic faculty and professional staff are available to answer any questions or concerns about this Agreement, or about disclosure of any specific information. Students who are uncertain about whether certain information is Confidential Information should ask mentors, Clinic faculty or professional staff before any disclosure.","title":"Confidentiality"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#professionalism","text":"Working with partner organizations is a position of significant privilege and trust. Your work does not just represent you, but your team, Citizen Clinic, the Center for Long-Term Cybersecurity, the School of Information, and UC Berkeley at-large. Students are expected to be on-time to all partner meetings ( remember: partners are not on Berkeley time ), and to be attentive and respectful during all external-facing engagements. Work product, communications, and other partner-facing materials you may produce over your time with the Clinic must adhere to a very high standard of quality. The work that is done in this course varies from team to team, but always keep in mind these three characteristics when preparing work for partners: Rigor: Be thorough in your research. Do not make recommendations for partners based on what you assume they need\u2014all recommendations should have a rigorous explanation behind them. Attention to Detail: Spelling, grammar, design, organization\u2014do not underestimate the importance of details. We want partners to rely on the materials we create when they are considering meaningful decisions about their security. Bad writing does not instill confidence. Contextualize: Think about who your audience is for any document or deliverable\u2014whether it is an email, an organizational policy, or a report. Who is reading it? Who might read it? How technical are they? Do they read English? How well? Tailoring your work to your audience is critical to making the work meaningfully received and understood.","title":"Professionalism"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#how-do-i-report-an-issue-related-to-the-code-of-conduct","text":"Please report any issues related to the Code of Conduct to: Sean Brooks - swb AT berkeley DOT edu Steve Trush - strush AT berkeley DOT edu Please speak to us if you encounter an issue\u2014whether related to a specific situation or to a more general aspect of the Citizen Clinic. You can contact the Citizen Clinic staff team as a group or individually, in person or by email. You can also report issues to the Citizen Clinic staff anonymously 1 \u2014 but please use an email address where you\u2019ll be able to receive replies. Many campus resources are also available for reporting incidents of harassment, violence, or discrimination. You can find information about those programs and contacts (including official reporting pathways) here: PATH to Care Center: http://survivorsupport.berkeley.edu/report Office for the Prevention of Harassment and Discrimination: https://ophd.berkeley.edu/home","title":"How do I report an issue related to the Code of Conduct?"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#conflicts-of-interest-reporting","text":"If an issue, complaint or concern involves a member of Clinic staff or mentors, that person will be removed from the issue response process and will not have access to documentation related to the issue.","title":"Conflicts of Interest - Reporting"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#conflicts-of-interest-partner-services","text":"Students must seriously consider their own political, religious, cultural, and social affiliations before agreeing to work with any given partner. If anything about a student\u2019s personal beliefs may cause a conflict of interest or prevent them from providing effective support to a partner, they are obligated to communicate with Clinic staff immediately so they can be assigned to a new team.","title":"Conflicts of Interest \u2013 Partner Services"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#appropriate-responses","text":"Staff will address all complaints or concerns in a responsive and expedient manner. Each case will be processed as is contextually appropriate and in line with existing University procedures. If, at any point, a student feels a concern, complaint, or report is not being addressed appropriately, they should escalate issues to the CLTC Faculty Director or other campus resources (such as Office for the Prevention of Harassment and Discrimination). Based on the nature of the issue, the Clinic Staff will propose a course of action to the individual who made the report, and, where not prohibited by law or university policy, work with them to determine whether that proposal is an appropriate response before acting. An appropriate response is one which: Seeks to ensure the safety, dignity and security of all Clinic participants; Respects the autonomy, experience and judgment of those who decide to report an issue; Aims to provide a resolution that is meaningful and fair to all participants affected; Encourages accountability, responsibility, cooperation, honesty, personal growth and respect on the part of all participants affected; Is context-specific and aims to \u201cmake things right,\u201d repairing specific harms to affected individuals; Works toward greater inclusiveness in the Clinic; and Complies with UC Berkeley policies, and involves University staff as appropriate and required by those policies. The undersigned agrees to abide by the terms of this Code of Conduct for the duration of their involvement with the Citizen Clinic. Failure to do so may result in disciplinary action outlined within the code, or as required by UC Berkeley policy. Your Name (Printed): Your Signature: Date:","title":"Appropriate Responses"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#attribution","text":"Much of this Code of Conduct is based on the Citizen Lab Summer Institute Code of Conduct . Parts of this Code are based on the xvzf Code of Conduct , the Contributor Covenant , the Django Code of Conduct and Reporting Guide . This code has also been influenced by this guidance from Ada Initiative .","title":"Attribution"},{"location":"Clinic_Curriculum/Modules/Ethics/Student_Code_of_Conduct/#notes","text":"An example of how to anonymously report: Use Tor to create and log in to a new email address, use the address exclusively for the purpose of your report, and never provide information that would personally identify you\u2014to either the email service provider or to us. \u21a9","title":"Notes"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/","text":"Summary What exactly is \u201charmful information\u201d? Attacks causing harms that stem from the use and/or abuse of information systems as they are designed and/or intended to be used. For example, a system might be designed to allow its users to spread hate speech to any user even though that behavior is against a community standards policy Major categories of abuses fall into misinformation and harassment Learning Objectives Vocabulary and Classification of Harmful Information Approaches to Identifying, Prioritizing, and Mitigating Harmful Information Pre-Readings Sarah Jeong, Charlie Warzel, Brianna Wu, Joan Donovan. New York Times. \u201cEverything is GamerGate\u201d [ https://www.nytimes.com/interactive/2019/08/15/opinion/gamergate-twitter.html ] - Read all of the four essays. IFTF \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51. [ http://www.iftf.org/statesponsoredtrolling ] Cindy Otis. USA Today. \u201cAmericans could be a bigger fake news threat than Russians in the 2020 presidential campaign\u201d [ https://www.usatoday.com/story/opinion/2019/07/19/disinformation-attacks-americans-threaten-2020-election-column/1756092001/ ] InterAction \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Optional) Tahmina Ansari. First Draft. \u201cThis Muslim journalist embraced social media until it \u2018ruined\u2019 his life\u201d [ https://firstdraftnews.org/this-muslim-journalist-embraced-social-media-until-it-ruined-his-life/ ] Resources * Mitigation Framework Activities Beyond Hacking How might Twitter be used to harm an organization even when the site is used as designed (ie not being \u201chacked\u201d)? Vocabulary and Classification Problems Which category (Usually Acceptable, Sometimes/Borderline Acceptable, Always Unacceptable) do the following terms belong to: Propaganda \u2013 Disinformation \u2013 Misinformation \u2013 Malinformation \u2013 Internet Shutdowns - Harassment \u2013 Trolls \u2013 Bots \u2013 Doxxing \u2013 Mobbing \u2013 Swatting \u2013 Leaks \u2013 Sockpuppets \u2013 Astroturfing \u2013 Clickfarms - Deceptive Advertising \u2013 Exclusionary Advertising \u2013 Dog Whistles \u2013 Subtweeting \u2013 Parody News \u2013 Clickbait Discussion How much does intent behind harmful information matter for the organization? How much does the truth of the harmful information matter for the organization? Input Harmful information threats can be considered as security risk management problems, however: Resources will be limited compared to scope of the problems Harms & risks are ill-defined for prioritization Less agreement on what \u201dbest practice\u201d looks like Threats may have greater impact depending on the context, content, audience, medium, and the capabilities of an attacker to gain legitimacy, impersonate, link, amplify, collect, and suppress. Harms may result regardless of Intent and Factual Accuracy of an attack. Intent is useful for anticipating escalation & future attacks. Truth will be leveraged by most attackers. Organizations have to consider Direct Targeting and Indirect Threats to Individuals, Groups, Organizations, and Beyond the Organization as well as their own Ingestion and Generation of harmful information. Focus on Harms to Self-Determination, Reputation, Economic Situation, and Operations. Practical \u201cSolutions\u201d for Civil Society: Increase understanding / practices around holistic security Integrate risk mitigation into existing systems and processes Strengthen external relationships and collaboration Deepening Step through the Harmful Information Mitigation Framework to Case Study 1 or 2 What are the harms or risks you find most important to address? (top 3) Which mitigations would you prioritize for implementation? (top 3) Synthesis Is the juice worth the squeeze? Assignments","title":"Harmful Information"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#summary","text":"What exactly is \u201charmful information\u201d? Attacks causing harms that stem from the use and/or abuse of information systems as they are designed and/or intended to be used. For example, a system might be designed to allow its users to spread hate speech to any user even though that behavior is against a community standards policy Major categories of abuses fall into misinformation and harassment","title":"Summary"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#learning-objectives","text":"Vocabulary and Classification of Harmful Information Approaches to Identifying, Prioritizing, and Mitigating Harmful Information","title":"Learning Objectives"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#pre-readings","text":"Sarah Jeong, Charlie Warzel, Brianna Wu, Joan Donovan. New York Times. \u201cEverything is GamerGate\u201d [ https://www.nytimes.com/interactive/2019/08/15/opinion/gamergate-twitter.html ] - Read all of the four essays. IFTF \u201cState-Sponsored Trolling: How Governments Are Deploying Disinformation as Part of Broader Digital Harassment Campaigns\u201d. Read pages 3 to 21 & 45 to 51. [ http://www.iftf.org/statesponsoredtrolling ] Cindy Otis. USA Today. \u201cAmericans could be a bigger fake news threat than Russians in the 2020 presidential campaign\u201d [ https://www.usatoday.com/story/opinion/2019/07/19/disinformation-attacks-americans-threaten-2020-election-column/1756092001/ ] InterAction \u201cDisinformation Toolkit.\u201d [ https://staging.interaction.org/documents/disinformation-toolkit/ ] Reply All podcast. \u201c#112 The Prophet\u201d Listen to or read transcript. [ https://www.gimletmedia.com/reply-all/112-the-prophet ] (Optional) Tahmina Ansari. First Draft. \u201cThis Muslim journalist embraced social media until it \u2018ruined\u2019 his life\u201d [ https://firstdraftnews.org/this-muslim-journalist-embraced-social-media-until-it-ruined-his-life/ ]","title":"Pre-Readings"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#resources","text":"","title":"Resources"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#mitigation-framework","text":"","title":"* Mitigation Framework"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#activities","text":"Beyond Hacking How might Twitter be used to harm an organization even when the site is used as designed (ie not being \u201chacked\u201d)? Vocabulary and Classification Problems Which category (Usually Acceptable, Sometimes/Borderline Acceptable, Always Unacceptable) do the following terms belong to: Propaganda \u2013 Disinformation \u2013 Misinformation \u2013 Malinformation \u2013 Internet Shutdowns - Harassment \u2013 Trolls \u2013 Bots \u2013 Doxxing \u2013 Mobbing \u2013 Swatting \u2013 Leaks \u2013 Sockpuppets \u2013 Astroturfing \u2013 Clickfarms - Deceptive Advertising \u2013 Exclusionary Advertising \u2013 Dog Whistles \u2013 Subtweeting \u2013 Parody News \u2013 Clickbait","title":"Activities"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#discussion","text":"How much does intent behind harmful information matter for the organization? How much does the truth of the harmful information matter for the organization?","title":"Discussion"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#input","text":"Harmful information threats can be considered as security risk management problems, however: Resources will be limited compared to scope of the problems Harms & risks are ill-defined for prioritization Less agreement on what \u201dbest practice\u201d looks like Threats may have greater impact depending on the context, content, audience, medium, and the capabilities of an attacker to gain legitimacy, impersonate, link, amplify, collect, and suppress. Harms may result regardless of Intent and Factual Accuracy of an attack. Intent is useful for anticipating escalation & future attacks. Truth will be leveraged by most attackers. Organizations have to consider Direct Targeting and Indirect Threats to Individuals, Groups, Organizations, and Beyond the Organization as well as their own Ingestion and Generation of harmful information. Focus on Harms to Self-Determination, Reputation, Economic Situation, and Operations. Practical \u201cSolutions\u201d for Civil Society: Increase understanding / practices around holistic security Integrate risk mitigation into existing systems and processes Strengthen external relationships and collaboration","title":"Input"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#deepening","text":"Step through the Harmful Information Mitigation Framework to Case Study 1 or 2 What are the harms or risks you find most important to address? (top 3) Which mitigations would you prioritize for implementation? (top 3)","title":"Deepening"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#synthesis","text":"Is the juice worth the squeeze?","title":"Synthesis"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Harmful_Information/#assignments","text":"","title":"Assignments"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Mitigation_Framework/","text":"Step 1. Threat Map. Identify potential threat methods for analysis. Subject Type Threat Type Individual Group Identity Organization Direct Bullying; coordinated targeting; hateful, inflammatory, or embarrassing comments; threats of violence; upsetting content; gendered threats; sustained harassment; mob harassment; sexual harassment; stalking; doxxing; SWATing; and account takeovers/lockouts. Tactics leveraging social cleavages (for example hate speech or dog whistles) such as race, ethnicity, socioeconomic status or class, gender, sexual orientation, religion, regional or national origin, citizenship status, occupation, employment status, age / generation, education, or political affiliation. Coordinated targeting to organizational accounts; Denial of service or access to an organization\u2019s content; Indirect Spreading of false or misleading information about an individual; defamatory information; disclosure of non-consensual intimate images; impersonation; hateful, inflammatory, or embarrassing comments. Spreading of false or misleading information about a social group; hate speech directed towards a social group; divisive speech that may be either opposed or supportive of various social groups. Mass internet shutdowns, establishing seemingly allied organizations to share disingenuous content; establishing opposition organizations to spread opposing viewpoints; imitation of the organization\u2019s online presence(eg, typosquatting). Ingestion Persuasion of the individual to believe or biased towards inaccurate information. Persuasion of groups to believe inaccurate information about other groups, sowing division or apathy or bolstering alliances. Persuasion of the organization to use inaccurate information in decision making. Generation Creation, publishing, or sharing of misinformation, harassment against co-workers and others outside of the organization Creation and spreading of misinformation; harassment against co-workers and others outside of the organization Creation / spreading of misinformation, harassment against co-workers and others outside of the organization Step 2. Harm Map. Connect scenarios to potential harms for the organization or its individuals or groups of individuals. Individual Harms Harms to Self Determination Definition Loss of autonomy Loss of autonomy includes needless changes in behavior, including self-imposed restrictions on freedom of expression or assembly. Loss of liberty Improper exposure to arrest or detainment. Even in democratic societies, false or negative information can lead to increased scrutiny, arrest or, abuse of governmental power. Power imbalance Information, or threat of disclosure, can create an inappropriate power imbalance or takes unfair advantage of a power imbalance between acquirer and the individual. Physical harm Actual physical harm to a person, including the potential to cause death. Psychological harm Information can cause psychological distress to the target such as increased anxiety, fear, and depression, possibly triggering reactions to previous trauma. This distress can also contribute to physical self-harm. Reputational Harms Loss of trust The breach of implicit or explicit expectations about the character and behavior between individuals or organizations. Loss of trust can leave entities reluctant to engage in further cooperation. Stigmatization Information can create a stigma that can cause embarrassment, emotional distress or discrimination. Economic Harms Financial losses Harms due to a result of loss of employment, business relationships, increased government scrutiny, and imprisonment. Group Harms Reputational Harms Discrimination Groups within an organization or individuals may be unfairly judged, scrutinized, or excluded based on their actual or perceived group affiliation. Stigmatization Information can create a stigma that can cause embarrassment, emotional distress or discrimination of a certain group. Organizational Harms Operational Harms Loss of productivity Inefficiencies due to decision-making based on inaccurate or misleading information leading to increased delays, false starts on program activities, or time spent sorting and verifying information for accuracy. Loss of mission impact Decreased impact due to organizational decision-making, activities that incorporate or promote inaccurate information, or from the influence of competing narratives on the organizations\u2019 supported beneficiaries. Reputational Harms Loss of trust Damage to trust with public and private entities such as individuals, partner organizations, funders, government agencies, and other external supporters. Loss of morale Damage to internal attitudes from individual embarrassment, emotional distress or discrimination due to association with the organization. Economic Harms Direct financial losses Lost time and money spent to counter false information or improve security. Indirect financial losses Lost funding and business relationships due to reputational damage or lack of productivity. Step 3. Threat Scenarios. Develop practical description of the threat and challenge assumptions. Probing Questions Adversary What is the identity of the adversary responsible for the harmful information? What are the goals (if any) of an adversary sharing the harmful information? What resources might an adversary have at their disposal? Content Does the content contain personal information? Does the content threaten or create fear for one\u2019s safety? What elements of \u201ctruth\u201d are contained in the message? Context How is the harmful information delivered? When and how often are interactions taking place? How might the harmful information affect current events or campaigns? Audience Who is the intended recipient of the information? How could various stakeholders of the organization perceive the harmful information? What social norms might be violated? How might the audience react to the harmful information? How might law enforcement or government regulators react to the harmful information, if known? Legitimacy What might give this threat legitimacy with an influential audience? Why might the threat\u2019s message or methods be perceived as normatively acceptable? How might those information sources already deemed legitimate by certain audiences spread or give additional credibility to the threat? Who in power may spread or give credibility to the threat? Impersonation How might an adversary take over or share information from an account belonging to the target? How might an adversary convince an audience that their information is being shared with the target\u2019s approval? How might an adversary bypass any vetting processes intended to ensure representations are made by authentic sources of information? Linking How have associates of the target been subject to harmful information threats in the past? How might publicly disclosed information about associations of the target tie to additional harmful information threats? How might historical information about the target\u2019s associations and activities be used in combination with the threat? Amplification How might an adversary disseminate information to a large audience? What is the current number of followers or subscribers of the adversary? How might a harmful message move, intentionally or unintentionally, from less active online forums to more popular platforms? How has an adversary\u2019s message or similar threats been amplified in the past? Collection How might sensitive information about the target be gathered by an adversary? How might a threat have been able to access, store, or share private information about the target? How might publicly available information about the target give credibility to a threat? Suppressing How might an adversary prevent opposing perspectives from being shared and heard? Why might the target be unable to use existing their information channels (website, social media accounts, newsletter) to counter the threat? How might an audience be blocked from accessing the target\u2019s information or counter-messaging? Step 4: Mitigation Map. Select suitable controls to mitigate potential harms. Identify Identify Harmful Information Risks Identify Harmful Information Risks Identify Potential Threats Consider threats to individuals, groups, or the organization Consider direct targeting, indirect attacks, ingestion, and generation Connect Threats to Potential Harms Identify the impact of potential threats to individuals, groups, and the organization Consider physical, reputational, financial harms Create and Prioritize Threat Scenarios Describe threat scenarios in detail Evaluate and prioritize scenarios based on likelihood and impact Identify informal practices or formal policies Identify informal practices or formal policies Security (Physical or Digital) or Incident Response Identify and evaluate the following: Evaluate security risk management abilities and training. Consider how psychosocial risks are addressed in the risk assessment / management program. Improve account security of organizational and personal social media accounts. Decrease the online availability of personal information about staff members. Other: Social Media Use Identify and evaluate the following: Acceptable social media use for organizational accounts, including response policy for comments and private messages. Monitoring protocols for mentions of your organization and staff members in social media, comments, and forums. How policies consider the subjective experience of online abuse. Other: Communications and Public Relations strategy Identify and evaluate the following: Media literacy and verification processes to avoid sharing and consuming misinformation. Plans to address potential information threats in advance. Existing messaging that addresses misinformation directly or offers constructive alternative narratives in outreach to funders and stakeholders Contacts at social media platforms, media outlets, academia, government, and intermediaries that can support the organization during a crisis \u201cFirst page\u201d search results for the organization and its members Other: Human Resources or Employee Health & Wellness Identify and evaluate the following: The ability and experience of members of historically disadvantaged or marginalized groups to report, respond, and recover from harmful information Reporting and confidential disclosure mechanisms for online and offline abuse Partnerships with programs offering mental health counseling, trainers, and other resources for victims and subjects of harmful information Other: Workplace Ethics / Code of Conduct Identify policies and practices regarding: Financial accounting Managing conflict of interests Political endorsements and advocacy Whistleblower protections Other: Evaluate Organizational Culture Evaluate Organization\u2019s capacity to address harmful information Leadership Identify and evaluate the following: Buy-in to address concerns of misinformation and online abuse Openness and transparency on areas for improvement Other: Values Identify and evaluate the following: Explicit values Implicit values Other: Performance Identify and evaluate the following: How leadership and staff uphold organizational values How staff and leadership perform and manage the identified policies or practices Other: Protect Improve Organization-wide Digital Security Protect the confidentiality, integrity, and availability of the organization\u2019s and individuals\u2019 information systems Maintaining confidentiality Secure accounts (personal & organizational) Secure devices Implement network monitoring Other: Maintaining availability of information Implement DoS Protection Enable Censorship Circumvention Other: Maintain integrity of information Enable domain spoofing protection. eg DMARC Enable DNS Hijacking protection (DNSSEC) Register similar URLs Other: Minimize the Availability of Potentially Harmful Information. Reducing or obfuscating available open source information on organization or members. Organizational Data Management Implement data minimization strategy Conduct open source audit Other: Personal Data Management Review Old Social Media Posts Review Social Media Privacy Settings \u201cDox Yourself\u201d Other: Maintain Social Media Management best practices Create policies for how to engage with legitimate commentators versus \u201ctrolls\u201d in public and via private messages. Maintain social media manager anonymity. Other: Strengthen Communication Plan and Social Media Policies Develop communication plan and social media policies Create a strategy for when to let harmful information to \u201cdie out\u201d, when to counter with direct refutations, or when to promote new narratives. Create messages in advance. Connect with a network of journalists and fact-checkers. Create advertising and automation strategies for messaging amplification. Other: Maintaining organizational presence and accurate information on authoritative sources of information Improve web presence and search engine optimization including strengthened networks of supporting sites. Correct the record on authoritative sources such as Wikipedia Other: Detect Implement Individual Detection Develop individual skills to identify known strategies for creating harmful information Identify and learn how to react when in potentially compromising situations Verify the identity of new contacts, online and offline Familiarize with counterintelligence tradecraft Avoid discussing politically or culturally sensitive topics with strangers Other: Improve media literacy to reduce an organization's susceptibility to its own digestion and spread of misinformation. Teach source checking Implement content verification procedures Other: Implement Organizational Detection Develop organizational policies and practice for detecting harmful content Implement manual content monitoring Implement and train staff on reporting harmful (or suspected) online information, including seemingly innocuous behavior Create a plan to relieve subjects of abuse from self-monitoring Create an emergency plan for manual monitoring of abuse campaigns by staff. Other: Implement automatic content monitoring Set free keyword notification tools such as Google Alerts Preset filtered feeds in tools such as TweetDeck Employ social sensing or brand monitoring services Other: Implement external content monitoring Collaborate with other organizations to monitor and research developments in misinformation in one\u2019s domain Create an intake plan for colleagues from other organizations that request help Other: Respond Immediate Response - \u201cTop 3 Things\u201d, planned in advance. Physical Safety and Wellbeing Train staff for initial shock: \u201cbreathe and connect with support, don\u2019t handle this alone\u201d Plan to move to safety if credible threats \u201cBetter to be safe than sorry\u201d policies Other: Digital Security Conduct Incident Response procedures Other: Gather Evidence and Stay Aware of Threats Monitor and Archive (Tweetdeck, Dox Yourself, Hunch.ly, Archive.org, Google Alerts) Manage manual monitoring of abuse campaigns by co-workers accounting for burn-out. Other: Next Stage Response Prevent Escalation of Harms Respond to content on Platforms Engage with platforms or intermediaries for removal of harmful content or automated accounts Use tools to identify, ignore, and/or block bots/trolls Other: Execute Crisis Communication Plan Engage with supporters and funders to keep them informed Inform public via media or other outlets (as needed) Other: Engage legal protections from harassment or threats. Notify law enforcement authorities if appropriate (SWATing prevention) Contact legal counsel for jurisdiction-based guidance Other: Recover Improving Safety Holistic Recovery Rebuild Psychological Resilience Offer multiple avenues for coping Provide counseling services for employees Other: Improve Physical Protections Reassess physical vulnerabilities at work locations and increase protections as appropriate Revisit personal security plans for employees Other: Recover Digital Safety Reassess digital vulnerabilities and increase protections as appropriate Other: Repair Information Harms Refine Communications Plan Adjust messaging based on counternarratives and situation Engage with supporters and funders to keep them informed. Inform public via media or other outlets Other: Continue to use Platform-Specific Methods Search engine optimization Search result downranking Content removal processes such as Right to be Forgotten / DMCA. Other: Seek Legal Remedies Contact legal counsel for jurisdiction-based guidance Other: Reassessment Conduct a Formal After-Event Assessment Learn how the organization could improve Learn and validate what people did well Describe resources that you wish were available. Other:","title":"Mitigation Framework"},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Mitigation_Framework/#step-1-threat-map-identify-potential-threat-methods-for-analysis","text":"Subject Type Threat Type Individual Group Identity Organization Direct Bullying; coordinated targeting; hateful, inflammatory, or embarrassing comments; threats of violence; upsetting content; gendered threats; sustained harassment; mob harassment; sexual harassment; stalking; doxxing; SWATing; and account takeovers/lockouts. Tactics leveraging social cleavages (for example hate speech or dog whistles) such as race, ethnicity, socioeconomic status or class, gender, sexual orientation, religion, regional or national origin, citizenship status, occupation, employment status, age / generation, education, or political affiliation. Coordinated targeting to organizational accounts; Denial of service or access to an organization\u2019s content; Indirect Spreading of false or misleading information about an individual; defamatory information; disclosure of non-consensual intimate images; impersonation; hateful, inflammatory, or embarrassing comments. Spreading of false or misleading information about a social group; hate speech directed towards a social group; divisive speech that may be either opposed or supportive of various social groups. Mass internet shutdowns, establishing seemingly allied organizations to share disingenuous content; establishing opposition organizations to spread opposing viewpoints; imitation of the organization\u2019s online presence(eg, typosquatting). Ingestion Persuasion of the individual to believe or biased towards inaccurate information. Persuasion of groups to believe inaccurate information about other groups, sowing division or apathy or bolstering alliances. Persuasion of the organization to use inaccurate information in decision making. Generation Creation, publishing, or sharing of misinformation, harassment against co-workers and others outside of the organization Creation and spreading of misinformation; harassment against co-workers and others outside of the organization Creation / spreading of misinformation, harassment against co-workers and others outside of the organization","title":"Step 1. Threat Map. Identify potential threat methods for analysis."},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Mitigation_Framework/#step-2-harm-map-connect-scenarios-to-potential-harms-for-the-organization-or-its-individuals-or-groups-of-individuals","text":"Individual Harms Harms to Self Determination Definition Loss of autonomy Loss of autonomy includes needless changes in behavior, including self-imposed restrictions on freedom of expression or assembly. Loss of liberty Improper exposure to arrest or detainment. Even in democratic societies, false or negative information can lead to increased scrutiny, arrest or, abuse of governmental power. Power imbalance Information, or threat of disclosure, can create an inappropriate power imbalance or takes unfair advantage of a power imbalance between acquirer and the individual. Physical harm Actual physical harm to a person, including the potential to cause death. Psychological harm Information can cause psychological distress to the target such as increased anxiety, fear, and depression, possibly triggering reactions to previous trauma. This distress can also contribute to physical self-harm. Reputational Harms Loss of trust The breach of implicit or explicit expectations about the character and behavior between individuals or organizations. Loss of trust can leave entities reluctant to engage in further cooperation. Stigmatization Information can create a stigma that can cause embarrassment, emotional distress or discrimination. Economic Harms Financial losses Harms due to a result of loss of employment, business relationships, increased government scrutiny, and imprisonment. Group Harms Reputational Harms Discrimination Groups within an organization or individuals may be unfairly judged, scrutinized, or excluded based on their actual or perceived group affiliation. Stigmatization Information can create a stigma that can cause embarrassment, emotional distress or discrimination of a certain group. Organizational Harms Operational Harms Loss of productivity Inefficiencies due to decision-making based on inaccurate or misleading information leading to increased delays, false starts on program activities, or time spent sorting and verifying information for accuracy. Loss of mission impact Decreased impact due to organizational decision-making, activities that incorporate or promote inaccurate information, or from the influence of competing narratives on the organizations\u2019 supported beneficiaries. Reputational Harms Loss of trust Damage to trust with public and private entities such as individuals, partner organizations, funders, government agencies, and other external supporters. Loss of morale Damage to internal attitudes from individual embarrassment, emotional distress or discrimination due to association with the organization. Economic Harms Direct financial losses Lost time and money spent to counter false information or improve security. Indirect financial losses Lost funding and business relationships due to reputational damage or lack of productivity.","title":"Step 2. Harm Map. Connect scenarios to potential harms for the organization or its individuals or groups of individuals."},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Mitigation_Framework/#step-3-threat-scenarios-develop-practical-description-of-the-threat-and-challenge-assumptions","text":"Probing Questions Adversary What is the identity of the adversary responsible for the harmful information? What are the goals (if any) of an adversary sharing the harmful information? What resources might an adversary have at their disposal? Content Does the content contain personal information? Does the content threaten or create fear for one\u2019s safety? What elements of \u201ctruth\u201d are contained in the message? Context How is the harmful information delivered? When and how often are interactions taking place? How might the harmful information affect current events or campaigns? Audience Who is the intended recipient of the information? How could various stakeholders of the organization perceive the harmful information? What social norms might be violated? How might the audience react to the harmful information? How might law enforcement or government regulators react to the harmful information, if known? Legitimacy What might give this threat legitimacy with an influential audience? Why might the threat\u2019s message or methods be perceived as normatively acceptable? How might those information sources already deemed legitimate by certain audiences spread or give additional credibility to the threat? Who in power may spread or give credibility to the threat? Impersonation How might an adversary take over or share information from an account belonging to the target? How might an adversary convince an audience that their information is being shared with the target\u2019s approval? How might an adversary bypass any vetting processes intended to ensure representations are made by authentic sources of information? Linking How have associates of the target been subject to harmful information threats in the past? How might publicly disclosed information about associations of the target tie to additional harmful information threats? How might historical information about the target\u2019s associations and activities be used in combination with the threat? Amplification How might an adversary disseminate information to a large audience? What is the current number of followers or subscribers of the adversary? How might a harmful message move, intentionally or unintentionally, from less active online forums to more popular platforms? How has an adversary\u2019s message or similar threats been amplified in the past? Collection How might sensitive information about the target be gathered by an adversary? How might a threat have been able to access, store, or share private information about the target? How might publicly available information about the target give credibility to a threat? Suppressing How might an adversary prevent opposing perspectives from being shared and heard? Why might the target be unable to use existing their information channels (website, social media accounts, newsletter) to counter the threat? How might an audience be blocked from accessing the target\u2019s information or counter-messaging?","title":"Step 3. Threat Scenarios. Develop practical description of the threat and challenge assumptions."},{"location":"Clinic_Curriculum/Modules/Harmful_Information/Mitigation_Framework/#step-4-mitigation-map-select-suitable-controls-to-mitigate-potential-harms","text":"Identify Identify Harmful Information Risks Identify Harmful Information Risks Identify Potential Threats Consider threats to individuals, groups, or the organization Consider direct targeting, indirect attacks, ingestion, and generation Connect Threats to Potential Harms Identify the impact of potential threats to individuals, groups, and the organization Consider physical, reputational, financial harms Create and Prioritize Threat Scenarios Describe threat scenarios in detail Evaluate and prioritize scenarios based on likelihood and impact Identify informal practices or formal policies Identify informal practices or formal policies Security (Physical or Digital) or Incident Response Identify and evaluate the following: Evaluate security risk management abilities and training. Consider how psychosocial risks are addressed in the risk assessment / management program. Improve account security of organizational and personal social media accounts. Decrease the online availability of personal information about staff members. Other: Social Media Use Identify and evaluate the following: Acceptable social media use for organizational accounts, including response policy for comments and private messages. Monitoring protocols for mentions of your organization and staff members in social media, comments, and forums. How policies consider the subjective experience of online abuse. Other: Communications and Public Relations strategy Identify and evaluate the following: Media literacy and verification processes to avoid sharing and consuming misinformation. Plans to address potential information threats in advance. Existing messaging that addresses misinformation directly or offers constructive alternative narratives in outreach to funders and stakeholders Contacts at social media platforms, media outlets, academia, government, and intermediaries that can support the organization during a crisis \u201cFirst page\u201d search results for the organization and its members Other: Human Resources or Employee Health & Wellness Identify and evaluate the following: The ability and experience of members of historically disadvantaged or marginalized groups to report, respond, and recover from harmful information Reporting and confidential disclosure mechanisms for online and offline abuse Partnerships with programs offering mental health counseling, trainers, and other resources for victims and subjects of harmful information Other: Workplace Ethics / Code of Conduct Identify policies and practices regarding: Financial accounting Managing conflict of interests Political endorsements and advocacy Whistleblower protections Other: Evaluate Organizational Culture Evaluate Organization\u2019s capacity to address harmful information Leadership Identify and evaluate the following: Buy-in to address concerns of misinformation and online abuse Openness and transparency on areas for improvement Other: Values Identify and evaluate the following: Explicit values Implicit values Other: Performance Identify and evaluate the following: How leadership and staff uphold organizational values How staff and leadership perform and manage the identified policies or practices Other: Protect Improve Organization-wide Digital Security Protect the confidentiality, integrity, and availability of the organization\u2019s and individuals\u2019 information systems Maintaining confidentiality Secure accounts (personal & organizational) Secure devices Implement network monitoring Other: Maintaining availability of information Implement DoS Protection Enable Censorship Circumvention Other: Maintain integrity of information Enable domain spoofing protection. eg DMARC Enable DNS Hijacking protection (DNSSEC) Register similar URLs Other: Minimize the Availability of Potentially Harmful Information. Reducing or obfuscating available open source information on organization or members. Organizational Data Management Implement data minimization strategy Conduct open source audit Other: Personal Data Management Review Old Social Media Posts Review Social Media Privacy Settings \u201cDox Yourself\u201d Other: Maintain Social Media Management best practices Create policies for how to engage with legitimate commentators versus \u201ctrolls\u201d in public and via private messages. Maintain social media manager anonymity. Other: Strengthen Communication Plan and Social Media Policies Develop communication plan and social media policies Create a strategy for when to let harmful information to \u201cdie out\u201d, when to counter with direct refutations, or when to promote new narratives. Create messages in advance. Connect with a network of journalists and fact-checkers. Create advertising and automation strategies for messaging amplification. Other: Maintaining organizational presence and accurate information on authoritative sources of information Improve web presence and search engine optimization including strengthened networks of supporting sites. Correct the record on authoritative sources such as Wikipedia Other: Detect Implement Individual Detection Develop individual skills to identify known strategies for creating harmful information Identify and learn how to react when in potentially compromising situations Verify the identity of new contacts, online and offline Familiarize with counterintelligence tradecraft Avoid discussing politically or culturally sensitive topics with strangers Other: Improve media literacy to reduce an organization's susceptibility to its own digestion and spread of misinformation. Teach source checking Implement content verification procedures Other: Implement Organizational Detection Develop organizational policies and practice for detecting harmful content Implement manual content monitoring Implement and train staff on reporting harmful (or suspected) online information, including seemingly innocuous behavior Create a plan to relieve subjects of abuse from self-monitoring Create an emergency plan for manual monitoring of abuse campaigns by staff. Other: Implement automatic content monitoring Set free keyword notification tools such as Google Alerts Preset filtered feeds in tools such as TweetDeck Employ social sensing or brand monitoring services Other: Implement external content monitoring Collaborate with other organizations to monitor and research developments in misinformation in one\u2019s domain Create an intake plan for colleagues from other organizations that request help Other: Respond Immediate Response - \u201cTop 3 Things\u201d, planned in advance. Physical Safety and Wellbeing Train staff for initial shock: \u201cbreathe and connect with support, don\u2019t handle this alone\u201d Plan to move to safety if credible threats \u201cBetter to be safe than sorry\u201d policies Other: Digital Security Conduct Incident Response procedures Other: Gather Evidence and Stay Aware of Threats Monitor and Archive (Tweetdeck, Dox Yourself, Hunch.ly, Archive.org, Google Alerts) Manage manual monitoring of abuse campaigns by co-workers accounting for burn-out. Other: Next Stage Response Prevent Escalation of Harms Respond to content on Platforms Engage with platforms or intermediaries for removal of harmful content or automated accounts Use tools to identify, ignore, and/or block bots/trolls Other: Execute Crisis Communication Plan Engage with supporters and funders to keep them informed Inform public via media or other outlets (as needed) Other: Engage legal protections from harassment or threats. Notify law enforcement authorities if appropriate (SWATing prevention) Contact legal counsel for jurisdiction-based guidance Other: Recover Improving Safety Holistic Recovery Rebuild Psychological Resilience Offer multiple avenues for coping Provide counseling services for employees Other: Improve Physical Protections Reassess physical vulnerabilities at work locations and increase protections as appropriate Revisit personal security plans for employees Other: Recover Digital Safety Reassess digital vulnerabilities and increase protections as appropriate Other: Repair Information Harms Refine Communications Plan Adjust messaging based on counternarratives and situation Engage with supporters and funders to keep them informed. Inform public via media or other outlets Other: Continue to use Platform-Specific Methods Search engine optimization Search result downranking Content removal processes such as Right to be Forgotten / DMCA. Other: Seek Legal Remedies Contact legal counsel for jurisdiction-based guidance Other: Reassessment Conduct a Formal After-Event Assessment Learn how the organization could improve Learn and validate what people did well Describe resources that you wish were available. Other:","title":"Step 4: Mitigation Map. Select suitable controls to mitigate potential harms."},{"location":"Clinic_Infrastructure/Phishing_Simulation/","text":"Last Updated: 27 April 2020 How to Setup Phishing Simulations for your Clinic or Lab. Introduction to Phishing Phishing is on the rise in both severity and amount of attacks. According to the 2019 Data Breach Investigations Report conducted by Verizon, phishing is the top threat action used in 32% of all successful data breaches, with attacks involving social engineering and malware [1]. While there is a wide variety of how to do phishing guides, ranging from advocacy groups such as EFF to commercial products, available on the web, we were unable to find any publicly accessible phishing policies. We can draw some insights from research that has been conducted in the space of evaluating the effectiveness of phishing training as well as the CPHS IRB process as a framework for ethical considerations [2, 3]. Citizen Clinic Phishing Policy Existing Phishing Policies UC Berkeley has an Information Security and Policy group that reportedly has an existing phishing policy and does conduct phishing training for the university. We have reached out to security@berkeley.edu , but have yet to receive a response. Their resources can be found at: https://security.berkeley.edu/resources/phishing And they have a phishing quiz that is currently in use: https://phishingquiz.withgoogle.com For conducting phishing training at UC Berkeley, one is supposed to contact security@berkeley.edu for questions and review of their procedures. IRB for Phishing Policy Though much of the IRB policies are more research specific, we can leverage its frameworks for thinking about how to protect the rights and welfare of human subjects. The section on Assessment of Risks and Benefits as laid out in the Belmont Report [4] on which ethical research guidelines are based is especially pertinent. The basic ethical principles the report asks us to follow are: Respect for persons - individuals should be treated as autonomous agents and that persons with diminished autonomy (e.g. underserved populations) are entitled to protection Beneficence - actions should (1) do not harm and (2) maximize possible benefits and minimize possible harms Justice - consider who ought to receive the benefits and bear its burdens (this is more relevant for research, such as in choosing what population to involve) Of the three, the most important in our assessment is the principle of beneficence in assessing the risk versus benefit of a good policy. The report uses the following definitions: \u201cBenefit\u201d as non-probabilistic positive value related to health or welfare; this may include contribution to generalizable knowledge and direct benefit to participant(s) \u201cRisk\u201d as possibility that harm may occur; including both chance (probability of experiencing harm) and severity (magnitude of such harm) We recommend when developing policies to have at least one author or reviewer having taken the Group 2 Human Subjects Training: Social and Behavioral Research Investigators Course, available to all UC Berkeley affiliates through CPHS and CITI, available at https://cphs.berkeley.edu/training.html . Relevant sections from the CPHS training are as follows: Assessing risk and privacy Assessing Risk (ID 503) Informed Consent (ID 504) Privacy and Confidentiality (ID 505) Given clinic work with vulnerable populations Vulnerable Subjects (ID 483) Unanticipated Problems and Reporting Requirements in Social and Behavioral Research (ID 14928) Given work with groups in other nations Cultural Competence in Research (ID 15166) International Research (ID 509) Considerations for Constructing a Policy When forming a phishing policy, we would recommend considering the following questions: What benefits would your phishing training and simulation bring to your organization? What is the goal of the phishing training or simulation? For my organization? To assess the risk of phishing to my organization To evaluate the effectiveness of phishing trainings (e.g. they do not click 1 week, 1 month, or 6 months in the future) For the participants? To introduce and inform participants about phishing To remind participants about phishing When should participants be informed (e.g. ahead of time, What should be the size of my phishing training (e.g. select individuals, all individuals, by team, by department, across the organization)? Where should training material be placed (e.g. in a live workshop ahead of time, in the phishing email, in training afterwards)? When do you inform participants they may be sent What emotional duress or stress might your training materials (emails or presentation) cause your participants? How long should phishing simulations last? A policy for a phishing simulation should include the following: Goal of outcome Target group definition Set duration Plan for disclosure to participants Ahead of time: consent getting, alert (potentially with opt out) Afterwards: debrief, share outcomes, additional training Review of phishing materials that evaluates potential harms (e.g. emotional duress or stress) against actual benefits (for organization or participant) If our goal is to conduct generalizable research, we should additionally consider: Who should be included in the sample? Who should we exclude (e.g. undue burden)? Can this take place in a lab or field setting? What is my outcome variable? Should I get informed consent ahead of time? How should I debrief the participants? Table 1, shown below, is from a 2018 CHI paper provides an overview of previous research design for phishing. Since they were interested in understanding how people who respond to different kinds of training material when shown after they have clicked on the phishing link, they did not get informed consent ahead of time. In this situation the debrief becomes very important as is having an IRB already in place [2]. Also interesting is that phishing studies [2, 3] referred to timeframes for phishing as short (2-days), medium (7-days) and long (30-days). Outcome variables refer to if the user clicked on the phishing link (click), if they shared personal information (info), or click and information (both). Please note that any phishing done for generalizable research purposes would need to submit a protocol for IRB review. You can find more information at https://cphs.berkeley.edu/ . Limitations and Future Work Due to time constraints, there is much more work that can be done, including but not limited to conducting expert interviews, getting existing phishing policies currently in practice, and getting feedback from practitioners and past phishing simulation participants Further questions to consider: Is the risk versus benefit assessment approach of the IRB a good approach to consider? Is there another framework that can be used? How can we assess what is acceptable \"harm\" or \"risk\" in a phishing policy? What are some normative constraints to consider (e.g. culture of organization, size of campaign, frequency of phishing attempts)? Who are all of the stakeholders who should be considered with regard to a phishing policy (e.g. managers, employees, HR, legal team)? References 2019 Data Breach Investigations Report. Verizon, 2019. https://enterprise.verizon.com/resources/reports/dbir/ Rick Wash and Molly M. Cooper. 2018. Who Provides Phishing Training?: Facts, Stories, and People Like Me. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Paper 492, 12 pages. DOI: https://doi.org/10.1145/3173574.3174066 Kumaraguru, Ponnurangam & Sheng, Steve & Acquisti, Alessandro & Cranor, Lorrie & Hong, Jason. (2008). Lessons From a Real World Evaluation of Anti-Phishing Training. eCrime Researchers Summit, eCrime 2008. 1 - 12. 10.1109/ECRIME.2008.4696970. National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research. The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research. [Bethesda, Md.]: The Commission, 1978. https://www.citiprogram.org/citidocuments/_001pic/1127_the_belmont_report.pdf Sample Policies Internal Attribute Goal To conduct a risk assessment of current employee phishing behaviors Type Phishing simulation Target Group All employees of the organization Content Targets will be sent emails that look similar to email already sent to the organization with indicators such as, incorrect sender email addresses, poor formatting. Content will not utilize spear-phishing (using personalized information of target) and will be generalized to the organization Content will utilize social engineering strategies such as urgency while avoiding threatening language. Duration Around 40 days. No longer than 90 days Repeatability Yes Outcome If participants click on link in phishing email; if participants disclose information to sender of phishing email Disclosure Participants were given no prior training, one email was sent to inform them that the organization would be conducting a phishing simulation. At the end of the simulation, participants will be sent an email allowing them to review their own behavior. Data & Privacy For the duration of the simulation information will be collected on each individual regarding if they clicked and/or shared information due to phishing. At the conclusion of the duration each participant will be sent a report regarding their behaviors. The overall results will be summed together in a final report for executive review. Individual performance in the phishing simulation will be retained for future follow-ups. If no future-follow-up is planned, it is advised that the non-summative data be deleted. Risk Emotional duress or stress due to content of phishing email. Stress due to disclosure of individual reports. Data breach of individual identifiers along with phishing performance data. Benefit To understand current phishing risk faced by organization, increase awareness, and improve employee reporting of suspicious emails External Attribute Goal To raise awareness and introduce phishing as a concept to members of a client organization Type Phishing simulation coupled with training Target Group All employees of the client organization Content Training session will take place first, introducing employees to the concept of phishing, provide examples, and recommend that they forward suspicious emails to a given email in IT. Targets will be sent emails that look similar to email already sent to the organization with indicators such as, incorrect sender email addresses, poor formatting. Upon clicking, targets will be informed that they have been phished, directed to an info page about phishing, and given a quiz (optional) to take about phishing. Content will utilize social engineering strategies such as urgency and may include threatening but non-violent language. Duration 30 days Repeatability Yes Outcome If participants click on link in phishing email; if participants forward suspicious email to IT Disclosure Participants are given prior training and are informed that they will be targeted with phishing emails over the course of the next month. They are asked to be on the look out and given the option to opt out. Data & Privacy For the duration of the simulation information will be collected of clicks and forwards. This information will not be collected in a personally identifiable way. At the conclusion, the overall results will be summed together in a final report for executive review and the collected information deleted. Risk Emotional duress or stress due to content of phishing email. Stress from being asked to look out for phishing emails Benefit To inform participants about phishing, raise awareness, and encourage safer behaviors regarding suspicious emails Research Attribute Goal To understand the impact of behavior change if click content of phishing simulation email is (a) a quiz about phishing, (b) information about phishing, (c) no information is provided about phishing and target is sent via link to where they believe they were going Type Phishing simulation Target Group Selected targets in an organization randomly selected and distributed over race and gender Content Targets will be sent emails that look similar to email already sent to the organization with indicators such as, incorrect sender email addresses, poor formatting. Content will not utilize spear-phishing (using personalized information of target) and will be generalized to the organization Content will utilize social engineering strategies such as urgency while avoiding threatening language. Duration At 2, 7, and 42 days Repeatability Yes (3 times) Outcome If participants click on link in phishing email; if participants disclose information to sender of phishing email Disclosure Participants will be given no prior training. Informed consent will not be gotten ahead of time. Deception is necessary because awareness of phishing could influence participant\u2019s natural responses. Participants will be debriefed after the duration of the experiment has elapsed and informed of the deception. Data & Privacy For the duration of the simulation information will be collected on each individual regarding if they clicked and/or shared information due to phishing. Data will be saved in a way to anonymize the participants. The overall results will be summed together in a final report for executive review. All collected data except for the summative analysis will be deleted at completion. Risk Emotional duress or stress due to content of phishing email. Deception in case c, where target is unaware they were phished. Benefit To develop generalizable knowledge about how different after-click content can influence future behavior to better understand what makes more effective phishing simulations Sample End of Exercise Notification Hi NAME(S) , This notification is for your awareness that, as of TIME today, DATE , the phishing attack simulation Citizen Clinic conducted for the NAME OF ORG has concluded. In my opinion, the results will successfully highlight practices to sustain and improve upon both at the individual and organizational level. There are some things that NAME OF ORG did well and areas that NAME OF ORG will need to improve upon to increase their digital security. We will compile a report of our findings to share with leadership in private and with MODIFYasNEEDED as previously discussed. We will discuss areas for improvement and procedures for recovery & response. Do advise participants that we took steps to mitigate risks such as no passwords being collected / stored and requesting account credentials for accounts that already have multi-factor authentication enabled or presumably would be \"virtual identities.\" Any information sent to the two \"attacker\" accounts is also protected by strong authentication (Yubikeys). Security is a team effort so any information disclosed should not seem like personal failures, but a combination of weak links in a chain. When a participant realizes they did disclose information to us, they should also realize that their disclosure was part of a larger system where ultimately the odds (and human nature) are stacked up against them. Participants should not compare themselves with others - neither at the individual or organizational level. Instead, we seek improvement that is relative to the current state - the goal is that participants are themselves better prepared to handle similar threats today or tomorrow compared to where they were yesterday. That being said: 1) Participants should know that they will not be receiving any more simulated phishing emails from us via our attacker personas ( INSERT ATTACKER EMAILS ). It is possible that prior emails may be bumped in their inbox due to your email service's reminder feature. Any forms or \"malicious\" links have been disabled. Any messages sent to those accounts will not be returned. 2) The two attacker persona accounts ( INSERT ATTACKER EMAILS ) have already been reported and confirmed. We will detail the attacks in our brief, but for participants' peace of mind, there is no need to take any immediate recovery steps, although changing one's password, reviewing sign-in activity, and ensuring multi-factor authentication is enabled can provide some relief to personal feelings of discomfort. 3) The NAME OF ORG should resume their security and incident response policies & practices as usual. We're not in a posture to continually evaluate suspicious emails, but we're still, of course, happy to help as we can. XYZ should, in most cases, be your primary resource beyond internal information sharing and precautions. Let me know if you have any questions. Thanks for participating! Note: Additional confirmation of end of exercise to be sent via trusted channel (eg. Signal instead of email)","title":"Phishing Simulation"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#how-to-setup-phishing-simulations-for-your-clinic-or-lab","text":"","title":"How to Setup Phishing Simulations for your Clinic or Lab."},{"location":"Clinic_Infrastructure/Phishing_Simulation/#introduction-to-phishing","text":"Phishing is on the rise in both severity and amount of attacks. According to the 2019 Data Breach Investigations Report conducted by Verizon, phishing is the top threat action used in 32% of all successful data breaches, with attacks involving social engineering and malware [1]. While there is a wide variety of how to do phishing guides, ranging from advocacy groups such as EFF to commercial products, available on the web, we were unable to find any publicly accessible phishing policies. We can draw some insights from research that has been conducted in the space of evaluating the effectiveness of phishing training as well as the CPHS IRB process as a framework for ethical considerations [2, 3].","title":"Introduction to Phishing"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#citizen-clinic-phishing-policy","text":"","title":"Citizen Clinic Phishing Policy"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#existing-phishing-policies","text":"UC Berkeley has an Information Security and Policy group that reportedly has an existing phishing policy and does conduct phishing training for the university. We have reached out to security@berkeley.edu , but have yet to receive a response. Their resources can be found at: https://security.berkeley.edu/resources/phishing And they have a phishing quiz that is currently in use: https://phishingquiz.withgoogle.com For conducting phishing training at UC Berkeley, one is supposed to contact security@berkeley.edu for questions and review of their procedures.","title":"Existing Phishing Policies"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#irb-for-phishing-policy","text":"Though much of the IRB policies are more research specific, we can leverage its frameworks for thinking about how to protect the rights and welfare of human subjects. The section on Assessment of Risks and Benefits as laid out in the Belmont Report [4] on which ethical research guidelines are based is especially pertinent. The basic ethical principles the report asks us to follow are: Respect for persons - individuals should be treated as autonomous agents and that persons with diminished autonomy (e.g. underserved populations) are entitled to protection Beneficence - actions should (1) do not harm and (2) maximize possible benefits and minimize possible harms Justice - consider who ought to receive the benefits and bear its burdens (this is more relevant for research, such as in choosing what population to involve) Of the three, the most important in our assessment is the principle of beneficence in assessing the risk versus benefit of a good policy. The report uses the following definitions: \u201cBenefit\u201d as non-probabilistic positive value related to health or welfare; this may include contribution to generalizable knowledge and direct benefit to participant(s) \u201cRisk\u201d as possibility that harm may occur; including both chance (probability of experiencing harm) and severity (magnitude of such harm) We recommend when developing policies to have at least one author or reviewer having taken the Group 2 Human Subjects Training: Social and Behavioral Research Investigators Course, available to all UC Berkeley affiliates through CPHS and CITI, available at https://cphs.berkeley.edu/training.html . Relevant sections from the CPHS training are as follows: Assessing risk and privacy Assessing Risk (ID 503) Informed Consent (ID 504) Privacy and Confidentiality (ID 505) Given clinic work with vulnerable populations Vulnerable Subjects (ID 483) Unanticipated Problems and Reporting Requirements in Social and Behavioral Research (ID 14928) Given work with groups in other nations Cultural Competence in Research (ID 15166) International Research (ID 509)","title":"IRB for Phishing Policy"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#considerations-for-constructing-a-policy","text":"When forming a phishing policy, we would recommend considering the following questions: What benefits would your phishing training and simulation bring to your organization? What is the goal of the phishing training or simulation? For my organization? To assess the risk of phishing to my organization To evaluate the effectiveness of phishing trainings (e.g. they do not click 1 week, 1 month, or 6 months in the future) For the participants? To introduce and inform participants about phishing To remind participants about phishing When should participants be informed (e.g. ahead of time, What should be the size of my phishing training (e.g. select individuals, all individuals, by team, by department, across the organization)? Where should training material be placed (e.g. in a live workshop ahead of time, in the phishing email, in training afterwards)? When do you inform participants they may be sent What emotional duress or stress might your training materials (emails or presentation) cause your participants? How long should phishing simulations last? A policy for a phishing simulation should include the following: Goal of outcome Target group definition Set duration Plan for disclosure to participants Ahead of time: consent getting, alert (potentially with opt out) Afterwards: debrief, share outcomes, additional training Review of phishing materials that evaluates potential harms (e.g. emotional duress or stress) against actual benefits (for organization or participant) If our goal is to conduct generalizable research, we should additionally consider: Who should be included in the sample? Who should we exclude (e.g. undue burden)? Can this take place in a lab or field setting? What is my outcome variable? Should I get informed consent ahead of time? How should I debrief the participants? Table 1, shown below, is from a 2018 CHI paper provides an overview of previous research design for phishing. Since they were interested in understanding how people who respond to different kinds of training material when shown after they have clicked on the phishing link, they did not get informed consent ahead of time. In this situation the debrief becomes very important as is having an IRB already in place [2]. Also interesting is that phishing studies [2, 3] referred to timeframes for phishing as short (2-days), medium (7-days) and long (30-days). Outcome variables refer to if the user clicked on the phishing link (click), if they shared personal information (info), or click and information (both). Please note that any phishing done for generalizable research purposes would need to submit a protocol for IRB review. You can find more information at https://cphs.berkeley.edu/ .","title":"Considerations for Constructing a Policy"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#limitations-and-future-work","text":"Due to time constraints, there is much more work that can be done, including but not limited to conducting expert interviews, getting existing phishing policies currently in practice, and getting feedback from practitioners and past phishing simulation participants Further questions to consider: Is the risk versus benefit assessment approach of the IRB a good approach to consider? Is there another framework that can be used? How can we assess what is acceptable \"harm\" or \"risk\" in a phishing policy? What are some normative constraints to consider (e.g. culture of organization, size of campaign, frequency of phishing attempts)? Who are all of the stakeholders who should be considered with regard to a phishing policy (e.g. managers, employees, HR, legal team)?","title":"Limitations and Future Work"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#references","text":"2019 Data Breach Investigations Report. Verizon, 2019. https://enterprise.verizon.com/resources/reports/dbir/ Rick Wash and Molly M. Cooper. 2018. Who Provides Phishing Training?: Facts, Stories, and People Like Me. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Paper 492, 12 pages. DOI: https://doi.org/10.1145/3173574.3174066 Kumaraguru, Ponnurangam & Sheng, Steve & Acquisti, Alessandro & Cranor, Lorrie & Hong, Jason. (2008). Lessons From a Real World Evaluation of Anti-Phishing Training. eCrime Researchers Summit, eCrime 2008. 1 - 12. 10.1109/ECRIME.2008.4696970. National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research. The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research. [Bethesda, Md.]: The Commission, 1978. https://www.citiprogram.org/citidocuments/_001pic/1127_the_belmont_report.pdf","title":"References"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#sample-policies","text":"Internal Attribute Goal To conduct a risk assessment of current employee phishing behaviors Type Phishing simulation Target Group All employees of the organization Content Targets will be sent emails that look similar to email already sent to the organization with indicators such as, incorrect sender email addresses, poor formatting. Content will not utilize spear-phishing (using personalized information of target) and will be generalized to the organization Content will utilize social engineering strategies such as urgency while avoiding threatening language. Duration Around 40 days. No longer than 90 days Repeatability Yes Outcome If participants click on link in phishing email; if participants disclose information to sender of phishing email Disclosure Participants were given no prior training, one email was sent to inform them that the organization would be conducting a phishing simulation. At the end of the simulation, participants will be sent an email allowing them to review their own behavior. Data & Privacy For the duration of the simulation information will be collected on each individual regarding if they clicked and/or shared information due to phishing. At the conclusion of the duration each participant will be sent a report regarding their behaviors. The overall results will be summed together in a final report for executive review. Individual performance in the phishing simulation will be retained for future follow-ups. If no future-follow-up is planned, it is advised that the non-summative data be deleted. Risk Emotional duress or stress due to content of phishing email. Stress due to disclosure of individual reports. Data breach of individual identifiers along with phishing performance data. Benefit To understand current phishing risk faced by organization, increase awareness, and improve employee reporting of suspicious emails External Attribute Goal To raise awareness and introduce phishing as a concept to members of a client organization Type Phishing simulation coupled with training Target Group All employees of the client organization Content Training session will take place first, introducing employees to the concept of phishing, provide examples, and recommend that they forward suspicious emails to a given email in IT. Targets will be sent emails that look similar to email already sent to the organization with indicators such as, incorrect sender email addresses, poor formatting. Upon clicking, targets will be informed that they have been phished, directed to an info page about phishing, and given a quiz (optional) to take about phishing. Content will utilize social engineering strategies such as urgency and may include threatening but non-violent language. Duration 30 days Repeatability Yes Outcome If participants click on link in phishing email; if participants forward suspicious email to IT Disclosure Participants are given prior training and are informed that they will be targeted with phishing emails over the course of the next month. They are asked to be on the look out and given the option to opt out. Data & Privacy For the duration of the simulation information will be collected of clicks and forwards. This information will not be collected in a personally identifiable way. At the conclusion, the overall results will be summed together in a final report for executive review and the collected information deleted. Risk Emotional duress or stress due to content of phishing email. Stress from being asked to look out for phishing emails Benefit To inform participants about phishing, raise awareness, and encourage safer behaviors regarding suspicious emails Research Attribute Goal To understand the impact of behavior change if click content of phishing simulation email is (a) a quiz about phishing, (b) information about phishing, (c) no information is provided about phishing and target is sent via link to where they believe they were going Type Phishing simulation Target Group Selected targets in an organization randomly selected and distributed over race and gender Content Targets will be sent emails that look similar to email already sent to the organization with indicators such as, incorrect sender email addresses, poor formatting. Content will not utilize spear-phishing (using personalized information of target) and will be generalized to the organization Content will utilize social engineering strategies such as urgency while avoiding threatening language. Duration At 2, 7, and 42 days Repeatability Yes (3 times) Outcome If participants click on link in phishing email; if participants disclose information to sender of phishing email Disclosure Participants will be given no prior training. Informed consent will not be gotten ahead of time. Deception is necessary because awareness of phishing could influence participant\u2019s natural responses. Participants will be debriefed after the duration of the experiment has elapsed and informed of the deception. Data & Privacy For the duration of the simulation information will be collected on each individual regarding if they clicked and/or shared information due to phishing. Data will be saved in a way to anonymize the participants. The overall results will be summed together in a final report for executive review. All collected data except for the summative analysis will be deleted at completion. Risk Emotional duress or stress due to content of phishing email. Deception in case c, where target is unaware they were phished. Benefit To develop generalizable knowledge about how different after-click content can influence future behavior to better understand what makes more effective phishing simulations","title":"Sample Policies"},{"location":"Clinic_Infrastructure/Phishing_Simulation/#sample-end-of-exercise-notification","text":"Hi NAME(S) , This notification is for your awareness that, as of TIME today, DATE , the phishing attack simulation Citizen Clinic conducted for the NAME OF ORG has concluded. In my opinion, the results will successfully highlight practices to sustain and improve upon both at the individual and organizational level. There are some things that NAME OF ORG did well and areas that NAME OF ORG will need to improve upon to increase their digital security. We will compile a report of our findings to share with leadership in private and with MODIFYasNEEDED as previously discussed. We will discuss areas for improvement and procedures for recovery & response. Do advise participants that we took steps to mitigate risks such as no passwords being collected / stored and requesting account credentials for accounts that already have multi-factor authentication enabled or presumably would be \"virtual identities.\" Any information sent to the two \"attacker\" accounts is also protected by strong authentication (Yubikeys). Security is a team effort so any information disclosed should not seem like personal failures, but a combination of weak links in a chain. When a participant realizes they did disclose information to us, they should also realize that their disclosure was part of a larger system where ultimately the odds (and human nature) are stacked up against them. Participants should not compare themselves with others - neither at the individual or organizational level. Instead, we seek improvement that is relative to the current state - the goal is that participants are themselves better prepared to handle similar threats today or tomorrow compared to where they were yesterday. That being said: 1) Participants should know that they will not be receiving any more simulated phishing emails from us via our attacker personas ( INSERT ATTACKER EMAILS ). It is possible that prior emails may be bumped in their inbox due to your email service's reminder feature. Any forms or \"malicious\" links have been disabled. Any messages sent to those accounts will not be returned. 2) The two attacker persona accounts ( INSERT ATTACKER EMAILS ) have already been reported and confirmed. We will detail the attacks in our brief, but for participants' peace of mind, there is no need to take any immediate recovery steps, although changing one's password, reviewing sign-in activity, and ensuring multi-factor authentication is enabled can provide some relief to personal feelings of discomfort. 3) The NAME OF ORG should resume their security and incident response policies & practices as usual. We're not in a posture to continually evaluate suspicious emails, but we're still, of course, happy to help as we can. XYZ should, in most cases, be your primary resource beyond internal information sharing and precautions. Let me know if you have any questions. Thanks for participating! Note: Additional confirmation of end of exercise to be sent via trusted channel (eg. Signal instead of email)","title":"Sample End of Exercise Notification"},{"location":"Clinic_Infrastructure/VPN/","text":"Last Updated: 27 April 2020 Setting up a Virtual Private Network (VPN) for Your Clinic or Partner Organization. We've included a phased approach for students to practice setting up the Algo VPN, The process can be broken into three main phases. As students go through the steps, they should keep track of things that went well, things that were difficult/went poorly/pain points, and ideas /opportunities for improving the process. They can use the tables below each section. Also, they can flag any \u201cmake sure you do this\u201d thoughts that they have and add them to the short list of instructions in each phase. Installation and Dependencies Follow instructions: https://github.com/trailofbits/algo#deploy-the-algo-server Install VPN Builder on local machine. It\u2019s possible another organization or tech expert needs to help you do this. Name Good things (Roses) Bad things (Thorns) Opportunities (Buds) Access and Deployment to AWS Follow instructions: https://github.com/trailofbits/algo/blob/master/docs/cloud-amazon-ec2.md Setup Amazon Web Service account for hosting the VPN on EC2. Create an \u201cIAM\u201d user such as \u201cAlgo VPN\u201d with appropriate permissions. Run the VPN builder, select AWS EC2 and input the public/secret key for the \u201cAlgo VPN\u201d account: Enter your aws_access_key (http://docs.aws.amazon.com/general/latest/gr/managing-aws-access-keys.html) Note: Make sure to use an IAM user with an acceptable policy attached (see https://github.com/trailofbits/algo/blob/master/docs/deploy-from-ansible.md). [pasted values will not be displayed] [AKIA...]: Enter your aws_secret_key (http://docs.aws.amazon.com/general/latest/gr/managing-aws-access-keys.html) [pasted values will not be displayed] [ABCD...]: Name Good things (Roses) Bad things (Thorns) Opportunities (Buds) VPN User Setup on Laptops and Mobile devices Follow instructions: https://github.com/trailofbits/algo#configure-the-vpn-clients Users download Wireguard to their phones and laptops. Share the setup configurations with users. Users finish setting up the VPN by importing config file or scanning the QR code. If WireGuard doesn\u2019t work, users can use another setup method, but will need more instructions. Name Good things (Roses) Bad things (Thorns) Opportunities (Buds)","title":"Virtual Private Network"},{"location":"Clinic_Infrastructure/VPN/#setting-up-a-virtual-private-network-vpn-for-your-clinic-or-partner-organization","text":"We've included a phased approach for students to practice setting up the Algo VPN, The process can be broken into three main phases. As students go through the steps, they should keep track of things that went well, things that were difficult/went poorly/pain points, and ideas /opportunities for improving the process. They can use the tables below each section. Also, they can flag any \u201cmake sure you do this\u201d thoughts that they have and add them to the short list of instructions in each phase.","title":"Setting up a Virtual Private Network (VPN) for Your Clinic or Partner Organization."},{"location":"Clinic_Infrastructure/VPN/#installation-and-dependencies","text":"Follow instructions: https://github.com/trailofbits/algo#deploy-the-algo-server Install VPN Builder on local machine. It\u2019s possible another organization or tech expert needs to help you do this. Name Good things (Roses) Bad things (Thorns) Opportunities (Buds)","title":"Installation and Dependencies"},{"location":"Clinic_Infrastructure/VPN/#access-and-deployment-to-aws","text":"Follow instructions: https://github.com/trailofbits/algo/blob/master/docs/cloud-amazon-ec2.md Setup Amazon Web Service account for hosting the VPN on EC2. Create an \u201cIAM\u201d user such as \u201cAlgo VPN\u201d with appropriate permissions. Run the VPN builder, select AWS EC2 and input the public/secret key for the \u201cAlgo VPN\u201d account: Enter your aws_access_key (http://docs.aws.amazon.com/general/latest/gr/managing-aws-access-keys.html) Note: Make sure to use an IAM user with an acceptable policy attached (see https://github.com/trailofbits/algo/blob/master/docs/deploy-from-ansible.md). [pasted values will not be displayed] [AKIA...]: Enter your aws_secret_key (http://docs.aws.amazon.com/general/latest/gr/managing-aws-access-keys.html) [pasted values will not be displayed] [ABCD...]: Name Good things (Roses) Bad things (Thorns) Opportunities (Buds)","title":"Access and Deployment to AWS"},{"location":"Clinic_Infrastructure/VPN/#vpn-user-setup-on-laptops-and-mobile-devices","text":"Follow instructions: https://github.com/trailofbits/algo#configure-the-vpn-clients Users download Wireguard to their phones and laptops. Share the setup configurations with users. Users finish setting up the VPN by importing config file or scanning the QR code. If WireGuard doesn\u2019t work, users can use another setup method, but will need more instructions. Name Good things (Roses) Bad things (Thorns) Opportunities (Buds)","title":"VPN User Setup on Laptops and Mobile devices"},{"location":"Clinic_Infrastructure/Virtual_Identities/","text":"Last Updated: 27 April 2020 How to Create Virtual Identities for your Clinic or Partner Organization. Work in progress. Check back soon. VIRTUAL IDENTITY WORKSHEET Identity Name Purpose of Identity For Engagement? Yes No Date of Risk Assessment Phone Number PIN (if burner phone) Email Address Email Password* Recovery Email Recovery Email PW* Personal Info Gender Age (date of birth)** Nationality Birth location Residence Occupation Employer Interests Hobbies Images (music, logos, etc.) 1. 2. 3. Infrastructure & User Behavior Device(s) Used Operating System(s) Browser (s) User\u2019s Time Zone Time when Active*** Browser Plugin(s) VPN Used VPN Location Scripts / Automation? Virtual Profiles (i.e. Platform-specific) Platform Name Date of Creation User Name / ID Password* Usually, you\u2019ll use a Password Manager to generate and store if possible ** Don\u2019t use your own birthdate *** Specific times of day when the identity is active (if applicable) EXAMPLE IDENTITY MAINTENANCE LOG Date Actions Performed Reason","title":"Virtual Identities"},{"location":"Clinic_Infrastructure/Virtual_Identities/#how-to-create-virtual-identities-for-your-clinic-or-partner-organization","text":"Work in progress. Check back soon.","title":"How to Create Virtual Identities for your Clinic or Partner Organization."},{"location":"Clinic_Infrastructure/Virtual_Identities/#virtual-identity-worksheet","text":"Identity Name Purpose of Identity For Engagement? Yes No Date of Risk Assessment Phone Number PIN (if burner phone) Email Address Email Password* Recovery Email Recovery Email PW* Personal Info Gender Age (date of birth)** Nationality Birth location Residence Occupation Employer Interests Hobbies Images (music, logos, etc.) 1. 2. 3. Infrastructure & User Behavior Device(s) Used Operating System(s) Browser (s) User\u2019s Time Zone Time when Active*** Browser Plugin(s) VPN Used VPN Location Scripts / Automation? Virtual Profiles (i.e. Platform-specific) Platform Name Date of Creation User Name / ID Password* Usually, you\u2019ll use a Password Manager to generate and store if possible ** Don\u2019t use your own birthdate *** Specific times of day when the identity is active (if applicable)","title":"VIRTUAL IDENTITY WORKSHEET"},{"location":"Clinic_Infrastructure/Virtual_Identities/#example-identity-maintenance-log","text":"Date Actions Performed Reason","title":"EXAMPLE IDENTITY MAINTENANCE LOG"},{"location":"LRO/0-Introduction_and_TOC_(README)/","text":"Please Note: Cybersecurity is a rapidly evolving field. This document was last updated on February 2, 2019. Some of the technical guidance within this document may change, and some of the risks defined may increase or decrease in their potential likelihood or impact. An introductory webinar to this guide including information about it's contents and how to use it, can be seen here: https://www.techsoup.org/community/events-webinars/cybersecurity-in-low-risk-organizations-understanding-your-risk-2019-02-19 Introduction This guide is intended as an introductory document for low-risk organizations interested in improving their cybersecurity practices, specifically nonprofits and public interest organizations at low risk of targeted cyberattacks. By \"targeted cyberattacks,\" this guide refers to attacks on systems that seek to disrupt or surveil a specific organization or individual (as opposed to attacks meant to compromise as many devices or accounts as possible). This document provides guidance to improve the resilience of low-risk organizations (LROs) to common cyberattacks, and a framework for LROs to develop a basic cybersecurity policy. It is worth noting that all organizations are at some risk of cybersecurity incidents. Though not all organizations are equally likely to be victimized by online attacks, there are basic steps that LROs can take to improve their resiliency and keep themselves at lower risk\u2014even while recognizing the limits to their potential investments of time, people, and money. This is not intended to be a comprehensive guide to cybersecurity, nor an exhaustive set of recommendations. This guide is intended to help individuals in leadership positions and technical staff with little or no cybersecurity background understand some of the fundamentals of their own security context and guide them toward initial steps for improving their cybersecurity. The audience for this guide could include executive staff, system administrators, financial officers, general counsels, non-profit board members, or anyone interested in elevating their organizations' appreciation of cybersecurity issues. This guide has three primary sections: the first introduces basic cybersecurity concepts, including the fundamentals of cybersecurity risk management; the second describes a series of basic cybersecurity \"controls\" \u2013 or measures organizations can take to improve their resilience to cybersecurity threats; the third describes additional cybersecurity best practices and policies LROs should adopt. Appendix A is designed to help organizations draft a basic cybersecurity policy using the controls and best practices described in this guide. Appendix B provides guidance on how to implement selected cybersecurity controls. Appendix C describes a series of additional resources for organizations interested in moving toward a more sophisticated cybersecurity posture.","title":"Introduction"},{"location":"LRO/0-Introduction_and_TOC_(README)/#introduction","text":"This guide is intended as an introductory document for low-risk organizations interested in improving their cybersecurity practices, specifically nonprofits and public interest organizations at low risk of targeted cyberattacks. By \"targeted cyberattacks,\" this guide refers to attacks on systems that seek to disrupt or surveil a specific organization or individual (as opposed to attacks meant to compromise as many devices or accounts as possible). This document provides guidance to improve the resilience of low-risk organizations (LROs) to common cyberattacks, and a framework for LROs to develop a basic cybersecurity policy. It is worth noting that all organizations are at some risk of cybersecurity incidents. Though not all organizations are equally likely to be victimized by online attacks, there are basic steps that LROs can take to improve their resiliency and keep themselves at lower risk\u2014even while recognizing the limits to their potential investments of time, people, and money. This is not intended to be a comprehensive guide to cybersecurity, nor an exhaustive set of recommendations. This guide is intended to help individuals in leadership positions and technical staff with little or no cybersecurity background understand some of the fundamentals of their own security context and guide them toward initial steps for improving their cybersecurity. The audience for this guide could include executive staff, system administrators, financial officers, general counsels, non-profit board members, or anyone interested in elevating their organizations' appreciation of cybersecurity issues. This guide has three primary sections: the first introduces basic cybersecurity concepts, including the fundamentals of cybersecurity risk management; the second describes a series of basic cybersecurity \"controls\" \u2013 or measures organizations can take to improve their resilience to cybersecurity threats; the third describes additional cybersecurity best practices and policies LROs should adopt. Appendix A is designed to help organizations draft a basic cybersecurity policy using the controls and best practices described in this guide. Appendix B provides guidance on how to implement selected cybersecurity controls. Appendix C describes a series of additional resources for organizations interested in moving toward a more sophisticated cybersecurity posture.","title":"Introduction"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/","text":"Please Note: Cybersecurity is a rapidly evolving field. This document was last updated on February 2, 2019. Some of the technical guidance within this document may change, and some of the risks defined may increase or decrease in their potential likelihood or impact. Why do Low-Risk Organizations Need Cybersecurity? A 2018 report from the Public Interest Registry surveyed over 5,300 NGOs and demonstrated that, while nonprofits invest in information technology to conduct mission-critical activities, information security investment continues to be low. 1 Beyond low cybersecurity investment, mission-driven organizations often lack the expertise at the staff level to fend off basic online threats. Connectivity is crucial for organizations with decentralized operations or a wide volunteer base. As a result, organizations establishing such connectivity often ignore many of the basic steps that more technically mature organizations would take to preserve system security (like using formal identity systems or multi-factor authentication) in order to establish an online presence quickly. They may not be of high risk of a cyberattack, but low-risk organizations are often resource-constrained. Therefore, the loss of control of an organizational bank account, of donor lists, or of important internal documents can have an outsized impact on organizations who otherwise might not consider cybersecurity important to their mission. Nonprofits and public interest organizations are unlikely to make significant investments in cybersecurity. On average, small nonprofits (defined as organizations with 15 or fewer employees) have one IT person on staff, and the ratios of IT staff to non-technical staff are even more uneven in larger organizations. 2 Given that cybersecurity jobs only account for 11 percent of all IT jobs, 3 the small IT staff of most nonprofits are unlikely to provide much, if any, cybersecurity support. Nonprofits face intense competition to attract IT talent. Some studies have estimated that the global cybersecurity labor market (including both the public and private sectors) will face a shortage of 1.8 million workers by 2022. 4 Given that 92 percent of nonprofits surveyed in a 2010 study by the John Hopkins Center for Civil Society Studies indicated a lack of funds to be a primary barrier to increasing their organization's IT capacity, it would be unrealistic to expect that these organizations have the capital to compete with the private sector to attract cybersecurity talent. 5 Nonprofits have traditionally used their missions to attract staff at sub-market rates, but still face challenges in recruiting the number of individuals needed to make up this gap. What makes an organization \"low risk\"? While many of the basic recommendations in this guide are applicable to all organizations, this guide is designed with \"low-risk\" organizations in mind. But what does it mean for an organization to be \"low risk\"? The \"Digital Security & Grantcraft Guide\" 6 published in early 2017 by the NetGain Partnership provides information for funders about how to evaluate if a grantee organization is at high risk of a cyberattack. Some of the same considerations can be applied to determining if an organization is low risk. The paper describes three basic layers of consideration: \"Is the grantee high risk; is the context high risk; is the project high risk?\" Each of these questions explores whether or not an element of a funded project or program is more or less at risk of a cyberattack. Consider the following questions: Do you believe your organization is actively at risk of a cyberattack? Are you aware of other organizations like yours that have been actively targeted with a cyberattack? Does your work generate controversy, or is it viewed with hostility by government actors, government-backed organizations, or independent malicious actors? Are any individuals affiliated with your organization (staff, board members, advisors, etc.) engaged in work or behaviors that might draw the attention of adversaries or malicious actors? Do you collect, generate, or otherwise handle sensitive information (such as names, addresses, phone numbers, banking information, gender identity, or other personally identifiable information) about a vulnerable population, or of interest to an oppressive government or malicious non-state actor? If the answer to any of the above questions is \"yes,\" your organization is not low risk, and this guide should not be considered sufficient for establishing a baseline security practice. While some of the recommendations in this guide may be useful for high-risk organizations, groups concerned about targeted attacks should consult a cybersecurity specialist, as well as the following resources: Electronic Frontier Foundation - Surveillance Self Defense: https://ssd.eff.org/ Internews - SAFETAG Framework: https://safetag.org/ Tactical Tech - Security in a Box: https://securityinabox.org/en/ Organizations who identify as high risk should consult cybersecurity specialists. While the contents of this guide offer a baseline for any organization's cybersecurity, they should not be considered a comprehensive set of cybersecurity tools. No organization or system is ever completely \"secure\" \u2013 and those at greater risk must evaluate their context and individual technical circumstances to understand how to best protect themselves from online threats. PLEASE NOTE: Cybersecurity is a rapidly changing field. Many useful and reliable tools can become obsolete \u2013 even to a dangerous degree \u2013 overnight as new attacks emerge. The advice and tools offered in this report are considered reliable by the authors and a panel of cybersecurity experts as of February 2, 2019, but as this report ages, readers should consider this advice subject to deprecation. Introduction to Cybersecurity There are a range of formal and legalistic definitions of cybersecurity and information security. An example: \"The protection of information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability.\" 7 If this seems incredibly broad \u2013 that is because it is. Cybersecurity has become a wide-ranging discipline as the use of information technology has stretched across all corners of our daily lives. Because of its breadth, its rapid evolution, and the sometimes counterintuitive nature of emerging challenges, understanding cybersecurity can feel overwhelming. This can be particularly true for organizations that do not consider cybersecurity to be an integral part of their mission. This section will outline the basic tenets of cybersecurity, and includes some examples to illustrate how cybersecurity disruptions can interfere with mission priorities in organizations that have not historically considered online threats. In practical terms, an organization's cybersecurity is its ability to operate information and online technologies safely, accurately, and without interruption or unintended observation. Most experts will point to the cybersecurity \"objectives\" of Confidentiality, Integrity, and Availability, known colloquially as \"CIA\" or the \"CIA Triad.\" These objectives are not goals, but rather, they describe the characteristics of secure information systems. No system has perfect confidentiality, integrity, or availability. These objectives can be used to articulate how a certain technique, tool, or policy might improve a system's security, or how a system's security might be diminished by an attack. These security-enhancing tools, techniques, or policies are referred to as \"controls\" - cybersecurity measures that can mitigate risk. The cybersecurity objectives may be briefly summarized as follows 8 : Confidentiality: Information is only readable by its intended audience. Integrity: Information is accurate and maintained in its intended state. Availability: Information is accessible to individuals and systems as intended. The following sections will further describe these objectives using real-world examples. A Note on Privacy While this guide is focused on cybersecurity, there are a number of privacy issues that intersect with the security of information systems. Many of the privacy issues highlighted in the news are related to breaches of security, but things can go wrong for privacy even without an active \"attack.\" For example, if an organization shares a list of attendees to a past event with a partner, and that partner wants to expand its own email list to promote a similar event, this sharing might generate backlash from supporters. Individuals may lose trust in the original organization and feel they have been signed up for \"spam\" if they learn their information was shared without their consent. While a number of the recommendations in this guide may improve the privacy of LROs' employees, supporters, and partners, this is not a guide to managing privacy risks. An organization's general or outside counsel can often serve as a good resource for learning more about the basics of managing privacy. The International Association of Privacy Professionals provides many tools, trainings, and even certifications in modern privacy practices for organizations who wish to expand their internal privacy expertise: https://iapp.org/ . Confidentiality Attacks on confidentiality make up the majority of what are often described as \"data breaches.\" When a system loses its confidentiality, someone has gained access to information without permission, or information is inappropriately released. Attacks on confidentiality could make public information that an organization wishes to keep private, such as donor lists, financial documents, human resource files, or sensitive emails. These attacks can also victimize partners, supporters, and clients by putting their personal or financial information in the hands of criminals or other malicious actors. Confidentiality Under Attack at the Utah Food Bank: For a period of nearly two years, a security flaw in the website of the Utah Food Bank (UFB) allowed an attacker to access the personal information of individuals who submitted a donation through that site. The information, belonging to over 10,000 people (or 8% of the Food Bank's donors), included names, addresses, email addresses, credit or debit card numbers, security codes and expiration dates. The UFB underwent an extensive investigation, but was unable to ascertain the identity of the attacker. The UFB offered free credit monitoring to those affected by the breach, and had to undergo an 18-month restructuring of its website to enable more secure payment methods for its donors. Integrity A system loses integrity when a person can change something without permission. For example, a student hacking into their school's system to change their grades would be an attack on the integrity of that grading system. Attacks on integrity often challenge one of the primary virtues of using information systems: that information can be maintained and shared in a way that is consistent and accurate. Online Vandals Disrupt the Website Integrity of Schools and Nonprofits: In November of 2017, a service called SchoolDesk \u2013 which provides web hosting services for thousands of schools across the US \u2013 was attacked by online vandals who altered a common system shared by many of SchoolDesk's customers. As a result, the homepages of about 800 schools were changed to display images and videos celebrating the Islamic State in Syria and the Levant. The sites were taken offline while SchoolDesk's systems were repaired, and while the attack did not disrupt the data or internal systems of school districts, it was deeply embarrassing for the affected schools. In 2015, the same groups of online vandals used a weakness in outdated versions of Wordpress \u2013 a common website design system \u2013 to display similar messages. The attack affected many small organizations who had not updated their Wordpress service, causing many to permanently lose portions of their website that were not backed up. Availability Availability attacks affect the ability to access data or systems. These attacks can create restrictions for user access, can take entire websites offline, or can even hold devices hostage. Ransomware Attacks Availability of the St. Louis Public Library: In early 2017, the St. Louis Public Library suffered a ransomware attack. Ransomware uses strong encryption software to lock individuals out of their devices, holding the devices hostage until a ransom is paid. In this case, the ransomware's authors demanded $35,000 to release systems that had been maliciously encrypted at all 17 branches of the library. The library refused to pay the ransom, but it needed nearly a week to regain access to its systems. Other ransomware victims are not so lucky, and if a ransom is not paid, all the data on a device can be lost. In 2017, multiple large-scale ransomware attacks crawled from system to system, locking millions of devices around the world. The security objectives are useful tools for discussing what kind of security any given system needs. In combination with some basic risk management considerations, the objectives can help LROs ask, \"What kinds of cyberattacks are we most worried about affecting our systems, and what kinds of controls will be effective at preventing those attacks?\" Understanding Cybersecurity Risk Risk management is an important tool that provides a way for organizations to prioritize how to spend limited resources. Given the broad range of potential cybersecurity threats, effective use of organizational resources requires a focus on mitigating threats that are important and relevant to an organization's mission. Risk management relies on two metrics to assess potential issues: the likelihood of an attack, and the impact of that potential attack. These two components are common for evaluating all forms of risk \u2013 including risk to finances, people, and mission. In cybersecurity, advanced risk management involves assessing particular systems for vulnerabilities and the likelihood an attacker might try to exploit those vulnerabilities \u2013 often through a process called \"threat modeling\" or \"threat mapping.\" 9 While LROs are unlikely to have the time and resources to complete a detailed risk assessment exercise, they can still benefit from a less intensive effort to understand the likelihood and potential impact of some basic threat areas. This simpler exercise may be enough to determine what steps an LRO needs to take to improve its cybersecurity, and shift its organizational approach to cybersecurity towards one that is more risk-informed. Common Threat Areas While cybersecurity threats will vary depending on context, LROs should focus their energy on mitigating the most common forms of attacks. Many of these common attacks use techniques that have not changed substantially for many years, but LROs can still be victimized if they have not implemented basic security measures. The goal of LRO risk management is to deny attackers this \"low hanging fruit.\" Attackers targeting LROs are likely to be motivated by profit rather than by politics. 10 Whereas politically-minded attackers tend to carry out sophisticated and targeted attacks, profit-minded attackers are much more concerned with their cost margins, and a sophisticated, time-consuming, or expensive method of attack limits the breadth of their potential pool of targets. 11 This means attacks on LROs are likely to be unsophisticated, automated, and targeted at simple, known systems vulnerabilities. Three types of common attacks described below represent the most common threats LROs will likely face online: Account Compromise: According to Verizon, the most common tactic used to facilitate data breaches in 2018 was the reuse of stolen usernames and passwords. 12 The proliferation of stolen passwords and usernames (also known as \"account credentials\") online \u2013 combined with the reality that people tend to recycle the same passwords across accounts \u2013 means that one of the most common forms of online attacks doesn't require any \"hacking\" at all. By buying or otherwise accessing dumps of already-compromised logins, attackers can attempt to take over multiple accounts owned by the same user. Account credentials are the \"front door\" to many sensitive or important services, and their design is generally unfriendly to humans (they are hard to memorize, hard to share, etc.). This means account credentials are often the easiest way to gain access to the most delicate of information - why do any complicated \"hacking\" if you can just get someone to send you their password in an email, or find a reused password in old breach data? Phishing: Phishing is the use of email or another digital communications platform to trick an individual into disclosing sensitive information that can then be used to carry out a cyberattack. Phishing attacks generally require low technical sophistication to execute, often relying on simple techniques like sending emails with links to fake websites that prompt individuals to \"log in\" with their usernames and passwords, when really they are submitting this sensitive information directly to the attacker. Phishing emails can also trick individuals into opening attachments that include malicious software. While it may seem embarrassing to fall for a phishing email, these attacks often fool even the most sophisticated targets, and in many ways it is the simplicity of this type of attack that makes it so dangerous. Phishing is the entry point for a range of attacks, so the consequences of being phished can vary widely. Some of those consequences can include the loss of control of important accounts (such as banking, email, or social media accounts), the infection of devices with malicious software, or the theft of important data. Data Promiscuity: The sprawl of data \u2013 both online and across internal systems \u2013 is a reality that can have many potential negative outcomes for an organization. Poor data security practices within an organization greatly increase the likelihood of an attacker siphoning off information from its systems. Poor internal access controls may allow employees of an organization to access privileged information \u2013 such as HR files \u2013 inappropriately. Especially for organizations with significant staff turnover, it is often challenging to manage and secure internal access to information. For example: every time an organization shares a password with an employee or grants them access to sensitive systems, then forgets to revoke that employee's access or change passwords once the employee leaves the organization or changes roles, an opportunity arises for an accidental or malicious leakage of information. Malware: Malicious software (or \"malware\") is a broad threat area, but one that encompasses many of the terms that people generally associate with cybersecurity, such as viruses, worms, and trojan horses. Malware generally takes advantage of a flaw in a system's design (a \"vulnerability\") to make the system act in a manner that is not intended. Many people have experienced firsthand a form of malware \"exploiting\" a vulnerability on a system or device they own or rely on. While a malware attack is one of the more clear and present dangers online, the technical vulnerabilities malware exploits often get fixed before the attack can be carried out. Attackers who use malware rely on individuals and organizations not updating their software frequently. They focus on systems with out-of-date web browsers or other common software (like Microsoft Office or Adobe Acrobat) with known vulnerabilities to maximize the reach of their attack. For example, one type of malware is ransomware, which uses encryption software to lock up a device so its basic functions and data are inaccessible unless and until the victim pays a ransom. . Ransomware has seen an explosive increase in growth in recent years. 13 Like most malware, it takes advantage of known security vulnerabilities in common software or operating systems. Like other forms of malware, it often requires some user interaction to operate (e.g. a user must click \"ok\" when prompted to install a piece of unknown software). However, recent variants of ransomware have used powerful methods stolen from intelligence agencies that enable the software to run on victims' computers with minimal user interaction. 14 Nonprofit Tech for Good, 2018 Global NGO Technology Report (Reston, VA: Public Interest Registry, 2018), http://techreport.ngo/ . \u21a9 Lyndal Cairns, \"Nonprofit Technology Staffing and Investments Report,\" Non-Profit Technology Network , May 2017, https://www.nten.org/article/your-guide-to-nonprofit-it-investment/ . \u21a9 Burning Glass, \"Job Market Intelligence: Cybersecurity Jobs, 2015,\" Burning Glass Technologies , July 2015, http://burning-glass.com/research/cybersecurity/ . \u21a9 Frost & Sullivan, 2017 Global Information Security Workforce Study: Benchmarking Workforce Capacity and Response to Cyber Risk (Clearwater, FL: Center for Cyber Safety and Education), 2017, https://iamcybersafe.org/wp-content/uploads/2017/06/Europe-GISWS.pdf . \u21a9 Stephanie L Geller, Alan J Abramson, and Erwin de Leon, The Nonprofit Technology Gap\u2013Myth or Reality (Johns Hopkins Listening Post Project, Communique 20, 2010), http://ejewishphilanthropy.com/wordpress/wp-content/uploads/2010/12/Nonprofit-Technology-Gap-Dec.-2010.pdf . \u21a9 \"Digital Security & Grantcraft Guide,\" Ford Foundation, accessed February 15, 2018, https://www.fordfoundation.org/library/reports-and-studies/digital-security-grantcraft-guide/ . \u21a9 Federal Information Processing Standard 199. \"Standards for Security Categorization of Federal Information and Information Systems.\" (2004): https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.199.pdf . \u21a9 These definitions are simplified for this document. More formal definitions can be found in CNSSI 4009 or NIST Special Publication 800-53. \u21a9 \"Hacked! Crooks Are Grabbing Nonprofit Websites and Demanding Ransom.\" The NonProfit Times (blog). Accessed December 20, 2017. http://www.thenonprofittimes.com/news-articles/hacked-crooks-grabbing-nonprofit-websites-demanding-ransom/ , \"More than 10,000 Utah Food Bank Donors Notified of Breach.\" SC Media US, August 31, 2015. https://www.scmagazine.com/the-data-breach-blog/more-than-10000-utah-food-bank-donors-notified-of-breach/article/532920/ . \u21a9 \"800 US Schools' Websites Hacked with Saddam Hussein Photo, 'I Love Islamic State' Message.\" International Business Times UK, November 7, 2017. http://www.ibtimes.co.uk/pro-isis-hackers-hijack-800-us-schools-sites-saddam-hussein-photo-i-love-islamic-state-message-1646210 . \u21a9 \"When ISIS Hacks Your Website.\" Nick Fogle (blog), January 7, 2015. http://nickfogle.com/hacked-by-isis/ . \u21a9 \"St. Louis Public Library Recovers from Ransomware Attack.\" Threatpost. Accessed December 20, 2017. https://threatpost.com/st-louis-public-library-recovers-from-ransomware-attack/123297/ . \u21a9 For organizations who are interested in learning more about threat modeling, the Electronic Frontier Foundation has an introductory guide on the topic: https://ssd.eff.org/en/module/assessing-your-risks . \u21a9 \"The Verizon 2018 Data Breach Investigations Report\" Verizon Enterprise Solutions, accessed February 1, 2019, https://enterprise.verizon.com/resources/reports/dbir/ . \u21a9","title":"Why do Low-Risk Organizations Need Cybersecurity?"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/#why-do-low-risk-organizations-need-cybersecurity","text":"A 2018 report from the Public Interest Registry surveyed over 5,300 NGOs and demonstrated that, while nonprofits invest in information technology to conduct mission-critical activities, information security investment continues to be low. 1 Beyond low cybersecurity investment, mission-driven organizations often lack the expertise at the staff level to fend off basic online threats. Connectivity is crucial for organizations with decentralized operations or a wide volunteer base. As a result, organizations establishing such connectivity often ignore many of the basic steps that more technically mature organizations would take to preserve system security (like using formal identity systems or multi-factor authentication) in order to establish an online presence quickly. They may not be of high risk of a cyberattack, but low-risk organizations are often resource-constrained. Therefore, the loss of control of an organizational bank account, of donor lists, or of important internal documents can have an outsized impact on organizations who otherwise might not consider cybersecurity important to their mission. Nonprofits and public interest organizations are unlikely to make significant investments in cybersecurity. On average, small nonprofits (defined as organizations with 15 or fewer employees) have one IT person on staff, and the ratios of IT staff to non-technical staff are even more uneven in larger organizations. 2 Given that cybersecurity jobs only account for 11 percent of all IT jobs, 3 the small IT staff of most nonprofits are unlikely to provide much, if any, cybersecurity support. Nonprofits face intense competition to attract IT talent. Some studies have estimated that the global cybersecurity labor market (including both the public and private sectors) will face a shortage of 1.8 million workers by 2022. 4 Given that 92 percent of nonprofits surveyed in a 2010 study by the John Hopkins Center for Civil Society Studies indicated a lack of funds to be a primary barrier to increasing their organization's IT capacity, it would be unrealistic to expect that these organizations have the capital to compete with the private sector to attract cybersecurity talent. 5 Nonprofits have traditionally used their missions to attract staff at sub-market rates, but still face challenges in recruiting the number of individuals needed to make up this gap. What makes an organization \"low risk\"? While many of the basic recommendations in this guide are applicable to all organizations, this guide is designed with \"low-risk\" organizations in mind. But what does it mean for an organization to be \"low risk\"? The \"Digital Security & Grantcraft Guide\" 6 published in early 2017 by the NetGain Partnership provides information for funders about how to evaluate if a grantee organization is at high risk of a cyberattack. Some of the same considerations can be applied to determining if an organization is low risk. The paper describes three basic layers of consideration: \"Is the grantee high risk; is the context high risk; is the project high risk?\" Each of these questions explores whether or not an element of a funded project or program is more or less at risk of a cyberattack. Consider the following questions: Do you believe your organization is actively at risk of a cyberattack? Are you aware of other organizations like yours that have been actively targeted with a cyberattack? Does your work generate controversy, or is it viewed with hostility by government actors, government-backed organizations, or independent malicious actors? Are any individuals affiliated with your organization (staff, board members, advisors, etc.) engaged in work or behaviors that might draw the attention of adversaries or malicious actors? Do you collect, generate, or otherwise handle sensitive information (such as names, addresses, phone numbers, banking information, gender identity, or other personally identifiable information) about a vulnerable population, or of interest to an oppressive government or malicious non-state actor? If the answer to any of the above questions is \"yes,\" your organization is not low risk, and this guide should not be considered sufficient for establishing a baseline security practice. While some of the recommendations in this guide may be useful for high-risk organizations, groups concerned about targeted attacks should consult a cybersecurity specialist, as well as the following resources: Electronic Frontier Foundation - Surveillance Self Defense: https://ssd.eff.org/ Internews - SAFETAG Framework: https://safetag.org/ Tactical Tech - Security in a Box: https://securityinabox.org/en/ Organizations who identify as high risk should consult cybersecurity specialists. While the contents of this guide offer a baseline for any organization's cybersecurity, they should not be considered a comprehensive set of cybersecurity tools. No organization or system is ever completely \"secure\" \u2013 and those at greater risk must evaluate their context and individual technical circumstances to understand how to best protect themselves from online threats. PLEASE NOTE: Cybersecurity is a rapidly changing field. Many useful and reliable tools can become obsolete \u2013 even to a dangerous degree \u2013 overnight as new attacks emerge. The advice and tools offered in this report are considered reliable by the authors and a panel of cybersecurity experts as of February 2, 2019, but as this report ages, readers should consider this advice subject to deprecation.","title":"Why do Low-Risk Organizations Need Cybersecurity?"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/#introduction-to-cybersecurity","text":"There are a range of formal and legalistic definitions of cybersecurity and information security. An example: \"The protection of information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability.\" 7 If this seems incredibly broad \u2013 that is because it is. Cybersecurity has become a wide-ranging discipline as the use of information technology has stretched across all corners of our daily lives. Because of its breadth, its rapid evolution, and the sometimes counterintuitive nature of emerging challenges, understanding cybersecurity can feel overwhelming. This can be particularly true for organizations that do not consider cybersecurity to be an integral part of their mission. This section will outline the basic tenets of cybersecurity, and includes some examples to illustrate how cybersecurity disruptions can interfere with mission priorities in organizations that have not historically considered online threats. In practical terms, an organization's cybersecurity is its ability to operate information and online technologies safely, accurately, and without interruption or unintended observation. Most experts will point to the cybersecurity \"objectives\" of Confidentiality, Integrity, and Availability, known colloquially as \"CIA\" or the \"CIA Triad.\" These objectives are not goals, but rather, they describe the characteristics of secure information systems. No system has perfect confidentiality, integrity, or availability. These objectives can be used to articulate how a certain technique, tool, or policy might improve a system's security, or how a system's security might be diminished by an attack. These security-enhancing tools, techniques, or policies are referred to as \"controls\" - cybersecurity measures that can mitigate risk. The cybersecurity objectives may be briefly summarized as follows 8 : Confidentiality: Information is only readable by its intended audience. Integrity: Information is accurate and maintained in its intended state. Availability: Information is accessible to individuals and systems as intended. The following sections will further describe these objectives using real-world examples.","title":"Introduction to Cybersecurity"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/#a-note-on-privacy","text":"While this guide is focused on cybersecurity, there are a number of privacy issues that intersect with the security of information systems. Many of the privacy issues highlighted in the news are related to breaches of security, but things can go wrong for privacy even without an active \"attack.\" For example, if an organization shares a list of attendees to a past event with a partner, and that partner wants to expand its own email list to promote a similar event, this sharing might generate backlash from supporters. Individuals may lose trust in the original organization and feel they have been signed up for \"spam\" if they learn their information was shared without their consent. While a number of the recommendations in this guide may improve the privacy of LROs' employees, supporters, and partners, this is not a guide to managing privacy risks. An organization's general or outside counsel can often serve as a good resource for learning more about the basics of managing privacy. The International Association of Privacy Professionals provides many tools, trainings, and even certifications in modern privacy practices for organizations who wish to expand their internal privacy expertise: https://iapp.org/ .","title":"A Note on Privacy"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/#confidentiality","text":"Attacks on confidentiality make up the majority of what are often described as \"data breaches.\" When a system loses its confidentiality, someone has gained access to information without permission, or information is inappropriately released. Attacks on confidentiality could make public information that an organization wishes to keep private, such as donor lists, financial documents, human resource files, or sensitive emails. These attacks can also victimize partners, supporters, and clients by putting their personal or financial information in the hands of criminals or other malicious actors. Confidentiality Under Attack at the Utah Food Bank: For a period of nearly two years, a security flaw in the website of the Utah Food Bank (UFB) allowed an attacker to access the personal information of individuals who submitted a donation through that site. The information, belonging to over 10,000 people (or 8% of the Food Bank's donors), included names, addresses, email addresses, credit or debit card numbers, security codes and expiration dates. The UFB underwent an extensive investigation, but was unable to ascertain the identity of the attacker. The UFB offered free credit monitoring to those affected by the breach, and had to undergo an 18-month restructuring of its website to enable more secure payment methods for its donors.","title":"Confidentiality"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/#integrity","text":"A system loses integrity when a person can change something without permission. For example, a student hacking into their school's system to change their grades would be an attack on the integrity of that grading system. Attacks on integrity often challenge one of the primary virtues of using information systems: that information can be maintained and shared in a way that is consistent and accurate. Online Vandals Disrupt the Website Integrity of Schools and Nonprofits: In November of 2017, a service called SchoolDesk \u2013 which provides web hosting services for thousands of schools across the US \u2013 was attacked by online vandals who altered a common system shared by many of SchoolDesk's customers. As a result, the homepages of about 800 schools were changed to display images and videos celebrating the Islamic State in Syria and the Levant. The sites were taken offline while SchoolDesk's systems were repaired, and while the attack did not disrupt the data or internal systems of school districts, it was deeply embarrassing for the affected schools. In 2015, the same groups of online vandals used a weakness in outdated versions of Wordpress \u2013 a common website design system \u2013 to display similar messages. The attack affected many small organizations who had not updated their Wordpress service, causing many to permanently lose portions of their website that were not backed up.","title":"Integrity"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/#availability","text":"Availability attacks affect the ability to access data or systems. These attacks can create restrictions for user access, can take entire websites offline, or can even hold devices hostage. Ransomware Attacks Availability of the St. Louis Public Library: In early 2017, the St. Louis Public Library suffered a ransomware attack. Ransomware uses strong encryption software to lock individuals out of their devices, holding the devices hostage until a ransom is paid. In this case, the ransomware's authors demanded $35,000 to release systems that had been maliciously encrypted at all 17 branches of the library. The library refused to pay the ransom, but it needed nearly a week to regain access to its systems. Other ransomware victims are not so lucky, and if a ransom is not paid, all the data on a device can be lost. In 2017, multiple large-scale ransomware attacks crawled from system to system, locking millions of devices around the world. The security objectives are useful tools for discussing what kind of security any given system needs. In combination with some basic risk management considerations, the objectives can help LROs ask, \"What kinds of cyberattacks are we most worried about affecting our systems, and what kinds of controls will be effective at preventing those attacks?\"","title":"Availability"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/#understanding-cybersecurity-risk","text":"Risk management is an important tool that provides a way for organizations to prioritize how to spend limited resources. Given the broad range of potential cybersecurity threats, effective use of organizational resources requires a focus on mitigating threats that are important and relevant to an organization's mission. Risk management relies on two metrics to assess potential issues: the likelihood of an attack, and the impact of that potential attack. These two components are common for evaluating all forms of risk \u2013 including risk to finances, people, and mission. In cybersecurity, advanced risk management involves assessing particular systems for vulnerabilities and the likelihood an attacker might try to exploit those vulnerabilities \u2013 often through a process called \"threat modeling\" or \"threat mapping.\" 9 While LROs are unlikely to have the time and resources to complete a detailed risk assessment exercise, they can still benefit from a less intensive effort to understand the likelihood and potential impact of some basic threat areas. This simpler exercise may be enough to determine what steps an LRO needs to take to improve its cybersecurity, and shift its organizational approach to cybersecurity towards one that is more risk-informed.","title":"Understanding Cybersecurity Risk"},{"location":"LRO/1-Why_Do_Low-Risk_Organizations_Need_Cybersecurity/#common-threat-areas","text":"While cybersecurity threats will vary depending on context, LROs should focus their energy on mitigating the most common forms of attacks. Many of these common attacks use techniques that have not changed substantially for many years, but LROs can still be victimized if they have not implemented basic security measures. The goal of LRO risk management is to deny attackers this \"low hanging fruit.\" Attackers targeting LROs are likely to be motivated by profit rather than by politics. 10 Whereas politically-minded attackers tend to carry out sophisticated and targeted attacks, profit-minded attackers are much more concerned with their cost margins, and a sophisticated, time-consuming, or expensive method of attack limits the breadth of their potential pool of targets. 11 This means attacks on LROs are likely to be unsophisticated, automated, and targeted at simple, known systems vulnerabilities. Three types of common attacks described below represent the most common threats LROs will likely face online: Account Compromise: According to Verizon, the most common tactic used to facilitate data breaches in 2018 was the reuse of stolen usernames and passwords. 12 The proliferation of stolen passwords and usernames (also known as \"account credentials\") online \u2013 combined with the reality that people tend to recycle the same passwords across accounts \u2013 means that one of the most common forms of online attacks doesn't require any \"hacking\" at all. By buying or otherwise accessing dumps of already-compromised logins, attackers can attempt to take over multiple accounts owned by the same user. Account credentials are the \"front door\" to many sensitive or important services, and their design is generally unfriendly to humans (they are hard to memorize, hard to share, etc.). This means account credentials are often the easiest way to gain access to the most delicate of information - why do any complicated \"hacking\" if you can just get someone to send you their password in an email, or find a reused password in old breach data? Phishing: Phishing is the use of email or another digital communications platform to trick an individual into disclosing sensitive information that can then be used to carry out a cyberattack. Phishing attacks generally require low technical sophistication to execute, often relying on simple techniques like sending emails with links to fake websites that prompt individuals to \"log in\" with their usernames and passwords, when really they are submitting this sensitive information directly to the attacker. Phishing emails can also trick individuals into opening attachments that include malicious software. While it may seem embarrassing to fall for a phishing email, these attacks often fool even the most sophisticated targets, and in many ways it is the simplicity of this type of attack that makes it so dangerous. Phishing is the entry point for a range of attacks, so the consequences of being phished can vary widely. Some of those consequences can include the loss of control of important accounts (such as banking, email, or social media accounts), the infection of devices with malicious software, or the theft of important data. Data Promiscuity: The sprawl of data \u2013 both online and across internal systems \u2013 is a reality that can have many potential negative outcomes for an organization. Poor data security practices within an organization greatly increase the likelihood of an attacker siphoning off information from its systems. Poor internal access controls may allow employees of an organization to access privileged information \u2013 such as HR files \u2013 inappropriately. Especially for organizations with significant staff turnover, it is often challenging to manage and secure internal access to information. For example: every time an organization shares a password with an employee or grants them access to sensitive systems, then forgets to revoke that employee's access or change passwords once the employee leaves the organization or changes roles, an opportunity arises for an accidental or malicious leakage of information. Malware: Malicious software (or \"malware\") is a broad threat area, but one that encompasses many of the terms that people generally associate with cybersecurity, such as viruses, worms, and trojan horses. Malware generally takes advantage of a flaw in a system's design (a \"vulnerability\") to make the system act in a manner that is not intended. Many people have experienced firsthand a form of malware \"exploiting\" a vulnerability on a system or device they own or rely on. While a malware attack is one of the more clear and present dangers online, the technical vulnerabilities malware exploits often get fixed before the attack can be carried out. Attackers who use malware rely on individuals and organizations not updating their software frequently. They focus on systems with out-of-date web browsers or other common software (like Microsoft Office or Adobe Acrobat) with known vulnerabilities to maximize the reach of their attack. For example, one type of malware is ransomware, which uses encryption software to lock up a device so its basic functions and data are inaccessible unless and until the victim pays a ransom. . Ransomware has seen an explosive increase in growth in recent years. 13 Like most malware, it takes advantage of known security vulnerabilities in common software or operating systems. Like other forms of malware, it often requires some user interaction to operate (e.g. a user must click \"ok\" when prompted to install a piece of unknown software). However, recent variants of ransomware have used powerful methods stolen from intelligence agencies that enable the software to run on victims' computers with minimal user interaction. 14 Nonprofit Tech for Good, 2018 Global NGO Technology Report (Reston, VA: Public Interest Registry, 2018), http://techreport.ngo/ . \u21a9 Lyndal Cairns, \"Nonprofit Technology Staffing and Investments Report,\" Non-Profit Technology Network , May 2017, https://www.nten.org/article/your-guide-to-nonprofit-it-investment/ . \u21a9 Burning Glass, \"Job Market Intelligence: Cybersecurity Jobs, 2015,\" Burning Glass Technologies , July 2015, http://burning-glass.com/research/cybersecurity/ . \u21a9 Frost & Sullivan, 2017 Global Information Security Workforce Study: Benchmarking Workforce Capacity and Response to Cyber Risk (Clearwater, FL: Center for Cyber Safety and Education), 2017, https://iamcybersafe.org/wp-content/uploads/2017/06/Europe-GISWS.pdf . \u21a9 Stephanie L Geller, Alan J Abramson, and Erwin de Leon, The Nonprofit Technology Gap\u2013Myth or Reality (Johns Hopkins Listening Post Project, Communique 20, 2010), http://ejewishphilanthropy.com/wordpress/wp-content/uploads/2010/12/Nonprofit-Technology-Gap-Dec.-2010.pdf . \u21a9 \"Digital Security & Grantcraft Guide,\" Ford Foundation, accessed February 15, 2018, https://www.fordfoundation.org/library/reports-and-studies/digital-security-grantcraft-guide/ . \u21a9 Federal Information Processing Standard 199. \"Standards for Security Categorization of Federal Information and Information Systems.\" (2004): https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.199.pdf . \u21a9 These definitions are simplified for this document. More formal definitions can be found in CNSSI 4009 or NIST Special Publication 800-53. \u21a9 \"Hacked! Crooks Are Grabbing Nonprofit Websites and Demanding Ransom.\" The NonProfit Times (blog). Accessed December 20, 2017. http://www.thenonprofittimes.com/news-articles/hacked-crooks-grabbing-nonprofit-websites-demanding-ransom/ , \"More than 10,000 Utah Food Bank Donors Notified of Breach.\" SC Media US, August 31, 2015. https://www.scmagazine.com/the-data-breach-blog/more-than-10000-utah-food-bank-donors-notified-of-breach/article/532920/ . \u21a9 \"800 US Schools' Websites Hacked with Saddam Hussein Photo, 'I Love Islamic State' Message.\" International Business Times UK, November 7, 2017. http://www.ibtimes.co.uk/pro-isis-hackers-hijack-800-us-schools-sites-saddam-hussein-photo-i-love-islamic-state-message-1646210 . \u21a9 \"When ISIS Hacks Your Website.\" Nick Fogle (blog), January 7, 2015. http://nickfogle.com/hacked-by-isis/ . \u21a9 \"St. Louis Public Library Recovers from Ransomware Attack.\" Threatpost. Accessed December 20, 2017. https://threatpost.com/st-louis-public-library-recovers-from-ransomware-attack/123297/ . \u21a9 For organizations who are interested in learning more about threat modeling, the Electronic Frontier Foundation has an introductory guide on the topic: https://ssd.eff.org/en/module/assessing-your-risks . \u21a9 \"The Verizon 2018 Data Breach Investigations Report\" Verizon Enterprise Solutions, accessed February 1, 2019, https://enterprise.verizon.com/resources/reports/dbir/ . \u21a9","title":"Common Threat Areas"},{"location":"LRO/2-Common_Cybersecurity_Controls/","text":"Please Note: Cybersecurity is a rapidly evolving field. This document was last updated on February 2, 2019. Some of the technical guidance within this document may change, and some of the risks defined may increase or decrease in their potential likelihood or impact. Section 2: Common Cybersecurity Controls Improving cybersecurity in any organization often requires moving from ad-hoc responses to intentional planning. Many of the technical steps that an organization can take to improve its cybersecurity posture are relatively simple \u2013 some can even be automated for an entire organization with the click of a button. But making any type of organization-wide change often requires a cultural change as well. Creating an organizational policy outlining cybersecurity expectations for staff can help usher in this cultural change. The active participation of staff is critical in ensuring that changes stick. This section will provide a series of technical controls and best practices a LRO can use to mitigate common cybersecurity issues, such as the three common threat areas described previously. A control is a tool, technique, or policy that makes hackers work harder, or makes a cybersecurity risk less likely to materialize. No control is 100% effective, and no system can ever be 100% secure. The controls described in this document may age over time, and in some cases may become obsolete. This section will briefly describe a control, then provide an overview of the time and complexity required for implementation. Each control includes a \"Baseline\" and \"Baseline +\" policy recommendation, where \"Baseline+\" requires a deeper level of staff engagement. These are not black and white distinctions, but are meant to illustrate how organizations can require different levels of adherence to specific practices. LROs can use Appendix A to design a policy for these controls that is appropriate for their organization. Cybersecurity policies are a place for an organization to document expectations for its staff. These policies can also dictate certain technical requirements (e.g. \"all employees must enable two-factor authentication for email accounts\" or \"employees may not email HR files to personal email accounts\"). Appendix A of this document provides a basic template for such a policy, with suggestions for how to tailor the language to your own organization. Not all security technologies are appropriate for all contexts, but the controls that follow are widely accepted as low-effort and high-impact solutions useful for most types of organizations. Given that LROs are not likely to be targeted by sophisticated or highly-motivated attackers (such as governments), these mostly context-agnostic controls should help to increase the security of an LRO's data and systems. Appendix B provides additional information and links to further guidance on how to implement controls and select the systems and accounts requiring protection. How to Use This Guide Read through the controls (in Section 2) and best practices (in Section 3) and understand what types of risks they mitigate. Section 2 controls are generally more technical, while the best practices in Section 3 are more generally designed to serve as a template for policy language for specific practices your organization may need to follow (i.e. travel policy or incident response). Select the level of controls appropriate for your organization, and use those controls and best practices described in Section 3 to build your security policy. Appendix A can help walk you through considerations for each control, and help you identify if Baseline or Baseline+ measures are correct for your organization. Implement security controls within your organization based upon your new security policy. Appendix B offers additional guidance on how to implement each of the controls. You can jump between the control descriptions in Section 2, the policy assistance in Appendix A, and the implementation guidance in Appendix B by using the links below each headline. Strong Authentication Set policy for this control here. Additional implementation guidance can be found here. Baseline: Require multi-factor authentication for all organization-managed accounts. Turn on login alerts where offered. What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? Low Sophistication Less than 1 hour System administrators and individuals set it up Phishing/Account Takeovers Baseline +: Require multi-factor authentication for all organization-managed accounts. Require the use of password managers. Turn on account monitoring where offered. Moderate Sophistication Less than 1 day System administrators and individuals set it up Phishing/Account Takeovers NOTE: As a general rule, do not recycle the same password across multiple accounts. When choosing a password, pick something unique, and make it long . You should focus more on length than on adding in hard-to-remember characters or complex upper/lower case combinations. The use of a \"passphrase\" - a string of at least 4 unrelated words - instead of a password is encouraged. Multi-factor Authentication Multi-factor authentication (MFA) is a tool that offers additional security online accounts by requiring an extra layer of user verification. When MFA is enabled for an account, a user must not only enter a username and password, but they must also verify additional \"factors\" \u2013 like a code texted to their phone \u2013 that prove they are the true owner of the account. When accounts have MFA enabled, attackers who attempt to log in using stolen usernames and passwords will have a much harder time succeeding. LROs should encourage employees to enable MFA on as many accounts as possible, but should mandate the use of MFA on critical accounts like email, data storage systems storing HR files, and financial accounts. Depending on the platform, administrators of centrally managed accounts (like G Suite) can flip a technical switch that forces all users to enable MFA. This technical solution can help LROs ensure staff use MFA, rather than hoping that staff will follow written policy. LROs can also require MFA when staff log into organization-owned computers, a policy that lowers the risk of a security incident in the event of loss or theft of devices. MFA \"factors\" come in many forms, but the three most common types are SMS-based, application-based, and physical tokens. While there are substantial differences between these three methods, each requires a different level of effort to set up and maintain. In choosing an MFA method, it is important to consider the needs and constraints of your organization. For example, while token-based MFA is the most secure method, your organization may not have the budget to purchase security keys, and so enabling SMS-based MFA will be a more realistic fit, and will still be a more secure option than not enabling any form of MFA. A security control that is not (or cannot be) used consistently is not a good security control. Below you will find a brief description of each of these MFA methods: SMS: After entering their username and password, a user will receive a prompt to verify a code (usually between 6-8 digits) sent via SMS to their mobile device. It is important to note this method is widely considered to be less secure than other methods (attackers have increasingly found ways to intercept text messages containing these verification codes). As such, SMS-based MFA is slowly being phased out. Nevertheless, SMS-based MFA is still better than no MFA at all, so LROs should absolutely enable it if it is the only option available for a service. Authenticator App: Companies like Google, Microsoft, Duo, and others offer free applications that generate a one-time, time sensitive code on your phone to serve as a \"second factor\" for individual user accounts. After a user enters their username and password, they will be prompted to enter a code generated by the app of their choosing. Authenticator apps are easy to set up, and can be quickly configured to work with many common web services. Apps have many advantages over SMS as an MFA method, but one of the most important is that the app will continue to generate codes even when the device is offline or out of cell range. This means apps are a particularly good option for LROs with poor cellular connection or with staff that travels internationally. Token: Physical tokens are the most secure form of MFA. They generally consist of small pieces of hardware that plug directly into a computer (or connect by Bluetooth), and they can be carried around on a keychain. Tokens can be more complicated to set up, but once configured, they eliminate the need to enter additional codes following a username and password combination, since connecting the token to your computer automatically generates a long and complex code. Unlike MFA and authenticator apps, tokens do come with a cost (each token runs between $15-50), but if you can afford it, the investment is worth the security payoff. A list of common websites with MFA and links to instructions on how to enable it can be found here: https://twofactorauth.org/ . Organizations should note that in the event of a lost second factor (like your phone or hardware token), account recovery becomes much more challenging with MFA enabled. Your staff may need to reset their account credentials by going to your IT staff, or through the help staff of a specific service. Password Managers It is really difficult to create strong passwords, and even more difficult to remember them. For this reason, organization should encourage (or require) employees to use password manager software like LastPass, especially in cases where a service does not offer MFA. Password managers help users generate long, random passwords and then stores them for users across devices. Attackers may still get ahold of these passwords through phishing or other means, but password managers make it much harder for attackers to guess or \"brute force\" a password (using a computer algorithm to make many guesses in a short period of time) since the software generates and remembers a strong, unique password on the user's behalf. Password managers can (and should!) be used in tandem with MFA, Moreover, many offer \"enterprise\" versions (for a small fee) that allow organizations to set use policies and even enable users to safely exchange passwords for shared accounts. While MFA provides a greater degree of security for an individual account, password managers significantly diminish the risk that one compromised account will lead to other compromised accounts due to recycled passwords. Account Monitoring Many common services offer suspicious login alerts, usually in the form of a push notification or an email that lets users know when someone has tried to access their account from a new device or location. Individuals can manually turn on these alerts or organizations can set technical policies for organization-managed accounts that require these alerts by default. In the event of an account compromise, these login alerts can substantially minimize the time an attacker has unauthorized access to an account by prompting a user to change their password and lock out the attacker. Learn How to Spot a Phishing Email MFA can help prevent attackers from accessing an account even when they have a user's account credentials. But, in cases where MFA is not enabled or not available, a username and password is all the attacker needs to break in. One of the most common ways attackers get their hands on user credentials is via phishing emails. Learning how to spot a phish is the best defense against losing control of accounts. The Electronic Frontier Foundation has a guide on how to spot a phishing email or scam here: https://ssd.eff.org/en/module/how-avoid-phishing-attacks In general, when you receive an email, do not click on links or open files you do not recognize, even if it came from a trusted source. If you're unsure about the origin of a link or document, it is usually worth a quick call or message (through a channel other than email) to the sender. It only takes a minute, and can save hours of headache in the case that your account does become compromised in some way. Automatic Updates and Software Licenses Set policy for this control here. Additional implementation guidance can be found here. Baseline: Force automatic updates for all operating systems, productivity software, and web browsers, and require other software updates to be installed as quickly as possible. Ensure all software licenses are renewed in a timely fashion. What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? Low Sophistication Less than 1 hour Individuals and system administrators set it up Malware Baseline +: Force automatic updates for all operating systems, productivity software, and web browsers, and require other software updates to be installed as quickly as possible. Auto-renew all critical software licenses. Moderate Sophistication Ongoing System administrators set it up Malware Enabling automatic updates is a simple and powerful cybersecurity control. While some larger organizations with more robust IT infrastructures may need to carefully consider this control (sometimes updates may interfere with the function of custom-built information systems), most LROs should enable automatic updates. There is a small chance an update might create problems for a system \u2013 particularly older computers or devices. However, problems with updates are often patched quickly. Out-of-date software is the primary way attackers can take over devices, steal or delete data, or otherwise interrupt systems, websites, and devices. This is because as vulnerabilities in various pieces of software are found, companies issue updates (or \"patches\") to fix those security flaws. Software that has not been updated retains those security flaws, and becomes increasingly vulnerable as attackers build malicious software that takes advantage of those known vulnerabilities. Most software now defaults to enabling automatic updates. An organization's security policy should require this function on all operating systems, web browsers, email clients, productivity software (like Microsoft Office), instant messengers, or other commonly-used programs. This includes updates for mobile device software. Some LROs may use expired software licenses to save money. Without a valid license, software is often not eligible for updates, exposing the organization to the risks described above. While software licenses can be expensive, many non-profits are eligible for free or reduced-costs software. Organizations like TechSoup ( http://www.techsoup.org/ ) are an easy source of reduced-price software for eligible non-profits. Popular software and services suites like Microsoft Office , Salesforce , and Google's G-Suite are available at greatly reduced prices for eligible non-profit organizations. A Note on Antivirus Software Organizations may choose to purchase antivirus software, but most major operating systems build in much of the protection LROs need to prevent malware infections. At a bare minimum, your organization should enable either Windows Defender or Apple's Gatekeeper \u2013 the default security services on both major operating systems. These services will harden most laptops and desktops against common threats. * How to enable Windows Defender: https://support.microsoft.com/en-us/help/17464/windows-defender-help-protect-computer * How to enable Gatekeeper on OSX: https://support.apple.com/en-us/HT202491 It is critical to allow these services to run their automatic updates. Without the latest information, these services cannot protect your device against new forms of malicious software. The Cloud Set policy for this control here. Additional implementation guidance can be found here. Baseline: Migrate organizational email to a cloud-based provider What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? Moderate Sophistication Variable time \u2013 days or weeks Organizations set it up Malware, Phishing, Web-Based Attacks, Data Theft, etc. Baseline +: Migrate organizational email, data storage, and productivity software to a cloud-based provider Moderate Sophistication Variable time \u2013 weeks Organizations set it up Malware, Phishing, Web-Based Attacks, Data Theft, etc. Building and maintaining technical resources for your organization requires a large investment in time, money, and energy. Even managing a \"simple\" service like an email server can be very complicated, and keeping any of these systems up to date and secure is often a task beyond the capabilities of many LROs. It is widely recognized that moving to cloud-based technologies is a good way to offload many of the more difficult and resource intensive tasks related to managing these services, in turn allowing an organization's employees to focus on their mission priorities. Cloud service providers like Google, Amazon, Microsoft, and Salesforce employ some of the best security teams in the world, and are constantly improving the security of their services. They also provide secure backups of data, which means that in the event of a breach or another data loss event, a previous version of that data is still available. Most IT needs of an LRO, including web hosting, email, productivity tools, and storage, can be migrated to cloud-based services. Nevertheless, these services can be expensive. Thankfully many cloud service providers offer free or discounted services for nonprofits and other public-interest organizations. Some examples of those services include: Productivity Suites and Email: https://products.office.com/en-us/nonprofit/office-365-nonprofit-plans-and-pricing?tab=1 https://www.google.com/nonprofits/ Web Hosting: https://help.dreamhost.com/hc/en-us/articles/215769478-Non-profit-discount Contact/Customer Relationship Management: http://www.salesforce.org/nonprofit/ Web Services: https://aws.amazon.com/government-education/nonprofits/ In the event that moving services to the cloud is impractical, an organization's leadership should focus instead on ensuring any local storage, mail, or other servers are running up-to-date software and are configured appropriately. It is likely that ensuring this will require the services of an external consultant or internal IT staff. HTTPS Set policy for this control here. Additional implementation guidance can be found here. Baseline: Ensure all organization-owned websites use HTTPS What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? High Sophistication Days Set up by the site service provider or web administrator Web-based attacks on visitors, changing information in transit HTTPS is a protocol (or set of rules) that encrypts the information flowing between a browser (like Chrome or Firefox) and a website, giving visitors to that website an added layer of protections. It is often represented by a lock icon or the word \"Secure\" in a browser's URL bar. HTTPS ensures traffic is encrypted (confidential) and authenticated (you can be confident that you are speaking to the real entity and not a malicious actor spoofing it). Starting July 2018, the popular Google Chrome browser started marking all websites without HTTPS as \"Not Secure,\" which it formally announced on its Chrome blog. 1 Other major browsers are also making design interface changes to flag non-HTTPS sites as insecure. 2 While maintaining a secure connection between a website and its visitors may seem obvious, it is something many organizations overlook. The vast majority of sites on the internet still do not offer HTTPS connections. Failing to offer an HTTPS connection to visitors of your website puts them at risk of attackers interfering with their connection. For example, when a visitor to your website enters sensitive information such as a credit card number or account password, without the encryption that HTTPS offers, a malicious actor may gain access to this unencrypted information. Configuring HTTPS for a website can be a complicated task, but thankfully, many website hosting services \u2013 like Wordpress or Squarespace will configure it for you at no additional cost. However, if an organization hosts its own website, the web administrator will need to enable HTTPS. HTTPS is the only control that does not have a Baseline + option because it is considered absolutely necessary for any organization that hosts a website. Organizations should not only provide visitors with a secure connection to their website(s), but should also avoid compromising the trust of their visitors, who will likely see a \"Not Secure\" warning in the URL bar so long as HTTPS is not enabled. Data Security Set policy for this control here. Additional implementation guidance can be found here. Baseline: Enable full-disk encryption on servers, cell phones, tablets, laptops, and desktops with access to critical or sensitive information. What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? Medium Sophistication Hours or days Individuals or Organizations Data theft and loss Baseline +: Enable full-disk encryption on all servers, cell phones, tablets, laptops, and desktops with access to organization resources. Regularly review permissions on cloud-based storage accounts to ensure access controls are appropriately granted and MFA is enabled. Consider adopting and implementing a device management system (learn more in the fleet management section). Medium Sophistication Weeks Individuals or Organizations Data theft and loss Data security is a difficult problem, and a wide variety of cybersecurity controls can help to manage the potential risks of lost or stolen data. The two controls described in this document are the most common, and should protect LROs in the case of accidental device loss or data theft. However, the generation, collection, and processing of data can create many risks for an organization \u2013 particularly when the data collected contains information about individuals and their behavior. Retaining sensitive data of this nature may move an organization out of the category of \"low risk\" into a higher category of risk. Encryption Note: Encrypting your data provides an important layer of security, but it also runs the risk of data lock-out. It is crucial that you store your encryption key(s) in a safe place, and that you create a back-up plan in the case that you lose a key. Locking yourself out can be costly and may temporarily interrupt the operation of your organization. Encryption conceals data on a device from any user without the \"key\" to unlock it. That key can come in the form of a password or an MFA token. Many applications rely on encryption to increase the security of messages they send or data they store. Most cloud-based email and storage services encrypt data they store by default. For LROs, encryption can be useful for protecting sensitive data or for securing devices in the event of theft or loss. Full-disk encryption encrypts all information on a device. When an individual logs into that device, the data is decrypted. But, without the appropriate login, the data will be inaccessible to most attackers. Note that some older devices may run more slowly with full-disk encryption enabled. Full-disk encryption is generally favorable to file-based encryption. Unlike file-based encryption, which requires manual encryption of individual files, full-disk encryption ensures that all files on a device are consistently encrypted, meaning there is no risk an important document or file will be left unsecured. Organizations can enable full-disk encryption on Windows and OSX using BitLocker and FileVault, respectively. File-based encryption allows an organization or individual to encrypt a specific file or folder to add additional security to that item. This form of encryption may be particularly useful for protecting sensitive files like HR documents, financial statements, or strategic plans. However, keep in mind that sharing encrypted files with others can pose challenges because the recipient of the file will need a password or key to decrypt the file.. Nevertheless, when transferring sensitive files between devices, it is highly recommended to transfer them in an encrypted state. Encrypted files can sometimes create challenges for an organization and its partners. To relieve some of these challenges, organizations can migrate to cloud-based storage for sensitive materials, where files are encrypted by default and access to those files can be easily customized. End-to-end encryption (\"E2E\") applies specifically to digital communications, and ensures that only the recipients and senders of messages can see and read those messages. For anyone else (including owners of messaging platforms and potential attackers wishing to intercept messages), the data will appear encrypted. Some of the most common E2E messaging apps are Signal, Whatsapp, and iMessage. Note that email is not encrypted by default. While communications applications encrypted with end-to-end encryption are excellent for securing communications about sensitive topics, they can create problems for some organizational processes (like discovery in legal proceedings) that require third-party access to previous communications. Access Management Merely encrypting data is not always enough to keep it \"secure.\" While encrypted devices are generally safe from the prying eyes of outsiders, there are plenty of internal risks posed by data sharing within organizations or between partners. For example, it would be disastrous if all employees were able to view each other's HR files. Similarly, a strategic planning document shared with a close partner organization could be passed along inappropriately to a third party. Access management can help to address these internal risks. Access management is the process of reviewing who within an organization has access to different resources, and setting clear \"permissions\" (or technical abilities) that restrict or grant access for each employee to the appropriate resources. Access management is particularly important for organizations with cloud-based storage, since cloud services make it very easy to share documents inside and outside of an organization. Many cloud services provide administrators with easy ways to manage access across their organizations' documents. However, fine-grained management of access permissions can take time - it is important to designate ownership of this task to specific individuals in your organization to ensure access controls are regularly refreshed. Notes Dino Dai Zovi, a cybersecurity researcher, has said that \"If the cost to attack is less than the value of your information to the attacker, you will be attacked.\" To learn more about the basic economic logic of online attackers, you can view his presentation here: https://trailofbits.files.wordpress.com/2011/08/attacker-math.pdf \u21a9 \"2018 DBIR.\" \u21a9","title":"Common Cybersecurity Controls"},{"location":"LRO/2-Common_Cybersecurity_Controls/#section-2-common-cybersecurity-controls","text":"Improving cybersecurity in any organization often requires moving from ad-hoc responses to intentional planning. Many of the technical steps that an organization can take to improve its cybersecurity posture are relatively simple \u2013 some can even be automated for an entire organization with the click of a button. But making any type of organization-wide change often requires a cultural change as well. Creating an organizational policy outlining cybersecurity expectations for staff can help usher in this cultural change. The active participation of staff is critical in ensuring that changes stick. This section will provide a series of technical controls and best practices a LRO can use to mitigate common cybersecurity issues, such as the three common threat areas described previously. A control is a tool, technique, or policy that makes hackers work harder, or makes a cybersecurity risk less likely to materialize. No control is 100% effective, and no system can ever be 100% secure. The controls described in this document may age over time, and in some cases may become obsolete. This section will briefly describe a control, then provide an overview of the time and complexity required for implementation. Each control includes a \"Baseline\" and \"Baseline +\" policy recommendation, where \"Baseline+\" requires a deeper level of staff engagement. These are not black and white distinctions, but are meant to illustrate how organizations can require different levels of adherence to specific practices. LROs can use Appendix A to design a policy for these controls that is appropriate for their organization. Cybersecurity policies are a place for an organization to document expectations for its staff. These policies can also dictate certain technical requirements (e.g. \"all employees must enable two-factor authentication for email accounts\" or \"employees may not email HR files to personal email accounts\"). Appendix A of this document provides a basic template for such a policy, with suggestions for how to tailor the language to your own organization. Not all security technologies are appropriate for all contexts, but the controls that follow are widely accepted as low-effort and high-impact solutions useful for most types of organizations. Given that LROs are not likely to be targeted by sophisticated or highly-motivated attackers (such as governments), these mostly context-agnostic controls should help to increase the security of an LRO's data and systems. Appendix B provides additional information and links to further guidance on how to implement controls and select the systems and accounts requiring protection.","title":"Section 2: Common Cybersecurity Controls"},{"location":"LRO/2-Common_Cybersecurity_Controls/#how-to-use-this-guide","text":"Read through the controls (in Section 2) and best practices (in Section 3) and understand what types of risks they mitigate. Section 2 controls are generally more technical, while the best practices in Section 3 are more generally designed to serve as a template for policy language for specific practices your organization may need to follow (i.e. travel policy or incident response). Select the level of controls appropriate for your organization, and use those controls and best practices described in Section 3 to build your security policy. Appendix A can help walk you through considerations for each control, and help you identify if Baseline or Baseline+ measures are correct for your organization. Implement security controls within your organization based upon your new security policy. Appendix B offers additional guidance on how to implement each of the controls. You can jump between the control descriptions in Section 2, the policy assistance in Appendix A, and the implementation guidance in Appendix B by using the links below each headline.","title":"How to Use This Guide"},{"location":"LRO/2-Common_Cybersecurity_Controls/#strong-authentication","text":"Set policy for this control here. Additional implementation guidance can be found here. Baseline: Require multi-factor authentication for all organization-managed accounts. Turn on login alerts where offered. What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? Low Sophistication Less than 1 hour System administrators and individuals set it up Phishing/Account Takeovers Baseline +: Require multi-factor authentication for all organization-managed accounts. Require the use of password managers. Turn on account monitoring where offered. Moderate Sophistication Less than 1 day System administrators and individuals set it up Phishing/Account Takeovers NOTE: As a general rule, do not recycle the same password across multiple accounts. When choosing a password, pick something unique, and make it long . You should focus more on length than on adding in hard-to-remember characters or complex upper/lower case combinations. The use of a \"passphrase\" - a string of at least 4 unrelated words - instead of a password is encouraged.","title":"Strong Authentication"},{"location":"LRO/2-Common_Cybersecurity_Controls/#multi-factor-authentication","text":"Multi-factor authentication (MFA) is a tool that offers additional security online accounts by requiring an extra layer of user verification. When MFA is enabled for an account, a user must not only enter a username and password, but they must also verify additional \"factors\" \u2013 like a code texted to their phone \u2013 that prove they are the true owner of the account. When accounts have MFA enabled, attackers who attempt to log in using stolen usernames and passwords will have a much harder time succeeding. LROs should encourage employees to enable MFA on as many accounts as possible, but should mandate the use of MFA on critical accounts like email, data storage systems storing HR files, and financial accounts. Depending on the platform, administrators of centrally managed accounts (like G Suite) can flip a technical switch that forces all users to enable MFA. This technical solution can help LROs ensure staff use MFA, rather than hoping that staff will follow written policy. LROs can also require MFA when staff log into organization-owned computers, a policy that lowers the risk of a security incident in the event of loss or theft of devices. MFA \"factors\" come in many forms, but the three most common types are SMS-based, application-based, and physical tokens. While there are substantial differences between these three methods, each requires a different level of effort to set up and maintain. In choosing an MFA method, it is important to consider the needs and constraints of your organization. For example, while token-based MFA is the most secure method, your organization may not have the budget to purchase security keys, and so enabling SMS-based MFA will be a more realistic fit, and will still be a more secure option than not enabling any form of MFA. A security control that is not (or cannot be) used consistently is not a good security control. Below you will find a brief description of each of these MFA methods: SMS: After entering their username and password, a user will receive a prompt to verify a code (usually between 6-8 digits) sent via SMS to their mobile device. It is important to note this method is widely considered to be less secure than other methods (attackers have increasingly found ways to intercept text messages containing these verification codes). As such, SMS-based MFA is slowly being phased out. Nevertheless, SMS-based MFA is still better than no MFA at all, so LROs should absolutely enable it if it is the only option available for a service. Authenticator App: Companies like Google, Microsoft, Duo, and others offer free applications that generate a one-time, time sensitive code on your phone to serve as a \"second factor\" for individual user accounts. After a user enters their username and password, they will be prompted to enter a code generated by the app of their choosing. Authenticator apps are easy to set up, and can be quickly configured to work with many common web services. Apps have many advantages over SMS as an MFA method, but one of the most important is that the app will continue to generate codes even when the device is offline or out of cell range. This means apps are a particularly good option for LROs with poor cellular connection or with staff that travels internationally. Token: Physical tokens are the most secure form of MFA. They generally consist of small pieces of hardware that plug directly into a computer (or connect by Bluetooth), and they can be carried around on a keychain. Tokens can be more complicated to set up, but once configured, they eliminate the need to enter additional codes following a username and password combination, since connecting the token to your computer automatically generates a long and complex code. Unlike MFA and authenticator apps, tokens do come with a cost (each token runs between $15-50), but if you can afford it, the investment is worth the security payoff. A list of common websites with MFA and links to instructions on how to enable it can be found here: https://twofactorauth.org/ . Organizations should note that in the event of a lost second factor (like your phone or hardware token), account recovery becomes much more challenging with MFA enabled. Your staff may need to reset their account credentials by going to your IT staff, or through the help staff of a specific service.","title":"Multi-factor Authentication"},{"location":"LRO/2-Common_Cybersecurity_Controls/#password-managers","text":"It is really difficult to create strong passwords, and even more difficult to remember them. For this reason, organization should encourage (or require) employees to use password manager software like LastPass, especially in cases where a service does not offer MFA. Password managers help users generate long, random passwords and then stores them for users across devices. Attackers may still get ahold of these passwords through phishing or other means, but password managers make it much harder for attackers to guess or \"brute force\" a password (using a computer algorithm to make many guesses in a short period of time) since the software generates and remembers a strong, unique password on the user's behalf. Password managers can (and should!) be used in tandem with MFA, Moreover, many offer \"enterprise\" versions (for a small fee) that allow organizations to set use policies and even enable users to safely exchange passwords for shared accounts. While MFA provides a greater degree of security for an individual account, password managers significantly diminish the risk that one compromised account will lead to other compromised accounts due to recycled passwords.","title":"Password Managers"},{"location":"LRO/2-Common_Cybersecurity_Controls/#account-monitoring","text":"Many common services offer suspicious login alerts, usually in the form of a push notification or an email that lets users know when someone has tried to access their account from a new device or location. Individuals can manually turn on these alerts or organizations can set technical policies for organization-managed accounts that require these alerts by default. In the event of an account compromise, these login alerts can substantially minimize the time an attacker has unauthorized access to an account by prompting a user to change their password and lock out the attacker. Learn How to Spot a Phishing Email MFA can help prevent attackers from accessing an account even when they have a user's account credentials. But, in cases where MFA is not enabled or not available, a username and password is all the attacker needs to break in. One of the most common ways attackers get their hands on user credentials is via phishing emails. Learning how to spot a phish is the best defense against losing control of accounts. The Electronic Frontier Foundation has a guide on how to spot a phishing email or scam here: https://ssd.eff.org/en/module/how-avoid-phishing-attacks In general, when you receive an email, do not click on links or open files you do not recognize, even if it came from a trusted source. If you're unsure about the origin of a link or document, it is usually worth a quick call or message (through a channel other than email) to the sender. It only takes a minute, and can save hours of headache in the case that your account does become compromised in some way.","title":"Account Monitoring"},{"location":"LRO/2-Common_Cybersecurity_Controls/#automatic-updates-and-software-licenses","text":"Set policy for this control here. Additional implementation guidance can be found here. Baseline: Force automatic updates for all operating systems, productivity software, and web browsers, and require other software updates to be installed as quickly as possible. Ensure all software licenses are renewed in a timely fashion. What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? Low Sophistication Less than 1 hour Individuals and system administrators set it up Malware Baseline +: Force automatic updates for all operating systems, productivity software, and web browsers, and require other software updates to be installed as quickly as possible. Auto-renew all critical software licenses. Moderate Sophistication Ongoing System administrators set it up Malware Enabling automatic updates is a simple and powerful cybersecurity control. While some larger organizations with more robust IT infrastructures may need to carefully consider this control (sometimes updates may interfere with the function of custom-built information systems), most LROs should enable automatic updates. There is a small chance an update might create problems for a system \u2013 particularly older computers or devices. However, problems with updates are often patched quickly. Out-of-date software is the primary way attackers can take over devices, steal or delete data, or otherwise interrupt systems, websites, and devices. This is because as vulnerabilities in various pieces of software are found, companies issue updates (or \"patches\") to fix those security flaws. Software that has not been updated retains those security flaws, and becomes increasingly vulnerable as attackers build malicious software that takes advantage of those known vulnerabilities. Most software now defaults to enabling automatic updates. An organization's security policy should require this function on all operating systems, web browsers, email clients, productivity software (like Microsoft Office), instant messengers, or other commonly-used programs. This includes updates for mobile device software. Some LROs may use expired software licenses to save money. Without a valid license, software is often not eligible for updates, exposing the organization to the risks described above. While software licenses can be expensive, many non-profits are eligible for free or reduced-costs software. Organizations like TechSoup ( http://www.techsoup.org/ ) are an easy source of reduced-price software for eligible non-profits. Popular software and services suites like Microsoft Office , Salesforce , and Google's G-Suite are available at greatly reduced prices for eligible non-profit organizations. A Note on Antivirus Software Organizations may choose to purchase antivirus software, but most major operating systems build in much of the protection LROs need to prevent malware infections. At a bare minimum, your organization should enable either Windows Defender or Apple's Gatekeeper \u2013 the default security services on both major operating systems. These services will harden most laptops and desktops against common threats. * How to enable Windows Defender: https://support.microsoft.com/en-us/help/17464/windows-defender-help-protect-computer * How to enable Gatekeeper on OSX: https://support.apple.com/en-us/HT202491 It is critical to allow these services to run their automatic updates. Without the latest information, these services cannot protect your device against new forms of malicious software.","title":"Automatic Updates and Software Licenses"},{"location":"LRO/2-Common_Cybersecurity_Controls/#the-cloud","text":"Set policy for this control here. Additional implementation guidance can be found here. Baseline: Migrate organizational email to a cloud-based provider What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? Moderate Sophistication Variable time \u2013 days or weeks Organizations set it up Malware, Phishing, Web-Based Attacks, Data Theft, etc. Baseline +: Migrate organizational email, data storage, and productivity software to a cloud-based provider Moderate Sophistication Variable time \u2013 weeks Organizations set it up Malware, Phishing, Web-Based Attacks, Data Theft, etc. Building and maintaining technical resources for your organization requires a large investment in time, money, and energy. Even managing a \"simple\" service like an email server can be very complicated, and keeping any of these systems up to date and secure is often a task beyond the capabilities of many LROs. It is widely recognized that moving to cloud-based technologies is a good way to offload many of the more difficult and resource intensive tasks related to managing these services, in turn allowing an organization's employees to focus on their mission priorities. Cloud service providers like Google, Amazon, Microsoft, and Salesforce employ some of the best security teams in the world, and are constantly improving the security of their services. They also provide secure backups of data, which means that in the event of a breach or another data loss event, a previous version of that data is still available. Most IT needs of an LRO, including web hosting, email, productivity tools, and storage, can be migrated to cloud-based services. Nevertheless, these services can be expensive. Thankfully many cloud service providers offer free or discounted services for nonprofits and other public-interest organizations. Some examples of those services include: Productivity Suites and Email: https://products.office.com/en-us/nonprofit/office-365-nonprofit-plans-and-pricing?tab=1 https://www.google.com/nonprofits/ Web Hosting: https://help.dreamhost.com/hc/en-us/articles/215769478-Non-profit-discount Contact/Customer Relationship Management: http://www.salesforce.org/nonprofit/ Web Services: https://aws.amazon.com/government-education/nonprofits/ In the event that moving services to the cloud is impractical, an organization's leadership should focus instead on ensuring any local storage, mail, or other servers are running up-to-date software and are configured appropriately. It is likely that ensuring this will require the services of an external consultant or internal IT staff.","title":"The Cloud"},{"location":"LRO/2-Common_Cybersecurity_Controls/#https","text":"Set policy for this control here. Additional implementation guidance can be found here. Baseline: Ensure all organization-owned websites use HTTPS What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? High Sophistication Days Set up by the site service provider or web administrator Web-based attacks on visitors, changing information in transit HTTPS is a protocol (or set of rules) that encrypts the information flowing between a browser (like Chrome or Firefox) and a website, giving visitors to that website an added layer of protections. It is often represented by a lock icon or the word \"Secure\" in a browser's URL bar. HTTPS ensures traffic is encrypted (confidential) and authenticated (you can be confident that you are speaking to the real entity and not a malicious actor spoofing it). Starting July 2018, the popular Google Chrome browser started marking all websites without HTTPS as \"Not Secure,\" which it formally announced on its Chrome blog. 1 Other major browsers are also making design interface changes to flag non-HTTPS sites as insecure. 2 While maintaining a secure connection between a website and its visitors may seem obvious, it is something many organizations overlook. The vast majority of sites on the internet still do not offer HTTPS connections. Failing to offer an HTTPS connection to visitors of your website puts them at risk of attackers interfering with their connection. For example, when a visitor to your website enters sensitive information such as a credit card number or account password, without the encryption that HTTPS offers, a malicious actor may gain access to this unencrypted information. Configuring HTTPS for a website can be a complicated task, but thankfully, many website hosting services \u2013 like Wordpress or Squarespace will configure it for you at no additional cost. However, if an organization hosts its own website, the web administrator will need to enable HTTPS. HTTPS is the only control that does not have a Baseline + option because it is considered absolutely necessary for any organization that hosts a website. Organizations should not only provide visitors with a secure connection to their website(s), but should also avoid compromising the trust of their visitors, who will likely see a \"Not Secure\" warning in the URL bar so long as HTTPS is not enabled.","title":"HTTPS"},{"location":"LRO/2-Common_Cybersecurity_Controls/#data-security","text":"Set policy for this control here. Additional implementation guidance can be found here. Baseline: Enable full-disk encryption on servers, cell phones, tablets, laptops, and desktops with access to critical or sensitive information. What time and technical sophistication is required to set up this control? Who enables this control? What risks does this control mitigate? Medium Sophistication Hours or days Individuals or Organizations Data theft and loss Baseline +: Enable full-disk encryption on all servers, cell phones, tablets, laptops, and desktops with access to organization resources. Regularly review permissions on cloud-based storage accounts to ensure access controls are appropriately granted and MFA is enabled. Consider adopting and implementing a device management system (learn more in the fleet management section). Medium Sophistication Weeks Individuals or Organizations Data theft and loss Data security is a difficult problem, and a wide variety of cybersecurity controls can help to manage the potential risks of lost or stolen data. The two controls described in this document are the most common, and should protect LROs in the case of accidental device loss or data theft. However, the generation, collection, and processing of data can create many risks for an organization \u2013 particularly when the data collected contains information about individuals and their behavior. Retaining sensitive data of this nature may move an organization out of the category of \"low risk\" into a higher category of risk.","title":"Data Security"},{"location":"LRO/2-Common_Cybersecurity_Controls/#encryption","text":"Note: Encrypting your data provides an important layer of security, but it also runs the risk of data lock-out. It is crucial that you store your encryption key(s) in a safe place, and that you create a back-up plan in the case that you lose a key. Locking yourself out can be costly and may temporarily interrupt the operation of your organization. Encryption conceals data on a device from any user without the \"key\" to unlock it. That key can come in the form of a password or an MFA token. Many applications rely on encryption to increase the security of messages they send or data they store. Most cloud-based email and storage services encrypt data they store by default. For LROs, encryption can be useful for protecting sensitive data or for securing devices in the event of theft or loss. Full-disk encryption encrypts all information on a device. When an individual logs into that device, the data is decrypted. But, without the appropriate login, the data will be inaccessible to most attackers. Note that some older devices may run more slowly with full-disk encryption enabled. Full-disk encryption is generally favorable to file-based encryption. Unlike file-based encryption, which requires manual encryption of individual files, full-disk encryption ensures that all files on a device are consistently encrypted, meaning there is no risk an important document or file will be left unsecured. Organizations can enable full-disk encryption on Windows and OSX using BitLocker and FileVault, respectively. File-based encryption allows an organization or individual to encrypt a specific file or folder to add additional security to that item. This form of encryption may be particularly useful for protecting sensitive files like HR documents, financial statements, or strategic plans. However, keep in mind that sharing encrypted files with others can pose challenges because the recipient of the file will need a password or key to decrypt the file.. Nevertheless, when transferring sensitive files between devices, it is highly recommended to transfer them in an encrypted state. Encrypted files can sometimes create challenges for an organization and its partners. To relieve some of these challenges, organizations can migrate to cloud-based storage for sensitive materials, where files are encrypted by default and access to those files can be easily customized. End-to-end encryption (\"E2E\") applies specifically to digital communications, and ensures that only the recipients and senders of messages can see and read those messages. For anyone else (including owners of messaging platforms and potential attackers wishing to intercept messages), the data will appear encrypted. Some of the most common E2E messaging apps are Signal, Whatsapp, and iMessage. Note that email is not encrypted by default. While communications applications encrypted with end-to-end encryption are excellent for securing communications about sensitive topics, they can create problems for some organizational processes (like discovery in legal proceedings) that require third-party access to previous communications.","title":"Encryption"},{"location":"LRO/2-Common_Cybersecurity_Controls/#access-management","text":"Merely encrypting data is not always enough to keep it \"secure.\" While encrypted devices are generally safe from the prying eyes of outsiders, there are plenty of internal risks posed by data sharing within organizations or between partners. For example, it would be disastrous if all employees were able to view each other's HR files. Similarly, a strategic planning document shared with a close partner organization could be passed along inappropriately to a third party. Access management can help to address these internal risks. Access management is the process of reviewing who within an organization has access to different resources, and setting clear \"permissions\" (or technical abilities) that restrict or grant access for each employee to the appropriate resources. Access management is particularly important for organizations with cloud-based storage, since cloud services make it very easy to share documents inside and outside of an organization. Many cloud services provide administrators with easy ways to manage access across their organizations' documents. However, fine-grained management of access permissions can take time - it is important to designate ownership of this task to specific individuals in your organization to ensure access controls are regularly refreshed.","title":"Access Management"},{"location":"LRO/2-Common_Cybersecurity_Controls/#notes","text":"Dino Dai Zovi, a cybersecurity researcher, has said that \"If the cost to attack is less than the value of your information to the attacker, you will be attacked.\" To learn more about the basic economic logic of online attackers, you can view his presentation here: https://trailofbits.files.wordpress.com/2011/08/attacker-math.pdf \u21a9 \"2018 DBIR.\" \u21a9","title":"Notes"},{"location":"LRO/3-Additional_Cybersecurity_Best_Practices/","text":"Please Note: Cybersecurity is a rapidly evolving field. This document was last updated on February 2, 2019. Some of the technical guidance within this document may change, and some of the risks defined may increase or decrease in their potential likelihood or impact. Section 3: Additional Cybersecurity Best Practices Beyond the technical controls listed above, additional organizational expectations for cybersecurity can be documented as policies. This section reviews key areas of policy that your organization should establish in order to facilitate secure day-to-day practices. These best practices do not have Baseline or Baseline+ categories, because they are more generally about setting ground rules for behavior instead of particular technical configurations. The best practices in this section are designed as templates your organization can further customize based on your needs. \"Fleet\" Management In a large organization, merely keeping track of the broad array of devices your employees use can be a huge challenge. Even in small organizations, keeping track of phones, laptops, and tablets can be a time-consuming exercise, particularly when employee turnover is high and your organization must regularly purchase new devices and retire old ones. At a minimum, an organization should keep track of the following information: What devices does the organization own? Who is in possession/responsible for that device? Are automatic updates turned on for that device? Are the licenses for the device's operating system and software up to date? This information should be collected and refreshed at regular intervals \u2013 at a minimum once a year, but semi-annually is best. As staff depart or join, or devices are upgraded/deprecated, the running list of devices should be updated accordingly. Each organization should also have a policy for device turnover before a device is handed off to a new employee. At a minimum, this should include the following: Before an employee departs or takes possession of a new device, they must return the old device to the organization. Employees should back up important data on their devices to a shared or otherwise accessible drive or cloud storage, and should inform relevant staff of the data's location. The organization should completely wipe the device and have a fresh system install of its operating system and important software before giving it to an employee. If the device owner is leaving the organization, permissions (such as passwords to sensitive accounts, access to shared documents) should be revoked for the user of the device. A Note on Device Management Systems There are some device management systems on the market that help organizations centrally manage their devices. These systems require time and some practice to use, but they can increase an organization's visibility into what devices are part of their network, and help alert managers to potential security issues. While these systems can be very helpful, they are usually unnecessary for organizations with fewer than 25 employees. Organizations should have dedicated IT staff in charge of operating these systems. Some common ways that device management systems help organizations manage their security include: enforcing organizational security settings such as mandatory strong passwords and forced screen lockout after a certain amount of time; pushing out email profile configuration to the devices; executing remote wipe and remote lock for managed devices; and generating reports of device inventories on the network. Different device management solutions have different strengths and weaknesses. There are two key types of solutions: Server management systems: These systems can comprehensively manage intranet servers. Some can also manage network appliances (servers, standalone firewalls, etc.). However, operating such systems usually requires strong IT proficiency and infrastructure to execute. Example server management systems include: Microsoft System Center Operations Manager Splunk Mobile device management systems (including client computer management): These systems can manage most modern mobile devices and client computers. The user interface is friendly and easier to use compared to server managements system. However, they require more time and attention than server management systems. Examples include: VMWare AirWatch Microsoft Intune MobileIron Travel Policy Travelling \u2013 whether domestically or abroad \u2013 can create unique risks for an organization's cybersecurity. Different regions have different cybersecurity laws and expectations, and different contexts can create new risks an organization might not ordinarily encounter. There are few hard and fast rules with regards to travel policies, but there are a few basic questions that all organizations should ask themselves. A strong travel policy for your organization will address the following: Should employees bring organization-owned devices on work or personal travel? The most likely cybersecurity risk while travelling is an increased chance of device loss or theft. Therefore, at a basic level, employees should only travel with devices that utilize strong full-disk or device-level encryption so that in the event of loss, an attacker will have a difficult time accessing the information. Some organizations provide staff with special \"travel\" devices that have limited capabilities. While this can limit an organization's exposure to risk, configuring devices for travel and wiping them after travel can be time consuming. An organization should always consider what work the employee will need to do while travelling: will they need access to sensitive data, and is that data stored on their device? How regularly will they need to email and communicate with their team? In general, organizations should not travel with devices that hold sensitive information, as loss or theft of these devices could have an outsized impact on an organization. If an employee has limited needs while traveling, like basic access to email, organizations can minimize risk by limiting the number of devices an employees can takes with them (for example, allowing them to take only a phone, as opposed to a phone and a laptop). Below is a summary of policies to help employees keep their devices safe while travelling: Only travel with devices that use full-disk encryption. Never travel with devices that store sensitive information (such as HR files, financial statements, strategic documents, or information about people or their behavior). Keep devices with you at all times (do not leave them unattended or unsecured in hotel rooms). Keep devices locked or off when not using them. How should employees connect to the internet while travelling? Another common risk while travelling is an insecure connection to the internet. This may include connecting to untrustworthy Wi-Fi or accessing work resources through a public computer in a library or caf\u00e9. Unsafe connections can allow hackers to spy on your connection, steal sensitive data, or hijack important accounts. Policies to help employees avoid unsafe connections may include: Ensure all devices have up-to-date software before travel. Do not connect to the internet in places that are unknown or untrustworthy. Only use connections provided by partner organizations or large chain hotels and cafes (even these connections can be insecure, but they are less likely to be compromised). Avoid open/unsecured Wi-Fi networks (e.g. networks not protected by passwords). Never accesswork resources on a computer not owned by your organization, such as a public computer in an internet cafe. When not using devices, turn off Wi-Fi and Bluetooth radios. The US Department of Homeland Security has published a guide that offers some specific guidelines for protecting your devices and online accounts while travelling: https://www.dhs.gov/sites/default/files/publications/Cybersecurity%20While%20Traveling_7.pdf Incident Response Given that no system or device is ever 100% secure, it is inevitable that something bad will happen at some point. People frequently lose devices and experience compromise of online accounts or theft of bank account information. Having a plan for how your organization will deal with an incident can make a significant difference in limiting its impact. This section reviews key steps LROs should take in response to common cybersecurity incidents. If a device is lost or stolen: *Note: if the stolen device was used as an MFA method to access your accounts, you may need to contact your account providers to recover your accounts. If an employee loses a device, they should report that loss to their supervisor immediately. If the device potentially stores or has access to personally identifiable information, the supervisor should alert the general counsel immediately. It may be possible to locate a lost device. Many common devices have services that can show owners the last known location of their device, and even help them remotely wipe or deactivate the device. Apple Find my Mac: https://support.apple.com/en-us/HT204756 Find my Phone: https://support.apple.com/en-us/HT201472 Android: https://myaccount.google.com/find-your-phone Microsoft: https://support.microsoft.com/en-us/help/11579/microsoft-account-find-and-lock-lost-windows-device The supervisor and employee should then catalog a list of information that was stored on that device, even if it is encrypted. Any of that information might be sensitive, and some may have regulatory consequences if lost. That list should include data like: Documents and spreadsheets relevant to their projects Usernames and passwords to important accounts saved in their browser Any information or documents stored in their email or messaging applications Strategic planning document Financial documents HR or personnel documents Assume all of the information on the device is compromised. If the information is sensitive or potentially contains personally identifiable information, send the list of information to the organization's general counsel or legal representative. Discuss with them any potential regulatory requirements or any other issues of liability regarding the loss of that data. Consult with an attorney about reporting the loss or theft to the police. Change the passwords for any accounts that may have been accessible through the lost device (e.g. through passwords saved on the device). Enable MFA on any accounts that did not already have it enabled. Some accounts may allow users to close sessions that are active, forcing anyone with access to the account to log in again. Here is how to view account activity or log out of active sessions on common services: Facebook: https://www.facebook.com/help/211990645501187?helpref=faq_content Google: https://support.google.com/mail/answer/8154?co=GENIE.Platform%3DDesktop&hl=en Microsoft: https://account.live.com/activity Apple: https://support.apple.com/en-us/HT205064 Twitter: https://help.twitter.com/en/safety-and-security/twitter-account-compromised If an account is compromised: If an employee loses control of an account or is concerned their username and password have been compromised, they should report that loss to their supervisor immediately. The supervisor should alert the organization's general counsel. Attempt to reestablish control of the account immediately and turn on MFA. Often the easiest way to do this is to initiate the \"Forgot my Password\" process on a website or service. By setting a new password and enabling MFA, most attackers will lose access to your account. Some accounts may allow users to close sessions that are active, forcing anyone with access to the account to log in again. Here is how to view account activity or log out of active sessions on common services: Facebook: https://www.facebook.com/help/211990645501187?helpref=faq_content Google: https://support.google.com/mail/answer/8154?co=GENIE.Platform%3DDesktop&hl=en Microsoft: https://account.live.com/activity Apple: https://support.apple.com/en-us/HT205064 Twitter: https://help.twitter.com/en/safety-and-security/twitter-account-compromised Examine if any actions have been taken with the account. Review account activity: Have any public posts been made? Have any messages been sent? The supervisor and employee should then catalog a list of information that was stored on that account, even if it is encrypted. Any of that information might be sensitive, and some may have regulatory consequences if lost. That list could include data like: Documents and spreadsheets relevant to their projects Any information or documents stored in email or messaging applications Strategic planning document Financial documents HR or personnel documents Assume all of the information on the device is compromised. If the information is sensitive or potentially contains personally identifiable information, send the list of information to the organization's general counsel or legal representative. Discuss with them potential regulatory requirements or any other issues of liability regarding the loss of that data. Consult with an attorney about reporting the loss or theft to the police. Consider if any other accounts use the same username or password, or could be otherwise accessed as a result of this account being compromised. Change the passwords of any accounts with shared or similar login information and enable MFA. If a device is infected with malware or ransomware: It is not always easy to tell if a device is infected, but sometimes it can become rapidly obvious. If a device is acting strangely (suddenly very slow, randomly turns off or restarts, or displays any suspicious messages), do not panic. Many infections are easily cleaned. Disconnect the device from the internet. Alert a supervisor. Run a scan with your computer's AV software Windows Defender: https://support.microsoft.com/en-us/help/4026780/windows-10-scan-an-item-with-windows-defender-antivirus Norton AntiVirus: https://support.norton.com/sp/en/us/home/current/solutions/v13139256_ns_retail_en_us McAfee AntiVirus: https://service.mcafee.com/webcenter/portal/cp/home/articleview?articleId=TS101105 If the device cannot be recovered or contains sensitive information, document the information as described above as if the device had been lost or stolen, and contact your General Counsel. If the device is not working properly, or you are unable to run AntiVirus software (as would be the case with Ransomware), attempt to turn off the computer. At this stage, you may need the consult a professional to restore, or refresh your operating system. If the malware is removed, update all software. Consider changing all important passwords that may have been saved on that computer and enable MFA on any accounts that may have been compromised. In the event of a data breach: In the event an organization loses access to sensitive information, they should consult their general counsel or legal representative immediately. There may be regulatory requirements to report that breach to authorities, or to notify individuals whose data may be affected. Do not ignore the breach. See above sections for documenting and recovering any compromised devices or accounts. Do not attempt to delete information or destroy devices that have been compromised, or communications about the breach. Doing so may be seen by authorities or regulators as an attempt to conceal the breach. Organizations should seek the advice of an attorney on how and when to contact the authorities. In the event of a serious breach, investigators may need to examine devices and systems for forensic evidence of the attack. Social Media Use Every organization has a different level of comfort with social media. By and large, use of social media is a communications issue, but cybersecurity concerns can arise and organizations should take steps to get ahead of opportunistic attackers. When developing a set of norms for the use of social media, LROss should include expectations such as the following: Secure important accounts with MFA and avoid sharing passwords between users (if possible \u2013 not all social media services allow multiple users to manage one account). Employees should not click on links or attachments sent from unknown sources. If employees are unsure if they can trust a link, they should use a service such as Norton SafeWeb , URLVoid , or ScanURL to inspect the link for potential malicious activity \u2013 but these services cannot provide guarantees of security. Suspicious documents or PDFs should always be opened in a web-based service like Google Drive, instead of being downloaded and opened directly on an employee's computer. This will prevent any malicious code embedded in the document from running on the employee's device. Do not engage with aggressive, abusive, or harassing accounts. Online trolls often seek simply to provoke an unflattering reaction from organizations that they can use to diminish its reputation. Managers of an organization's social media presence should familiarize themselves with the process of reporting malicious, abusive, or hateful comments \u2013 and should know how to use tools provided by social media services such as blocking or muting accounts. More information about how to counter harassment or abuse online can be found here: HeartMob: https://iheartmob.org/ Facebook Safety Tips (specifically for journalists, but much of the advices is generally applicable): https://www.facebook.com/facebookmedia/blog/safety-tips-for-journalists Twitter Safety Features: https://about.twitter.com/en_us/safety/safety-tools.html Payment Card Security LROs may take donations via credit cards online. There are many legal requirements for processing payment cards, and the general counsel should be an organization's first stop for understanding the specific regulatory expectations applicable to their context. In general, organizations should avoid processing payments on their own. Many web services make this process easy \u2013 including PayPal, Square, and Venmo \u2013 by providing plugins or other website add-ons that give visitors a simple way to send donations or other payments to an organization. Low-risk organization should avoid collecting and storing payment card information. Organizations may be required to maintain a record of donations or other transactions, but should always consult legal counsel about the level of detail required.","title":"Additional Cybersecurity Best Practices"},{"location":"LRO/3-Additional_Cybersecurity_Best_Practices/#section-3-additional-cybersecurity-best-practices","text":"Beyond the technical controls listed above, additional organizational expectations for cybersecurity can be documented as policies. This section reviews key areas of policy that your organization should establish in order to facilitate secure day-to-day practices. These best practices do not have Baseline or Baseline+ categories, because they are more generally about setting ground rules for behavior instead of particular technical configurations. The best practices in this section are designed as templates your organization can further customize based on your needs.","title":"Section 3: Additional Cybersecurity Best Practices"},{"location":"LRO/3-Additional_Cybersecurity_Best_Practices/#fleet-management","text":"In a large organization, merely keeping track of the broad array of devices your employees use can be a huge challenge. Even in small organizations, keeping track of phones, laptops, and tablets can be a time-consuming exercise, particularly when employee turnover is high and your organization must regularly purchase new devices and retire old ones. At a minimum, an organization should keep track of the following information: What devices does the organization own? Who is in possession/responsible for that device? Are automatic updates turned on for that device? Are the licenses for the device's operating system and software up to date? This information should be collected and refreshed at regular intervals \u2013 at a minimum once a year, but semi-annually is best. As staff depart or join, or devices are upgraded/deprecated, the running list of devices should be updated accordingly. Each organization should also have a policy for device turnover before a device is handed off to a new employee. At a minimum, this should include the following: Before an employee departs or takes possession of a new device, they must return the old device to the organization. Employees should back up important data on their devices to a shared or otherwise accessible drive or cloud storage, and should inform relevant staff of the data's location. The organization should completely wipe the device and have a fresh system install of its operating system and important software before giving it to an employee. If the device owner is leaving the organization, permissions (such as passwords to sensitive accounts, access to shared documents) should be revoked for the user of the device. A Note on Device Management Systems There are some device management systems on the market that help organizations centrally manage their devices. These systems require time and some practice to use, but they can increase an organization's visibility into what devices are part of their network, and help alert managers to potential security issues. While these systems can be very helpful, they are usually unnecessary for organizations with fewer than 25 employees. Organizations should have dedicated IT staff in charge of operating these systems. Some common ways that device management systems help organizations manage their security include: enforcing organizational security settings such as mandatory strong passwords and forced screen lockout after a certain amount of time; pushing out email profile configuration to the devices; executing remote wipe and remote lock for managed devices; and generating reports of device inventories on the network. Different device management solutions have different strengths and weaknesses. There are two key types of solutions: Server management systems: These systems can comprehensively manage intranet servers. Some can also manage network appliances (servers, standalone firewalls, etc.). However, operating such systems usually requires strong IT proficiency and infrastructure to execute. Example server management systems include: Microsoft System Center Operations Manager Splunk Mobile device management systems (including client computer management): These systems can manage most modern mobile devices and client computers. The user interface is friendly and easier to use compared to server managements system. However, they require more time and attention than server management systems. Examples include: VMWare AirWatch Microsoft Intune MobileIron","title":"\"Fleet\" Management"},{"location":"LRO/3-Additional_Cybersecurity_Best_Practices/#travel-policy","text":"Travelling \u2013 whether domestically or abroad \u2013 can create unique risks for an organization's cybersecurity. Different regions have different cybersecurity laws and expectations, and different contexts can create new risks an organization might not ordinarily encounter. There are few hard and fast rules with regards to travel policies, but there are a few basic questions that all organizations should ask themselves. A strong travel policy for your organization will address the following: Should employees bring organization-owned devices on work or personal travel? The most likely cybersecurity risk while travelling is an increased chance of device loss or theft. Therefore, at a basic level, employees should only travel with devices that utilize strong full-disk or device-level encryption so that in the event of loss, an attacker will have a difficult time accessing the information. Some organizations provide staff with special \"travel\" devices that have limited capabilities. While this can limit an organization's exposure to risk, configuring devices for travel and wiping them after travel can be time consuming. An organization should always consider what work the employee will need to do while travelling: will they need access to sensitive data, and is that data stored on their device? How regularly will they need to email and communicate with their team? In general, organizations should not travel with devices that hold sensitive information, as loss or theft of these devices could have an outsized impact on an organization. If an employee has limited needs while traveling, like basic access to email, organizations can minimize risk by limiting the number of devices an employees can takes with them (for example, allowing them to take only a phone, as opposed to a phone and a laptop). Below is a summary of policies to help employees keep their devices safe while travelling: Only travel with devices that use full-disk encryption. Never travel with devices that store sensitive information (such as HR files, financial statements, strategic documents, or information about people or their behavior). Keep devices with you at all times (do not leave them unattended or unsecured in hotel rooms). Keep devices locked or off when not using them. How should employees connect to the internet while travelling? Another common risk while travelling is an insecure connection to the internet. This may include connecting to untrustworthy Wi-Fi or accessing work resources through a public computer in a library or caf\u00e9. Unsafe connections can allow hackers to spy on your connection, steal sensitive data, or hijack important accounts. Policies to help employees avoid unsafe connections may include: Ensure all devices have up-to-date software before travel. Do not connect to the internet in places that are unknown or untrustworthy. Only use connections provided by partner organizations or large chain hotels and cafes (even these connections can be insecure, but they are less likely to be compromised). Avoid open/unsecured Wi-Fi networks (e.g. networks not protected by passwords). Never accesswork resources on a computer not owned by your organization, such as a public computer in an internet cafe. When not using devices, turn off Wi-Fi and Bluetooth radios. The US Department of Homeland Security has published a guide that offers some specific guidelines for protecting your devices and online accounts while travelling: https://www.dhs.gov/sites/default/files/publications/Cybersecurity%20While%20Traveling_7.pdf","title":"Travel Policy"},{"location":"LRO/3-Additional_Cybersecurity_Best_Practices/#incident-response","text":"Given that no system or device is ever 100% secure, it is inevitable that something bad will happen at some point. People frequently lose devices and experience compromise of online accounts or theft of bank account information. Having a plan for how your organization will deal with an incident can make a significant difference in limiting its impact. This section reviews key steps LROs should take in response to common cybersecurity incidents. If a device is lost or stolen: *Note: if the stolen device was used as an MFA method to access your accounts, you may need to contact your account providers to recover your accounts. If an employee loses a device, they should report that loss to their supervisor immediately. If the device potentially stores or has access to personally identifiable information, the supervisor should alert the general counsel immediately. It may be possible to locate a lost device. Many common devices have services that can show owners the last known location of their device, and even help them remotely wipe or deactivate the device. Apple Find my Mac: https://support.apple.com/en-us/HT204756 Find my Phone: https://support.apple.com/en-us/HT201472 Android: https://myaccount.google.com/find-your-phone Microsoft: https://support.microsoft.com/en-us/help/11579/microsoft-account-find-and-lock-lost-windows-device The supervisor and employee should then catalog a list of information that was stored on that device, even if it is encrypted. Any of that information might be sensitive, and some may have regulatory consequences if lost. That list should include data like: Documents and spreadsheets relevant to their projects Usernames and passwords to important accounts saved in their browser Any information or documents stored in their email or messaging applications Strategic planning document Financial documents HR or personnel documents Assume all of the information on the device is compromised. If the information is sensitive or potentially contains personally identifiable information, send the list of information to the organization's general counsel or legal representative. Discuss with them any potential regulatory requirements or any other issues of liability regarding the loss of that data. Consult with an attorney about reporting the loss or theft to the police. Change the passwords for any accounts that may have been accessible through the lost device (e.g. through passwords saved on the device). Enable MFA on any accounts that did not already have it enabled. Some accounts may allow users to close sessions that are active, forcing anyone with access to the account to log in again. Here is how to view account activity or log out of active sessions on common services: Facebook: https://www.facebook.com/help/211990645501187?helpref=faq_content Google: https://support.google.com/mail/answer/8154?co=GENIE.Platform%3DDesktop&hl=en Microsoft: https://account.live.com/activity Apple: https://support.apple.com/en-us/HT205064 Twitter: https://help.twitter.com/en/safety-and-security/twitter-account-compromised If an account is compromised: If an employee loses control of an account or is concerned their username and password have been compromised, they should report that loss to their supervisor immediately. The supervisor should alert the organization's general counsel. Attempt to reestablish control of the account immediately and turn on MFA. Often the easiest way to do this is to initiate the \"Forgot my Password\" process on a website or service. By setting a new password and enabling MFA, most attackers will lose access to your account. Some accounts may allow users to close sessions that are active, forcing anyone with access to the account to log in again. Here is how to view account activity or log out of active sessions on common services: Facebook: https://www.facebook.com/help/211990645501187?helpref=faq_content Google: https://support.google.com/mail/answer/8154?co=GENIE.Platform%3DDesktop&hl=en Microsoft: https://account.live.com/activity Apple: https://support.apple.com/en-us/HT205064 Twitter: https://help.twitter.com/en/safety-and-security/twitter-account-compromised Examine if any actions have been taken with the account. Review account activity: Have any public posts been made? Have any messages been sent? The supervisor and employee should then catalog a list of information that was stored on that account, even if it is encrypted. Any of that information might be sensitive, and some may have regulatory consequences if lost. That list could include data like: Documents and spreadsheets relevant to their projects Any information or documents stored in email or messaging applications Strategic planning document Financial documents HR or personnel documents Assume all of the information on the device is compromised. If the information is sensitive or potentially contains personally identifiable information, send the list of information to the organization's general counsel or legal representative. Discuss with them potential regulatory requirements or any other issues of liability regarding the loss of that data. Consult with an attorney about reporting the loss or theft to the police. Consider if any other accounts use the same username or password, or could be otherwise accessed as a result of this account being compromised. Change the passwords of any accounts with shared or similar login information and enable MFA. If a device is infected with malware or ransomware: It is not always easy to tell if a device is infected, but sometimes it can become rapidly obvious. If a device is acting strangely (suddenly very slow, randomly turns off or restarts, or displays any suspicious messages), do not panic. Many infections are easily cleaned. Disconnect the device from the internet. Alert a supervisor. Run a scan with your computer's AV software Windows Defender: https://support.microsoft.com/en-us/help/4026780/windows-10-scan-an-item-with-windows-defender-antivirus Norton AntiVirus: https://support.norton.com/sp/en/us/home/current/solutions/v13139256_ns_retail_en_us McAfee AntiVirus: https://service.mcafee.com/webcenter/portal/cp/home/articleview?articleId=TS101105 If the device cannot be recovered or contains sensitive information, document the information as described above as if the device had been lost or stolen, and contact your General Counsel. If the device is not working properly, or you are unable to run AntiVirus software (as would be the case with Ransomware), attempt to turn off the computer. At this stage, you may need the consult a professional to restore, or refresh your operating system. If the malware is removed, update all software. Consider changing all important passwords that may have been saved on that computer and enable MFA on any accounts that may have been compromised. In the event of a data breach: In the event an organization loses access to sensitive information, they should consult their general counsel or legal representative immediately. There may be regulatory requirements to report that breach to authorities, or to notify individuals whose data may be affected. Do not ignore the breach. See above sections for documenting and recovering any compromised devices or accounts. Do not attempt to delete information or destroy devices that have been compromised, or communications about the breach. Doing so may be seen by authorities or regulators as an attempt to conceal the breach. Organizations should seek the advice of an attorney on how and when to contact the authorities. In the event of a serious breach, investigators may need to examine devices and systems for forensic evidence of the attack.","title":"Incident Response"},{"location":"LRO/3-Additional_Cybersecurity_Best_Practices/#social-media-use","text":"Every organization has a different level of comfort with social media. By and large, use of social media is a communications issue, but cybersecurity concerns can arise and organizations should take steps to get ahead of opportunistic attackers. When developing a set of norms for the use of social media, LROss should include expectations such as the following: Secure important accounts with MFA and avoid sharing passwords between users (if possible \u2013 not all social media services allow multiple users to manage one account). Employees should not click on links or attachments sent from unknown sources. If employees are unsure if they can trust a link, they should use a service such as Norton SafeWeb , URLVoid , or ScanURL to inspect the link for potential malicious activity \u2013 but these services cannot provide guarantees of security. Suspicious documents or PDFs should always be opened in a web-based service like Google Drive, instead of being downloaded and opened directly on an employee's computer. This will prevent any malicious code embedded in the document from running on the employee's device. Do not engage with aggressive, abusive, or harassing accounts. Online trolls often seek simply to provoke an unflattering reaction from organizations that they can use to diminish its reputation. Managers of an organization's social media presence should familiarize themselves with the process of reporting malicious, abusive, or hateful comments \u2013 and should know how to use tools provided by social media services such as blocking or muting accounts. More information about how to counter harassment or abuse online can be found here: HeartMob: https://iheartmob.org/ Facebook Safety Tips (specifically for journalists, but much of the advices is generally applicable): https://www.facebook.com/facebookmedia/blog/safety-tips-for-journalists Twitter Safety Features: https://about.twitter.com/en_us/safety/safety-tools.html","title":"Social Media Use"},{"location":"LRO/3-Additional_Cybersecurity_Best_Practices/#payment-card-security","text":"LROs may take donations via credit cards online. There are many legal requirements for processing payment cards, and the general counsel should be an organization's first stop for understanding the specific regulatory expectations applicable to their context. In general, organizations should avoid processing payments on their own. Many web services make this process easy \u2013 including PayPal, Square, and Venmo \u2013 by providing plugins or other website add-ons that give visitors a simple way to send donations or other payments to an organization. Low-risk organization should avoid collecting and storing payment card information. Organizations may be required to maintain a record of donations or other transactions, but should always consult legal counsel about the level of detail required.","title":"Payment Card Security"},{"location":"LRO/4-Appendix_A_Building_a_Security_Policy/","text":"Please Note: Cybersecurity is a rapidly evolving field. This document was last updated on February 2, 2019. Some of the technical guidance within this document may change, and some of the risks defined may increase or decrease in their potential likelihood or impact. Appendix A: Building a Security Policy for Your Organization Security policies can serve many purposes for organizations. Some prefer these documents to be legal policies that establish clear responsibilities and liability. This section focuses on elements of security policies that can be used to plan for effective cybersecurity practice. But, if your organization wishes to utilize more legally-oriented language, the SANS Institute maintains a consensus-based collection of organizational cybersecurity policy language that your organization can use, free of charge: https://www.sans.org/security-resources/policies Each section will include a template for writing an organizational cybersecurity policy to implement the controls described in Section 2. These fillable templates, in combination with the best practices described in Section 3, can serve as a baseline cybersecurity policy for an organization. Each template can be expanded as needed \u2013 while there may not be enough fields in the examples to capture all of the devices, accounts, etc. in an organization, each policy, best practice, and control can be modified to fit the context of a specific organization. More guidance on how to select a policy and implement a control can be found in Appendix C. Strong Authentication Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Require multi-factor authentication for all organization-managed accounts. Turn on login alerts where offered. Baseline +: Require multi-factor authentication for all organization-managed accounts. Require the use of password managers. Turn on account monitoring where offered. No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual is responsible for ensuring multifactor authentication is enabled on all critical accounts, and will serve as a resource for other staff who need assistance with MFA set up or recovery. This individual is also responsible for ensuring that back up MFA codes for organization-owned accounts are stored in a safe, secure place - such as an external USB drive in a locked cabinet. What accounts are considered critical? Account MFA Forced? (Account Name) (yes/no) Automatic Updates and Software Licenses Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Force automatic updates for all operating systems, productivity software, and web browsers, and require other software updates to be installed as quickly as possible. Ensure all software licenses are renewed in a timely fashion. Baseline +: Force automatic updates for all operating systems, productivity software, and web browsers, and require other software updates to be installed as quickly as possible. Auto-renew all critical software licenses. No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual is responsible for ensuring automatic updates are turned on for all required software, and that software and services licenses are current. They will also serve as a resource for any staff having trouble updating their software. What software is considered critical? Software or Operating System Updates Forced? Auto-Renew License? (Software or OS Name) (yes/no) (yes/no) The Cloud Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Migrate organizational email to a cloud-based provider Baseline +: Migrate organizational email, data storage, and productivity software to a cloud-based provider No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual is responsible for leading the migration to any new cloud-based services - either migrating data themselves, or managing a contract with a third party to conduct that migration. They should become knowledgeable users of that service, so that any staff struggling with the transition can use them as a resource. What services are considered critical? Software or Services Cloud-based? (Software or Service Name) (yes/no) What services or software will your organization migrate to the cloud? Software or Services Persons or third party responsible for migration Timeline for migration (Software or OS Name) (Staff/Contractor Name) (Timeframe) It is highly recommended you enable strong authentication for any cloud-based services important to your organization. HTTPS Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Ensure all organization-owned websites uses HTTPS No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual will be responsible for enabling HTTPS on any organization owned or supported sites - either themselves or by working with a third party contractor/servicer. What sites does the organization own or support? Site URL Site Administrator HTTPS enabled? Timeline for enabling HTTPS? ( www.xyz.org ) (Staff/Contractor Name) (yes/no) (Timeframe) Data Security Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Enable full-disk encryption on servers, cell phones, tablets, laptops, and desktops with access to critical or sensitive information. Baseline +: Enable full-disk encryption on all servers, cell phones, tablets, laptops, and desktops with access to organization resources. Regularly review permissions on cloud-based storage accounts to ensure access controls are appropriately granted and MFA is enabled. Consider adopting and implementing a device management system (learn more in the fleet management section). No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual will be responsible for ensuring critical devices are encrypted and access management reviews are conducted. They should become knowledgeable about how to enable device encryption, as well as how to review the permissions of shared resources, so that any staff struggling with the transition can use them as a resource. What devices do those staff members use to access critical or sensitive information? Those devices should have full disk encryption enabled. Staff Devices All staff who store data deemed sensitive or critical to the organization should keep it in an encrypted state on their devices. Any data that can be stored and accessed from a shared or cloud service should remain there, under strong account security. Any information downloaded should not be held on individual devices unless necessary. If there are questions about the necessity of on-device access to certain sensitive data, employees should contact the owner of that data type. Employees who do not have a direct mission or business need should never access sensitive information. In particular, HR or personnel files should only be accessed with the explicit permission of the organization's HR team. Employees responsible for working with relevant account owners to manage, revoke, or edit access to sensitive data. The individual responsible for this policy shall implement an annual or semi-annual process to revise account permissions to ensure these permissions are up-to-date and commensurate with staff's current responsibilities. Employees who work with that data regularly are expected to contribute to that review. What services do those staff members use to store or share critical or sensitive information? Those services should be subject to a regular review of permissions. Service Interval for reviewing permissions (quarterly, semi-annual, annual)","title":"Appendix A - Building a Security Policy for Your Organization"},{"location":"LRO/4-Appendix_A_Building_a_Security_Policy/#appendix-a-building-a-security-policy-for-your-organization","text":"Security policies can serve many purposes for organizations. Some prefer these documents to be legal policies that establish clear responsibilities and liability. This section focuses on elements of security policies that can be used to plan for effective cybersecurity practice. But, if your organization wishes to utilize more legally-oriented language, the SANS Institute maintains a consensus-based collection of organizational cybersecurity policy language that your organization can use, free of charge: https://www.sans.org/security-resources/policies Each section will include a template for writing an organizational cybersecurity policy to implement the controls described in Section 2. These fillable templates, in combination with the best practices described in Section 3, can serve as a baseline cybersecurity policy for an organization. Each template can be expanded as needed \u2013 while there may not be enough fields in the examples to capture all of the devices, accounts, etc. in an organization, each policy, best practice, and control can be modified to fit the context of a specific organization. More guidance on how to select a policy and implement a control can be found in Appendix C.","title":"Appendix A: Building a Security Policy for Your Organization"},{"location":"LRO/4-Appendix_A_Building_a_Security_Policy/#strong-authentication","text":"Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Require multi-factor authentication for all organization-managed accounts. Turn on login alerts where offered. Baseline +: Require multi-factor authentication for all organization-managed accounts. Require the use of password managers. Turn on account monitoring where offered. No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual is responsible for ensuring multifactor authentication is enabled on all critical accounts, and will serve as a resource for other staff who need assistance with MFA set up or recovery. This individual is also responsible for ensuring that back up MFA codes for organization-owned accounts are stored in a safe, secure place - such as an external USB drive in a locked cabinet. What accounts are considered critical? Account MFA Forced? (Account Name) (yes/no)","title":"Strong Authentication"},{"location":"LRO/4-Appendix_A_Building_a_Security_Policy/#automatic-updates-and-software-licenses","text":"Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Force automatic updates for all operating systems, productivity software, and web browsers, and require other software updates to be installed as quickly as possible. Ensure all software licenses are renewed in a timely fashion. Baseline +: Force automatic updates for all operating systems, productivity software, and web browsers, and require other software updates to be installed as quickly as possible. Auto-renew all critical software licenses. No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual is responsible for ensuring automatic updates are turned on for all required software, and that software and services licenses are current. They will also serve as a resource for any staff having trouble updating their software. What software is considered critical? Software or Operating System Updates Forced? Auto-Renew License? (Software or OS Name) (yes/no) (yes/no)","title":"Automatic Updates and Software Licenses"},{"location":"LRO/4-Appendix_A_Building_a_Security_Policy/#the-cloud","text":"Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Migrate organizational email to a cloud-based provider Baseline +: Migrate organizational email, data storage, and productivity software to a cloud-based provider No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual is responsible for leading the migration to any new cloud-based services - either migrating data themselves, or managing a contract with a third party to conduct that migration. They should become knowledgeable users of that service, so that any staff struggling with the transition can use them as a resource. What services are considered critical? Software or Services Cloud-based? (Software or Service Name) (yes/no) What services or software will your organization migrate to the cloud? Software or Services Persons or third party responsible for migration Timeline for migration (Software or OS Name) (Staff/Contractor Name) (Timeframe) It is highly recommended you enable strong authentication for any cloud-based services important to your organization.","title":"The Cloud"},{"location":"LRO/4-Appendix_A_Building_a_Security_Policy/#https","text":"Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Ensure all organization-owned websites uses HTTPS No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual will be responsible for enabling HTTPS on any organization owned or supported sites - either themselves or by working with a third party contractor/servicer. What sites does the organization own or support? Site URL Site Administrator HTTPS enabled? Timeline for enabling HTTPS? ( www.xyz.org ) (Staff/Contractor Name) (yes/no) (Timeframe)","title":"HTTPS"},{"location":"LRO/4-Appendix_A_Building_a_Security_Policy/#data-security","text":"Read the description of this control here. Additional implementation guidance can be found here. Policy Selection: Baseline: Enable full-disk encryption on servers, cell phones, tablets, laptops, and desktops with access to critical or sensitive information. Baseline +: Enable full-disk encryption on all servers, cell phones, tablets, laptops, and desktops with access to organization resources. Regularly review permissions on cloud-based storage accounts to ensure access controls are appropriately granted and MFA is enabled. Consider adopting and implementing a device management system (learn more in the fleet management section). No Policy Policy Details: Person(s) responsible for implementing this policy: ( Name ) This individual will be responsible for ensuring critical devices are encrypted and access management reviews are conducted. They should become knowledgeable about how to enable device encryption, as well as how to review the permissions of shared resources, so that any staff struggling with the transition can use them as a resource. What devices do those staff members use to access critical or sensitive information? Those devices should have full disk encryption enabled. Staff Devices All staff who store data deemed sensitive or critical to the organization should keep it in an encrypted state on their devices. Any data that can be stored and accessed from a shared or cloud service should remain there, under strong account security. Any information downloaded should not be held on individual devices unless necessary. If there are questions about the necessity of on-device access to certain sensitive data, employees should contact the owner of that data type. Employees who do not have a direct mission or business need should never access sensitive information. In particular, HR or personnel files should only be accessed with the explicit permission of the organization's HR team. Employees responsible for working with relevant account owners to manage, revoke, or edit access to sensitive data. The individual responsible for this policy shall implement an annual or semi-annual process to revise account permissions to ensure these permissions are up-to-date and commensurate with staff's current responsibilities. Employees who work with that data regularly are expected to contribute to that review. What services do those staff members use to store or share critical or sensitive information? Those services should be subject to a regular review of permissions. Service Interval for reviewing permissions (quarterly, semi-annual, annual)","title":"Data Security"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/","text":"Please Note: Cybersecurity is a rapidly evolving field. This document was last updated on February 2, 2019. Some of the technical guidance within this document may change, and some of the risks defined may increase or decrease in their potential likelihood or impact. Appendix B: Implementation Guidance While many of the controls described in this guide are simple, that does not mean it is easy to decide where (or how strictly) to implement them in an organization. This section provides additional resources and guidance to help identify critical account, priority devices, and other information to help prioritize where an organization focuses its limited time and attention. Strong Authentication Read the description of this control here. Set policy for this control here. The below chart is a basic way to determine which accounts should be considered \"critical\" to an organization. By rating the accounts and mapping them to the staff with access, organization can determine which staff members need to prioritize enabling strong authentication. Account Inventory What online accounts does your organization consider important to your mission? This could include email, social media, financial, online storage, etc.: Account Purpose Impact on organization if access is lost (High, Medium, Low) What staff members have access to which account? Include if they \"own\" the account and are responsible for its activity. Account Staff MFA Enabled? Automatic Updates and Software Licenses Read the description of this control here. Set policy for this control here. Turning on Automatic Updates If an organization uses enterprise software that requires centralized deployment of patches and updates, an IT administrator should be in charge of patch management for critical software. Guides on how to enable automatic updates on common operating systems can be seen below: Android Devices: https://support.google.com/googleplay/answer/113412?hl=en OSX Devices: https://support.apple.com/kb/PH25532?locale=en_US iOS Devices: https://support.apple.com/en-us/HT202180 Windows 10: https://support.microsoft.com/en-us/help/3067639/how-to-get-an-update-through-windows-update Previous versions: https://support.microsoft.com/en-us/help/3067639/how-to-get-an-update-through-windows-update Finding Affordable Software Licenses Software is expensive. Cost is a major contributor to why many organizations fail to update their software. Organizations like TechSoup can help provide non-profits with affordable, discounted, or free software. But many cloud service providers offer free or discounted services for nonprofits and other public-interest organizations. Some examples of those services include: Productivity Suites: https://products.office.com/en-us/nonprofit/office-365-nonprofit-plans-and-pricing?tab=1 https://www.google.com/nonprofits/ Web Services: https://aws.amazon.com/government-education/nonprofits/ Web Hosting: https://help.dreamhost.com/hc/en-us/articles/215769478-Non-profit-discount Contact/Customer Relationship Management: http://www.salesforce.org/nonprofit/ The Cloud Read the description of this control here. Set policy for this control here. Moving data to cloud-based services can be a challenge. And, just as important, ensuring that old devices are cleaned of that data can also be difficult. This section outlines a number of important steps to take into account when migrating important data away from legacy devices. For some organizations, this is a process that can be run internally. For other organizations with a greater \"sprawl\" of data or devices, services exist to support migration to cloud-based services. TechSoup provides cloud migration consultation services for non-profits: http://page.techsoup.org/cloud-services?cg=pc Migrating Files to Cloud-Based Storage It is likely that data - both sensitive and insensitive - is currently spread across many personal devices. These files should now be consolidated in a single place. Cloud storage services, such as Google Drive or Office OneDrive, provide a simple way for employees to migrate files into a centralized location. Employees can log into a cloud storage service and upload any legacy files. This process is imperfect - it is very easy to miss files. Here a few common locations that individuals often miss when looking for legacy files on a device: Downloads folders: This applies to both mobile devices and laptops. Files downloaded onto devices for one-time viewing are often forgotten, making the downloads file a honeypot of potentially sensitive information. Employees should search through their downloads for documents that need to be archived in the cloud, and delete the entirety of their downloads folders when they have finished. For information on how to find common downloads directories, see below: Windows OSX Android iOS Search: Organizations can save documents in many locations, sometimes accidentally, sometimes on purpose. The result is that most organizations end up having a sprawl of folders across their \"documents\" library, their desktop, and everywhere in-between. While spending time searching through common directories for important documents is worthwhile, it is not always clear where to look. Using the search function in your operating system can be a powerful shortcut - but what should you search for? Depending on what type of work you do, there are likely only a few file types with which you regularly work - Microsoft Word, Excel, and Powerpoint are some of the most common. By searching for their extension name (or the .xyz at the end of the file type - such as .doc or docx for Word, or .xls or .xlsx for Excel), you can search your operating system for documents that are important to migrate. The searching process can also reveal folders you may have forgotten about that are hiding important files. Some common extensions you may want to search for include: Microsoft Word: .doc, .docx, .odt Microsoft Excel: .xls, .xlsx, .csv Microsoft Powerpoint: .ppt, .pptx Adobe: .pdf Apple Pages: .pages Apple Numbers: .number Apple Keynote: .key, .keynote An exhaustive list of other file formats and their associated applications can be found here: https://en.wikipedia.org/wiki/List_of_file_formats . Temporary folders and other hidden locations: Some operating systems will have \"temp\" folders for a number of applications, such as Office, that save in-progress documents. While it is possible to find these folder, they can often be hidden and rarely contain complete documents or files that you'll want to back up. The best way to ensure a device is clean of legacy files is to reinstall its operating system. Newer devices make this refresh easy - but many will ask if you'd like to keep an archive of the old files. This is fine, but make sure you remove that archive and store it somewhere safe - like on a USB drive not connected to the internet. WARNING: Resetting a device to factory settings or reinstalling its operating system will purge all data and applications from the device. Make sure any information you want to keep is backed up in the cloud or on an external drive before resetting your device. Information on how to reset, refresh, or reinstall common operating systems can be found here: Resetting Windows 10 How to refresh, reset, or reinstall older versions of Windows How to restore iOS device to factory settings How to wipe and reset macOS device How to restore factory settings on an Android device HTTPS Read the description of this control here. Set policy for this control here. For most websites, enabling HTTPS will not be a giant task - but it does require some baseline technical knowledge. Trying to enable HTTPS may be possible without any technical experience if you use a platform like Wordpress or Squarespace that does some of the work for you - but depending on your site's style and configuration, it can still be a challenge. It is advisable to rely on whoever administers or designed your site for support in enabling HTTPs. Some general information about how to turn on HTTPS can be found in this guide: https://httpsiseasy.com/ . Other guides to enabling HTTPS can be found here: Let's Encrypt is a free source of the certificates needed to offer HTTPS on your website. Their documentation is generally geared toward more technical users: https://letsencrypt.org/ Facebook has provided a quick guide on how and why to enable HTTPs, with links to a number of additional resources: https://developers.facebook.com/docs/facebook-login/web/enabling-https Additional information on how to enable HTTPS in common site hosting and design services can be found here: Wordpress: https://make.wordpress.org/support/user-manual/web-publishing/https-for-wordpress/ Squarespace: https://support.squarespace.com/hc/en-us/articles/205815898-Squarespace-and-SSL Data Security Read the description of this control here. Set policy for this control here. Data Inventory Data security is a difficult task, and requires ongoing management and attention. However, basic measures to encrypt devices with access to sensitive information can go a long way for low-risk organizations. The below inventory is an example of how to identify which devices should be encrypted: Data Inventory What data does your organization consider \"sensitive\" or to be essential to fulfilling its mission? This could include strategic plans, donor lists, financial records, HR records, etc. Where (what devices or systems) does that information reside? Data Type Location What staff members regularly access or process that information? Include if they \"own\" that data type. Data Type Staff What devices do those staff members use to access critical or sensitive information? Those devices should have full disk encryption enabled. Staff Devices Access Management in the Cloud Access management is an ongoing task, but many cloud-based storage services provide a high-level view of document permissions in use across the organization. Larger organizations may need to deploy more robust solutions to manage access to organization resources, but these two guides are a good place to start for LROs using common cloud storage services: Microsoft One Drive: https://support.office.com/en-us/article/stop-sharing-onedrive-files-or-folders-or-change-permissions-0a36470f-d7fe-40a0-bd74-0ac6c1e13323 Google Drive: https://support.google.com/a/answer/60781?hl=en Not all documents or directories warrant constant monitoring for access permissions. However, a few key considerations that may help organizations identify documents and directories likely to need their permissions reviewed: Documents of critical importance to organizational operations: Strategic plans, budgets, funding agreements or plans. Documents containing personal or sensitive information: HR files, donor or outreach lists with contact information, payment records, or any data that might illustrate information about individuals' behavior or preferences Files exposed to external viewers: Documents shared outside of your organization for purposes of external review or collaboration. Files accessed by departing staff: When staff leave, they are unlikely to resolve any outstanding access permissions issues. For example: owners of documents may have allowed a personal account to access an organization-owned document. Once their organization account is disabled, they may be able to retain access to that document if their personal account has opened it even once. They may have also shared documents and directories outside the organization in away that other staff are unaware of. When staff leave, it is important to review their files for permissions issues - or to archive all their documents in a new directory where the permissions can be holistically altered. Enabling Device Encryption Windows Devices Information on how to turn on device encryption in Windows 10 devices can be foud here: https://support.microsoft.com/en-us/help/4028713/windows-10-turn-on-device-encryption Note: This feature is not available on Windows Home edition, requires at least Windows Professional license. Apple Devices FileVault is a disk encryption feature built in to Mac OS X. FileVault provides 128bit AES encryption with a 256 bit key to encrypt the disk and all files located on the drive. This is a very strong encryption mechanism. Strong encryption helps to prevent unauthorized access to the Mac since the disk and all file contents are encrypted, a requiring the password must be entered on boot before the computer, data, and files can be accessed. The following link provides a step- by- step instructions on how to enable FileVault: https://support.apple.com/en-us/HT204837 All iOS devices (iPads, iPhones) from recent years have been encrypted by default, but the vast majority of iOS devices can have encryption enabled. If you need to enable device encryption on an iOS device, you can follow these directions: https://ssd.eff.org/en/module/how-encrypt-your-iphone Android Devices General instructions on how to enable full-disk encryption on Android devices can be found here: https://docs.microsoft.com/en-us/intune-user-help/encrypt-your-device-android , though the settings may differ across devices. Many new Android devices are encrypted by default. Note: Chromebooks, which run a similar (but distinct) operating system called ChromeOS, are encrypted by default.","title":"Appendix B - Implementation Guidance"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#appendix-b-implementation-guidance","text":"While many of the controls described in this guide are simple, that does not mean it is easy to decide where (or how strictly) to implement them in an organization. This section provides additional resources and guidance to help identify critical account, priority devices, and other information to help prioritize where an organization focuses its limited time and attention.","title":"Appendix B: Implementation Guidance"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#strong-authentication","text":"Read the description of this control here. Set policy for this control here. The below chart is a basic way to determine which accounts should be considered \"critical\" to an organization. By rating the accounts and mapping them to the staff with access, organization can determine which staff members need to prioritize enabling strong authentication. Account Inventory What online accounts does your organization consider important to your mission? This could include email, social media, financial, online storage, etc.: Account Purpose Impact on organization if access is lost (High, Medium, Low) What staff members have access to which account? Include if they \"own\" the account and are responsible for its activity. Account Staff MFA Enabled?","title":"Strong Authentication"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#automatic-updates-and-software-licenses","text":"Read the description of this control here. Set policy for this control here.","title":"Automatic Updates and Software Licenses"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#turning-on-automatic-updates","text":"If an organization uses enterprise software that requires centralized deployment of patches and updates, an IT administrator should be in charge of patch management for critical software. Guides on how to enable automatic updates on common operating systems can be seen below: Android Devices: https://support.google.com/googleplay/answer/113412?hl=en OSX Devices: https://support.apple.com/kb/PH25532?locale=en_US iOS Devices: https://support.apple.com/en-us/HT202180 Windows 10: https://support.microsoft.com/en-us/help/3067639/how-to-get-an-update-through-windows-update Previous versions: https://support.microsoft.com/en-us/help/3067639/how-to-get-an-update-through-windows-update","title":"Turning on Automatic Updates"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#finding-affordable-software-licenses","text":"Software is expensive. Cost is a major contributor to why many organizations fail to update their software. Organizations like TechSoup can help provide non-profits with affordable, discounted, or free software. But many cloud service providers offer free or discounted services for nonprofits and other public-interest organizations. Some examples of those services include: Productivity Suites: https://products.office.com/en-us/nonprofit/office-365-nonprofit-plans-and-pricing?tab=1 https://www.google.com/nonprofits/ Web Services: https://aws.amazon.com/government-education/nonprofits/ Web Hosting: https://help.dreamhost.com/hc/en-us/articles/215769478-Non-profit-discount Contact/Customer Relationship Management: http://www.salesforce.org/nonprofit/","title":"Finding Affordable Software Licenses"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#the-cloud","text":"Read the description of this control here. Set policy for this control here. Moving data to cloud-based services can be a challenge. And, just as important, ensuring that old devices are cleaned of that data can also be difficult. This section outlines a number of important steps to take into account when migrating important data away from legacy devices. For some organizations, this is a process that can be run internally. For other organizations with a greater \"sprawl\" of data or devices, services exist to support migration to cloud-based services. TechSoup provides cloud migration consultation services for non-profits: http://page.techsoup.org/cloud-services?cg=pc","title":"The Cloud"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#migrating-files-to-cloud-based-storage","text":"It is likely that data - both sensitive and insensitive - is currently spread across many personal devices. These files should now be consolidated in a single place. Cloud storage services, such as Google Drive or Office OneDrive, provide a simple way for employees to migrate files into a centralized location. Employees can log into a cloud storage service and upload any legacy files. This process is imperfect - it is very easy to miss files. Here a few common locations that individuals often miss when looking for legacy files on a device: Downloads folders: This applies to both mobile devices and laptops. Files downloaded onto devices for one-time viewing are often forgotten, making the downloads file a honeypot of potentially sensitive information. Employees should search through their downloads for documents that need to be archived in the cloud, and delete the entirety of their downloads folders when they have finished. For information on how to find common downloads directories, see below: Windows OSX Android iOS Search: Organizations can save documents in many locations, sometimes accidentally, sometimes on purpose. The result is that most organizations end up having a sprawl of folders across their \"documents\" library, their desktop, and everywhere in-between. While spending time searching through common directories for important documents is worthwhile, it is not always clear where to look. Using the search function in your operating system can be a powerful shortcut - but what should you search for? Depending on what type of work you do, there are likely only a few file types with which you regularly work - Microsoft Word, Excel, and Powerpoint are some of the most common. By searching for their extension name (or the .xyz at the end of the file type - such as .doc or docx for Word, or .xls or .xlsx for Excel), you can search your operating system for documents that are important to migrate. The searching process can also reveal folders you may have forgotten about that are hiding important files. Some common extensions you may want to search for include: Microsoft Word: .doc, .docx, .odt Microsoft Excel: .xls, .xlsx, .csv Microsoft Powerpoint: .ppt, .pptx Adobe: .pdf Apple Pages: .pages Apple Numbers: .number Apple Keynote: .key, .keynote An exhaustive list of other file formats and their associated applications can be found here: https://en.wikipedia.org/wiki/List_of_file_formats . Temporary folders and other hidden locations: Some operating systems will have \"temp\" folders for a number of applications, such as Office, that save in-progress documents. While it is possible to find these folder, they can often be hidden and rarely contain complete documents or files that you'll want to back up. The best way to ensure a device is clean of legacy files is to reinstall its operating system. Newer devices make this refresh easy - but many will ask if you'd like to keep an archive of the old files. This is fine, but make sure you remove that archive and store it somewhere safe - like on a USB drive not connected to the internet. WARNING: Resetting a device to factory settings or reinstalling its operating system will purge all data and applications from the device. Make sure any information you want to keep is backed up in the cloud or on an external drive before resetting your device. Information on how to reset, refresh, or reinstall common operating systems can be found here: Resetting Windows 10 How to refresh, reset, or reinstall older versions of Windows How to restore iOS device to factory settings How to wipe and reset macOS device How to restore factory settings on an Android device","title":"Migrating Files to Cloud-Based Storage"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#https","text":"Read the description of this control here. Set policy for this control here. For most websites, enabling HTTPS will not be a giant task - but it does require some baseline technical knowledge. Trying to enable HTTPS may be possible without any technical experience if you use a platform like Wordpress or Squarespace that does some of the work for you - but depending on your site's style and configuration, it can still be a challenge. It is advisable to rely on whoever administers or designed your site for support in enabling HTTPs. Some general information about how to turn on HTTPS can be found in this guide: https://httpsiseasy.com/ . Other guides to enabling HTTPS can be found here: Let's Encrypt is a free source of the certificates needed to offer HTTPS on your website. Their documentation is generally geared toward more technical users: https://letsencrypt.org/ Facebook has provided a quick guide on how and why to enable HTTPs, with links to a number of additional resources: https://developers.facebook.com/docs/facebook-login/web/enabling-https Additional information on how to enable HTTPS in common site hosting and design services can be found here: Wordpress: https://make.wordpress.org/support/user-manual/web-publishing/https-for-wordpress/ Squarespace: https://support.squarespace.com/hc/en-us/articles/205815898-Squarespace-and-SSL","title":"HTTPS"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#data-security","text":"Read the description of this control here. Set policy for this control here.","title":"Data Security"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#data-inventory","text":"Data security is a difficult task, and requires ongoing management and attention. However, basic measures to encrypt devices with access to sensitive information can go a long way for low-risk organizations. The below inventory is an example of how to identify which devices should be encrypted: Data Inventory What data does your organization consider \"sensitive\" or to be essential to fulfilling its mission? This could include strategic plans, donor lists, financial records, HR records, etc. Where (what devices or systems) does that information reside? Data Type Location What staff members regularly access or process that information? Include if they \"own\" that data type. Data Type Staff What devices do those staff members use to access critical or sensitive information? Those devices should have full disk encryption enabled. Staff Devices","title":"Data Inventory"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#access-management-in-the-cloud","text":"Access management is an ongoing task, but many cloud-based storage services provide a high-level view of document permissions in use across the organization. Larger organizations may need to deploy more robust solutions to manage access to organization resources, but these two guides are a good place to start for LROs using common cloud storage services: Microsoft One Drive: https://support.office.com/en-us/article/stop-sharing-onedrive-files-or-folders-or-change-permissions-0a36470f-d7fe-40a0-bd74-0ac6c1e13323 Google Drive: https://support.google.com/a/answer/60781?hl=en Not all documents or directories warrant constant monitoring for access permissions. However, a few key considerations that may help organizations identify documents and directories likely to need their permissions reviewed: Documents of critical importance to organizational operations: Strategic plans, budgets, funding agreements or plans. Documents containing personal or sensitive information: HR files, donor or outreach lists with contact information, payment records, or any data that might illustrate information about individuals' behavior or preferences Files exposed to external viewers: Documents shared outside of your organization for purposes of external review or collaboration. Files accessed by departing staff: When staff leave, they are unlikely to resolve any outstanding access permissions issues. For example: owners of documents may have allowed a personal account to access an organization-owned document. Once their organization account is disabled, they may be able to retain access to that document if their personal account has opened it even once. They may have also shared documents and directories outside the organization in away that other staff are unaware of. When staff leave, it is important to review their files for permissions issues - or to archive all their documents in a new directory where the permissions can be holistically altered.","title":"Access Management in the Cloud"},{"location":"LRO/5-Appendix_B_Implementation_Guidance/#enabling-device-encryption","text":"Windows Devices Information on how to turn on device encryption in Windows 10 devices can be foud here: https://support.microsoft.com/en-us/help/4028713/windows-10-turn-on-device-encryption Note: This feature is not available on Windows Home edition, requires at least Windows Professional license. Apple Devices FileVault is a disk encryption feature built in to Mac OS X. FileVault provides 128bit AES encryption with a 256 bit key to encrypt the disk and all files located on the drive. This is a very strong encryption mechanism. Strong encryption helps to prevent unauthorized access to the Mac since the disk and all file contents are encrypted, a requiring the password must be entered on boot before the computer, data, and files can be accessed. The following link provides a step- by- step instructions on how to enable FileVault: https://support.apple.com/en-us/HT204837 All iOS devices (iPads, iPhones) from recent years have been encrypted by default, but the vast majority of iOS devices can have encryption enabled. If you need to enable device encryption on an iOS device, you can follow these directions: https://ssd.eff.org/en/module/how-encrypt-your-iphone Android Devices General instructions on how to enable full-disk encryption on Android devices can be found here: https://docs.microsoft.com/en-us/intune-user-help/encrypt-your-device-android , though the settings may differ across devices. Many new Android devices are encrypted by default. Note: Chromebooks, which run a similar (but distinct) operating system called ChromeOS, are encrypted by default.","title":"Enabling Device Encryption"},{"location":"LRO/6-Appendix_C_Moving_Beyond_the_Baseline/","text":"Please Note: Cybersecurity is a rapidly evolving field. This document was last updated on February 2, 2019. Some of the technical guidance within this document may change, and some of the risks defined may increase or decrease in their potential likelihood or impact. Appendix C: Moving Beyond the Baseline As an organization grows and takes advantage of more online technologies, the opportunities for attacks on your systems and sensitive data will grow. It will be important to consider these risks as the organization adopts new technology and works to improve security practices. This section includes a list of resources that can help a LRO become more informed about cybersecurity, and can help move the organization's security practices to the next level of sophistication. Citizen Lab Security Planner The Citizen Lab, a cybersecurity research lab at the University of Toronto, recently published a web-based guide that helps individuals find cybersecurity tools and tips based on the types of devices they use and the services they tend to access online. Security Planner can be accessed here: https://securityplanner.org/ . Note that this guide is more appropriate to individuals than to LROs, but may still serve as a useful assessment and recommendation tool. NIST Small and Medium-Sized Business Guidance The National Institute of Standards and Technology is an agency within the US Department of Commerce that issues sophisticated cybersecurity guidance that is adopted widely across the US government and in many large companies. While most of their guidance is highly technical, they also have some resources on how to apply their work in smaller and more resource-constrained organizations. NISTIR 7621: Small Business Information Security: The Fundamentals http://nvlpubs.nist.gov/nistpubs/ir/2016/NIST.IR.7621r1.pdf Slides: https://csrc.nist.gov/csrc/media/projects/small-business-community/documents/sbc_workshop_presentation_2015_ver1.pdf FCC CyberPlanner The Federal Communications Commission of the US Government is a regulatory agency focused on telecommunications issues. They have many cybersecurity resources for small organizations, but their CyberPlanner page is a clear, helpful tool for developing a written organizational security policy that addresses common issues: https://www.fcc.gov/cyberplanner EFF Cybersecurity Training Materials The Electronic Frontier Foundation is a technology privacy and civil liberties advocacy organization. They have developed a number of strong, clear, and succinct training materials for improving individuals' cybersecurity practices. While many of their materials are geared toward high-risk individuals and organizations, their lessons are clear and usable by a broad audience. The Security Education Companion: https://sec.eff.org/topics Surveillance Self-Defense: https://ssd.eff.org/","title":"Appendix C - Moving Beyond the Baseline"},{"location":"LRO/6-Appendix_C_Moving_Beyond_the_Baseline/#appendix-c-moving-beyond-the-baseline","text":"As an organization grows and takes advantage of more online technologies, the opportunities for attacks on your systems and sensitive data will grow. It will be important to consider these risks as the organization adopts new technology and works to improve security practices. This section includes a list of resources that can help a LRO become more informed about cybersecurity, and can help move the organization's security practices to the next level of sophistication. Citizen Lab Security Planner The Citizen Lab, a cybersecurity research lab at the University of Toronto, recently published a web-based guide that helps individuals find cybersecurity tools and tips based on the types of devices they use and the services they tend to access online. Security Planner can be accessed here: https://securityplanner.org/ . Note that this guide is more appropriate to individuals than to LROs, but may still serve as a useful assessment and recommendation tool. NIST Small and Medium-Sized Business Guidance The National Institute of Standards and Technology is an agency within the US Department of Commerce that issues sophisticated cybersecurity guidance that is adopted widely across the US government and in many large companies. While most of their guidance is highly technical, they also have some resources on how to apply their work in smaller and more resource-constrained organizations. NISTIR 7621: Small Business Information Security: The Fundamentals http://nvlpubs.nist.gov/nistpubs/ir/2016/NIST.IR.7621r1.pdf Slides: https://csrc.nist.gov/csrc/media/projects/small-business-community/documents/sbc_workshop_presentation_2015_ver1.pdf FCC CyberPlanner The Federal Communications Commission of the US Government is a regulatory agency focused on telecommunications issues. They have many cybersecurity resources for small organizations, but their CyberPlanner page is a clear, helpful tool for developing a written organizational security policy that addresses common issues: https://www.fcc.gov/cyberplanner EFF Cybersecurity Training Materials The Electronic Frontier Foundation is a technology privacy and civil liberties advocacy organization. They have developed a number of strong, clear, and succinct training materials for improving individuals' cybersecurity practices. While many of their materials are geared toward high-risk individuals and organizations, their lessons are clear and usable by a broad audience. The Security Education Companion: https://sec.eff.org/topics Surveillance Self-Defense: https://ssd.eff.org/","title":"Appendix C: Moving Beyond the Baseline"}]}